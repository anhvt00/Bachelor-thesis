\documentclass{thesis}

\newcommand{\vnuname}{\MakeUppercase{Đại học quốc gia Hà Nội}}
\newcommand{\husname}{\MakeUppercase{Trường đại học khoa học tự nhiên}}
\newcommand{\facultyname}{\textbf{\MakeUppercase{Khoa sinh học}}}
\newcommand{\thesisname}{\bf\MakeUppercase{Xây dựng mô hình in-silico dự đoán tương tác protein-protein sử dụng mạng nơ-ron nhân tạo}}
\newcommand{\ppi}{tương tác protein-protein}
\newcommand{\ppis}{Protein-Protein Interactions}

\begin{document}

\renewcommand{\refname}{\fontsize{18pt}{18pt}TÀI LIỆU THAM KHẢO}

\newgeometry{top=2cm,bottom=2.5cm,right=3cm}
\begin{titlepage}

	\begin{tikzpicture}[remember picture, overlay]
		\draw[line width=1.2mm] ($(current page.north west) + (3cm, -3cm)$) rectangle ($(current page.south east) + (-3cm,3cm)$);
		\draw[ultra thick] ($(current page.north west) + (3.15cm,-3.15cm)$) rectangle ($(current page.south east) + (-3.15cm,3.15cm)$);
	\end{tikzpicture}

	\begin{center}
		\vspace{0.3cm}
		{\vnuname}         \\
		{\husname} \\
        {\facultyname} \\
		\vspace{3.5cm}
		{\fontsize{14pt}{14pt}\textbf{Vũ Tiến Anh}} \\
		\vspace{2cm}
		\begin{center}
		    \fontsize{18pt}{18pt}\thesisname
		\end{center}
		\vfill{}
		\vspace{3cm}
		{\fontsize{14pt}{14pt}Khóa luận tốt nghiệp đại học hệ chính quy\\ Ngành Sinh học} \\
		{\fontsize{14pt}{14pt} (Chương trình đào tạo tài năng)} \\
		\vfill{}
		\vspace{0.8cm}
		\begin{center}
		    \textbf{Hà Nội - 2022}
		\end{center}
		\vspace{0.8cm}
	\end{center}
\end{titlepage}

\begin{titlepage}
	\begin{tikzpicture}[remember picture, overlay]
		\draw[line width=1.2mm] ($(current page.north west) + (3cm, -3cm)$) rectangle ($(current page.south east) + (-3cm,3cm)$);
		\draw[ultra thick] ($(current page.north west) + (3.15cm,-3.15cm)$) rectangle ($(current page.south east) + (-3.15cm,3.15cm)$);
	\end{tikzpicture}

	\begin{center}
		\vspace{0.3cm}
		{\vnuname}         \\

		{\husname} \\
% 		\vspace{1cm}
		{\facultyname} \\
		\vspace{3.5cm}
		{\fontsize{14pt}{14pt}\textbf{Vũ Tiến Anh}} \\
		\vspace{2cm}
		\begin{center}
            \fontsize{18pt}{18pt}\thesisname
		\end{center}
		\vfill{}
		\vspace{1cm}
		{\fontsize{14pt}{14pt}Khóa luận tốt nghiệp đại học hệ chính quy\\ Ngành Sinh học} \\
		{\fontsize{14pt}{14pt} (Chương trình đào tạo tài năng)} \\
		\vfill{}

		% chktex-file 36
		\begin{tabular}{ll}
		    \textbf{\fontsize{14pt}{14pt}Cán bộ hướng dẫn:} & \textbf{\fontsize{14pt}{14pt}TS\@. Đặng Thanh Hải} \\
		                              % & \textbf{\fontsize{14pt}{14pt}TS\@. Lê Hồng Phương} \\
		                               & \textbf{\fontsize{14pt}{14pt}TS\@. Trần Đức Long}
		\end{tabular}
		\vspace{0.8cm}
		\begin{center}
		    \textbf{Hà Nội - 2022}
		\end{center}
		\vspace{0.8cm}
	\end{center}
\end{titlepage}

\restoregeometry{}
\pagebreak

\cleardoublepage{}
\pagenumbering{gobble}

% \textbf{\Large\MakeUppercase{LỜI CẢM ƠN}}\cftaddtitleline{toc}{section}{LỜI CẢM ƠN}{}
    \section*{LỜI CẢM ƠN}\
    
    \par Đầu tiên, tôi xin dành lời cảm ơn sâu sắc nhất đến bản thân vì đã rất nỗ lực học tập, nghiên cứu, tự động viên trong suốt hơn hai năm vừa rồi. Nếu không có những điều đó, khóa luận này không thể nào đạt được kết quả tốt. 
    
    \par Tôi xin cảm ơn đến TS\@. Đặng Thanh Hải đã đưa ra những định hướng và gợi mở tôi vào con đường nghiên cứu tin sinh học, và những  góp ý về đề tài khóa luận này. Tôi cũng xin cảm ơn TS\@. Trần Đức Long vì những góp ý quan trọng về trình bày khóa luận tốt nghiệp trong khoa Sinh học.
    
    \par Bên cạnh đó, tôi cũng muốn cảm ơn tới gia đình tôi, đặc biệt là mẹ, người đã chăm sóc tôi trong suốt những năm tháng ăn học. Và tôi cũng xin cảm ơn anh Ngô Quang Dương, chị Võ Hằng Mai Anh, những người bạn đã ở bên cạnh hỗ trợ, động viên trong suốt thời gian thực hiện khóa luận tốt nghiệp. 
    
    
    \begin{flushright}
        \begin{tabular}{@{}c@{}}
            Hà Nội, \MakeLowercase{\today} \\
            Sinh viên                      \\
            \\
            \\
            \\
            Vũ Tiến Anh
        \end{tabular}
    \end{flushright}
\pagebreak


\section*{BẢNG KÝ HIỆU VÀ TỪ VIẾT TẮT}


\begin{table}[htp]
\begin{tabularx}{\textwidth}{|c|X|X|X|}
    % ANN & \textit{Artificial Neural Network} \\
    % CNN & \textit{Convolutional Neural Network} \\
    % FSNN & \textit{Functional Link Neural Network} \\
    % LGBM & \textit{Light Gradient Boosting Machine} \\
    % PPI & \textit{Protein Protein Interaction} \\ 
    % RNN & \textit{Recurrent Neural Network} \\
    \hline
    \textbf{Từ viết tắt} & \textbf{Tiếng Anh} & \textbf{Tiếng Việt}\\
    \hline
    Acc & Accuracy & Độ chính xác\\
    \hline
    AUPRC & Area under precision recall curve & Diện tích dưới đường cong PRC\\
    \hline
    AUROC & Area under receiver operating curve & Diện tích dưới đường cong ROC\\
    \hline
    CNN & Convolutional neural network & Mạng nơ-ron tích chập\\
    \hline
    CSDL & & Cơ sở dữ liệu\\
    \hline
    CT & Conjoint triad & Bộ mô tả bộ ba liên tiếp\\
    \hline
    DNN & Deep neural network & Mạng nơ-ron sâu\\
    \hline
    F1 & F1-score & Điểm F1\\
    \hline
    LD & Local descriptor & Bộ mô tả đặc trưng cục bộ\\
    \hline
    Mcc & Matthew's correlation coefficient & Hệ số tương quan Matthew\\
    \hline
    MLP & Multi-layer perceptron & Perceptron đa tầng\\
    \hline
    PPI & Protein-protein interaction & tương tác protein-protein\\
    \hline
    PseAAC & Pseudo amino acid composition & Bộ mô tả thành phần giả axit amin\\
    \hline
    Pre & Precision & Độ tụ\\
    \hline
    Rec & Recall & Độ nhạy\\
    \hline
    RNN & Reccurent neural network & Mạng nơ-ron hồi cấp\\
    \hline
    Spe & Specificity & Độ đặc hiệu\\
    \hline
    TAP & Tandem affinity purification & Tinh sạch ái lực liên tiếp \\
    \hline
    Y2H & Yeast-two hybrid & Hệ thống lai hai nấm men\\
    \hline
    
\end{tabularx}
\end{table}

\pagebreak

\begingroup
\customtoc
\pagebreak
\endgroup

\begingroup
\customlistoftables
\pagebreak
\endgroup

\begingroup
\customlistoffigures
\pagebreak
\endgroup



\cleardoublepage{}
\pagenumbering{arabic}

\addtocontents{toc}{\protect\thispagestyle{empty}}


\section*{MỞ ĐẦU}\addcontentsline{toc}{section}{MỞ ĐẦU}
\par Protein là đại phân tử sinh học giúp tế bào thực hiện các chức năng quan trọng như xúc tác các phản ứng hóa sinh, sao chép ADN, chống lại tác nhân gây bệnh\ldots Protein trong tế bào không hoạt động độc lập mà thường tương tác với các phân tử khác để thực hiện chức năng sinh học. Tương tác protein-protein hay PPI (protein-protein interaction) là trung tâm của mọi quá trình sinh học trong tế bào. Nhờ các nghiên cứu về PPI, các nhà khoa học ngày một hiểu rõ hơn về các cơ chế kiểm soát hoạt động của tế bào, giúp xác định mục tiêu điều trị bệnh và thiết kế thuốc hiệu quả hơn. Nhiều phương pháp thực nghiệm xác định PPI đã được phát triển, trong đó có các kĩ thuật thông lượng cao như lai hệ thống hai nấm men, tinh sạch ái lực liên tiếp tuy nhiên gặp phải hạn chế như tỷ lệ dương tính giả cao ~25-45\%, khó xác định các protein màng, tốn kém nhiều thời gian, vật chất và công sức \cite{huang2007have}. Hệ gen của người chứa khoảng 20.000 gen mã hóa protein và tổ hợp sẽ có khoảng 200 triệu cặp protein. Cho đến thời điểm gần đây, một nghiên cứu lớn năm 2020 đã lập bản đồ hệ tương tác tham chiếu ở người với khoảng 53.000 PPI chất lượng cao, nhiều gấp 4 lần so với các PPI chất lượng cao được tuyển chọn từ các nghiên cứu quy mô nhỏ trước đó, tuy nhiên vẫn còn khoảng từ 500 nghìn đến 3 triệu PPI của hệ tương tác người vẫn còn chưa được khám phá  \cite{luck2020reference}. 

\par Có một nhu cầu cấp thiết cho phát triển các phương pháp tính toán dự đoán PPI nhanh và chính xác, các kết quả dự đoán này sẽ cần các phương pháp thực nghiệm xác nhận lại nhưng khối lượng công việc sẽ giảm bớt vì ưu tiên xác nhận lại các PPI dự đoán tin cậy cao. Các mô hình dự đoán PPI tốt nhất gần đây thường thường dựa trên các thuật toán học máy, chúng khai thác các đặc điểm thông tin sinh học khác nhau của protein, trong đó các mô hình học sâu hiện dựa trên trình tự đang là hướng nghiên cứu được quan tâm hơn cả do những tiến bộ vượt bậc của học sâu những năm gần đây \cite{dong2021survey} và sự mở rộng không ngừng của các cơ sở dữ liệu trình tự protein theo thời gian \cite{uniprot2021uniprot}. Thông qua đề tài ``Xây dựng mô hình in-silico dự đoán tương tác protein-protein sử dụng mạng nơ-ron nhân tạo'', tôi mong muốn phát triển một mô hình thuật toán tên là MCAPSL với khả năng dự đoán PPI tốt hơn một vài mô hình tốt nhất hiện nay ở một số độ đo chất lượng. Nghiên cứu gôm ba nội dung chính: (1) Xây dựng quy trình đánh giá chất lượng dự đoán PPI của các mô hình, (2) Chuẩn bị các tập dữ liệu PPI chuẩn và cài đặt một vài mô hình dự đoán PPI tốt nhất hiện nay, (3) Phát triển và cài đặt mô hình MCAPSL, (4) Đánh giá các mô hình trên các tập dữ liệu PPI chuẩn theo quy trình đã xây dựng.

\newpage
\section{TỔNG QUAN}

\subsection{Tổng quan về tương tác protein-protein}
\subsubsection{Giới thiệu về tương tác protein-protein}


\par Protein là những đại phân tử cấu thành phần lớn bộ máy phân tử tế bào của bất kỳ cơ thể sống hoặc hệ thống sinh học nào. Các protein tham gia vào hầu hết các quá trình sinh học của tế bào và để thực hiện chức năng đó, protein sẽ tương tác với các phân tử khác như ADN, ARN và protein. Tương tác protein-protein là trung tâm điều hòa các con đường hóa sinh, truyền tin tín hiệu,  biểu hiện gen, vận chuyển các chất trong tế bào. Ta có thể định nghĩa tương tác protein protein là các tiếp xúc vật lý có tính đặc hiệu cao giữa các bề mặt của protein, là kết quả của các sự kiện  hóa sinh được thiết lập bởi các tương tác yếu bao gồm liên kết hydro, tương tác kị nước, lực tĩnh điện. 

\par Giao diện của protein (protein interface) là nơi xảy ra tương tác giữa hai protein (minh họa như hình \ref{fig:ppi-interface-illustration}). Giao diện protein bao gồm các mảng (patch) trên bề mặt mỗi protein, với kích thước trung bình khoảng từ 400-1600 $\si{\angstrom}^{2}$ \cite{conte1999atomic}. Mỗi mảng bao gồm phần lõi (core) không tiếp cận được môi trường dung môi và được bao quanh bởi phần vành (rim) tiếp xúc được một phần với dung môi \cite{chakrabarti2002dissecting}. Các phân tích về trình tự giao diện cho thấy phân bố khác nhau của các axit amin giữa phần lõi và phần vành. Phần lõi gồm các gốc axit amin kị nước và nhân thơm như Tryptophan và Tyrosine, axit amin ưa nước tích điện như Arginine vùi vào trong, còn phần vành gồm các axit amin có thành phần giống với phần còn lại của bề mặt protein. Trong phần lõi, một số axit amin nhất định gọi là `điểm nóng' chịu trách nhiệm chính về phần lớn năng lượng tự do liên kết giữa hai protein. Chúng có thể được duy trì trong quá trình tiến hóa để đảm bảo tính ổn định của giao diện protein, cũng có thể đồng tiến hóa trên mỗi protein để hài hòa về tương thích hình học và điện tích của giao diện tương tác.

\par Để làm rõ hơn về bản chất tương tác protein-protein, ta cần quan tâm đến bối cảnh tương tác xảy ra ở nhiều khía cạnh. Trong tế bào, mật độ protein dày đặc với tính động học cao tạo điều kiện thuận lợi các protein có thể dễ dàng va chạm với nhau trên quãng đường di chuyển nhưng phần lớn các tiếp xúc này không phải là tương tác protein-protein mà chỉ là sự va chạm ngẫu nhiên. Các tiếp xúc protein với nhau để xem là tương tác thì phải tồn tại cùng nhau trong một thời gian đủ lớn để chúng không phải là sự va chạm ngẫu nhiên, tuy nhiên cũng có những tương tác tạm thời diễn ra trong khoảng thời gian rất ngắn cũng sẽ phải tính vào cân nhắc. Tương tác protein-protein phụ thuộc vào bối cảnh không gian và thời gian, một tương tác cụ thể không thể xuất hiện ở bất cứ loại mô hay tế bào nào vào bất ki thời điểm nào mà chỉ tồn tại ở một số loại mô tế bào nhất định vào một số thời điểm nhất định phụ thuộc vào các yếu tố liên quan đến chu kì, trạng thái tế bào, điều kiện và tác động của môi trường bên ngoài \cite{keskin2016predicting}.

\par Từ tương tác protein-protein, các đối tượng phức tạp và lớn hơn được phát triển một cách có thứ bậc. Protein có thể tương tác với một protein khác theo cặp hoặc với đồng thời nhiều protein khác trong phức hệ protein phức tạp hơn. Phức hệ protein là phức hệ tạo bởi hai hay nhiều protein cùng hoặc khác loại duy trì mối liên kết ổn định. Mạng lưới tương tác protein-protein là tập hợp các tương tác protein theo cặp và các phức hệ protein. Tập hợp các mạng lưới tương tác protein-protein của một sinh vật tạo nên một hệ thống gọi hệ tương tác của sinh vật đó. 


\begin{figure}[htp]
    {\centering
    \includegraphics[width=450pt]{images/ppi-interface-illustration.png}
    \caption{\textbf{Biểu diễn dạng đặc và dạng ruy-băng của phức hệ yếu tố xuất nhân mRNA TAP-p15} \cite{sowmya2014protein}}
    \label{fig:ppi-interface-illustration}}
    {\par Phức hệ TAP-p15 thực hiện nhiệm vụ vận chuyển mRNA ra khỏi nhân ở người, nấm men và một số sinh vật khác. Protein p15 có kích thước 140 axit amin còn protein TAP có kích thước 250 axit amin. Hai protein p15 và TAP tương tác với nhau tại giao diện, trong đó xảy ra sự tiếp xúc giữa một số gốc axit amin của chuỗi A protein p15 và một số gốc axit amin của chuỗi B protein TAP.}
\end{figure}




\subsubsection{Phân loại tương tác \ppi}
\par Các tương tác protein-protein có thể chia thành 3 loại (Hình \ref{fig:ppi-classification}): về thành phần thì chia thành homo-oligomer và hetero-oligomer, về mức độ ổn định của phức hệ hay thời gian tồn tại của phức hệ thì chia thành bắt buộc (obligate) và không bắt buộc (non-obligate), và về ái lực của tương tác thì chia thành tạm thời (transient) và vĩnh viễn (permanent) \cite{nooren2003diversity}.

\begin{itemize}
    \item \textbf{Homo-oligomer và hetero-oligomer}
    \par Phức hệ protein được gọi là homo-oligomer khi chỉ chứa một loại tiểu phần protein, ngược lại được gọi là hetero-oligomer nếu chứa từ hai loại tiểu phần protein trở lên. Phức hệ homo-oligomer có xu hướng hình thành cấu trúc vĩnh viễn, điều này đặc biệt đúng trong các trường hợp homo–dimer \cite{jones1996principles}, ví dụ: Cytochrome c tồn tại chủ yếu ở dạng dimer đóng vai trò chất vận chuyển điện tử trong hô hấp \cite{finzel1985structure}. Do tính chất đối xứng của các homo-oligomer, các phức hệ dạng này thường đóng vai trò như một giá đỡ cho các đại phân tử liên kết với nhau, ví dụ: Protein GroEL chaperonin của vi khuẩn có thể tạo thành dạng hình trụ khi liên kết với bảy protein GroES ở một mặt của nó \cite{boisvert19962}. Ngoài ra homo-oligomer thường có chức năng làm enzyme, protein mang và điều hòa quá trình phiên mã \cite{keskin2016predicting}.
    \item \textbf{Bắt buộc và không bắt buộc}
    \par Tương tác bắt buộc xuất hiện ở các phức hệ mà các protein thành phần không thể tồn tại ổn định độc lập và không bắt buộc xuất hiện ở các phức hệ mà protein thành phần có thể tồn tại ổn định độc lập\cite{nooren2003diversity}. Các giao diện không bắt buộc thường có diện tích nhỏ hơn, ít đóng chặt hơn, phân cực nhiều hơn, có tính bảo thủ yếu hơn và về tổng thể giống với bề mặt protein bình thường về thành phần axit amin hơn so với bề mặt của tương tác bắt buộc \cite{zhu2006noxclass}. Tương tác bắt buộc thường là vĩnh viễn và phần lớn các bộ máy phân tử của tế bào cấu tạo dựa trên tương tác bắt buộc trong khi tương tác không bắt buộc chủ yếu là tạm thời, phần ít là vĩnh viễn \cite{janin2008protein}. 
    \item \textbf{Vĩnh viễn và tạm thời}
    \par Tương tác vĩnh viễn có thời gian tồn tại lâu dài trong khi tương tác tạm thời thường được tạo ra và phân hủy trong một thời gian ngắn. Tương tác vĩnh viễn thường có ái lực mạnh trong khi tương tác tạm thời có thể có ái lực yếu hoặc mạnh. Tương tác tạm thời yếu được đặc trưng bởi có ái lực liên kết thấp và thời gian tồn tại rất ngắn (tức là vài giây), trong khi tương tác tạm thời mạnh là một dạng cảm ứng, hình thành khi có một tác nhân kích thích chuyển tương tác tạm thời yếu thành tương tác tạm thời mạnh. Cấu trúc của giao diện tương tác tạm thời thường nhỏ hơn giao diện tương tác vĩnh viễn và thành phần axit amin của chúng tương tự như thành phần của bề mặt protein, giao diện của tương tác tạm thời có nhiều các gốc ở các nhóm axit amin phân cực trung tính hơn so với giao diện tương tác vĩnh tiễn. Các giao diện tương tác tạm thời thường được làm giàu trong dung môi nước, giao diện này chủ yếu bao gồm lõi trung tâm bị chôn vùi hoàn toàn trong quá trình tương tác. Hơn nữa, người ta đã chỉ ra rằng các tương tác tạm thời mạnh so với tương tác tạm thời yếu có các giao diện nhỏ hơn, phẳng hơn và kỵ nước hơn \cite{nooren2003diversity}. Các gốc axit amin trong giao diện tương tác tạm thời yếu có xu hướng kém ổn định, nhưng bảo thủ cao hơn so với giao diện tương tác tạm thời mạnh \cite{nooren2003structural}.
    
\end{itemize}




\begin{figure}[htp]
    {\centering
    \includegraphics[width=400pt]{images/PPI-classification.png}
    \caption{\textbf{Phân loại tương tác protein-protein} \cite{keskin2016predicting}}
    \label{fig:ppi-classification}}
    {Tương tác protein-protein có thể được phân loại theo các đặc điểm khác nhau. Dựa trên tính ổn định của liên kết, tương tác protein-protein có thể được chia thành tương tác bắt buộc và tương tác không bắt buộc. Dựa vào thời gian tồn tại, có thể chia thành tương tác vĩnh viễn và tương tác tạm thời. Dựa vào ái lực, người ta thường chia tương tác tạm thời thành tương tác tạm thời yếu và tương tác tạm thời mạnh. Dựa vào thành phần, người ta thường chia phức hệ tương tác thành homo-oligomer và hetero-oligomer. Các phân loại này thường chồng gối lên nhau chứ không tách biệt rõ ràng.}
\end{figure}

\pagebreak

\par Tương tác protein-protein có thể đồng thời thuộc nhiều lớp phân loại khác nhau, ví dụ tương tác bắt buộc là vĩnh viễn trong khi các tương tác không bắt buôc có thể là tạm thời hoặc vĩnh viễn. Tương tác kháng thể-kháng nguyên là ví dụ về tương tác vĩnh viễn, không bắt buộc vì cả kháng nguyên và kháng thể có thể tồn tại ổn định độc lập (không bắt buộc), khi chúng bám với nhau thì sẽ tồn tại vĩnh viễn dưới dạng phức kháng nguyên-kháng thể (vĩnh viễn). Các protein tham gia vào phức hệ vĩnh viễn thường được biểu hiện cùng nhau và cùng trong một không gian nội bào hơn là các protein trong phức hệ tạm thời. Tùy thuộc vào điều kiện tế bào và sinh lý cơ thể thì tính ổn định và động học của phức protein có thể thay đổi,  một tương tác tạm thời trong điều kiện bình thường có thể trở thành một tương tác vĩnh viễn trong điêu kiện bệnh lý và ngược lại.




% \subsubsection{Điều hòa quá trình hình thành tương tác protein-protein}
% \par Cũng giống như các phức chất hóa học, tất cả các tương tác và phức hệ protein được điều khiển bởi nồng độ của các thành phần và năng lượng tự do của phức. PPI có thể được kiểm soát bằng cách thay đổi nồng độ cục bộ của các thành phần protein hoặc ảnh hưởng lên ái lực liên kết, được xác định bởi các đặc trưng hóa lý và tính chất hình học của giao diện (Hình~\ref{fig:control-protein-oligomerization}). Có ba yếu tố chính điều hòa hình thành PPI \cite{nooren2003diversity}: 
% \begin{itemize}
%     \item \textbf{Sự tiếp xúc của các protein}: Sự liên kết của hai protein hoặc protomer (trong sinh học cấu trúc, protomer là đơn vị cấu trúc của protein hetero-oligomer, là đơn vị nhỏ nhất bao gồm ít nhất hai chuỗi protein khác nhau) phụ thuộc vào sự tiếp xúc của các giao diện, đòi hỏi sự đồng điệu trong thời gian và không gian của các thành phần. Những cuộc gặp gỡ như vậy có thể xảy ra khi các protein đồng biểu hiện hoặc khu trú trong một ngăn tế bào hoặc trong các ngăn khác nhau. Đối với các cuộc gặp gỡ của các protein này từ các vị trí khác nhau, sự khuếch tán có hướng (\textit{directed diffusion}) hoặc vận chuyển theo dòng (\textit{vascular trasnport}) là điều cần thiết.
%     \item\textbf{Nồng độ cục bộ}: Các cơ chế kiểm soát làm thay đổi nồng độ cục bộ bao của biểu hiện gen, tiết protein, phân hủy protein, lưu trữ sản phẩm protein theo thời gian, môi trường phân tử cục bộ, sự khuếch tán, và độ nhớt. Rõ ràng, việc cố định của các protein trên màng (oligomer hóa của protein xuyên màng) hoặc phức hệ cấu trúc khác, cũng như sự định vị của các vùng lân cận trong các protein đa miền, có thể giúp tăng nồng độ cục bộ của các protein tham gia tương tác trong phức hệ.
%     \item \textbf{Môi trường hóa lý cục bộ}: Ái lực tương hỗ (\textit{mutual affinity}) của các thành phần của phức hệ có thể bị thay đổi khi có mặt của phân tử tác động (ví dụ: ATP, Ca$^{2+}$) hoặc sự thay đổi điều kiện sinh lý. Thông thường, nồng độ của các ion, hóa chất hoặc protein, sự thay đổi pH và nhiệt độ, hoặc các thay đổi các liên kết cộng hóa trị như quá trình phosphoryl hóa (thêm gốc PO$_{4}^{-}$) đều ảnh hưởng đến PPI.
% \end{itemize}




% \begin{figure}[htp]
%     \centering
%     \includegraphics[width=490pt]{images/control-protein-oligomerization.png}
%     \caption{Điều hòa quá trình oligomer hóa protein \cite{nooren2003diversity}}
%     \label{fig:control-protein-oligomerization}
% \end{figure}

% \par Các protomer tham gia vào các tương tác mạnh bắt buộc thường được biểu hiện đồng thời và do đó đồng vị trí khi tổng hợp (Hình~\ref{fig:relation-of-PPI-types}). Điều này rõ ràng là đúng đối với các homo-oligomer nhưng cũng có thể xảy ra trong các hetero-oligomer. Hầu hết các tương tác không bắt buộc thực hiện có chức năng điều hòa phần lớn các quá trình sinh học diễn ra trong tế bào. Cơ chế kiểm soát của PPI thường liên quan đến ái lực của phức hệ mà nó đang điều hòa. Các tương tác giữa thụ thể - chất gắn, inhibitor - enzyme, kháng thể - kháng nguyên được điều chỉnh bởi sự đồng địa hóa thường có ái lực cao với nhau và sự liên kết một khi được tạo ra thường là vĩnh viễn và không thể đảo ngược (Hình~\ref{fig:relation-of-PPI-types}). Những tương tác rất mạnh như vậy thường chỉ bị phá hủy bởi quá trình phân giải protein. Ngược lại, các tương tác tạm thời được điều chỉnh về mặt vật lý cần khả năng thay đổi ái lực giữa các chất phản ứng; ví dụ, tập hợp tiểu phần G$_{\alpha}$-G$_{\beta\gamma}$ của protein G heterotrimer, được kiểm soát bởi trao đổi GTP và GDP, thể hiện sự thay đổi ái lực gấp 1000 lần. Các công tắc điều hòa như vậy cho phép kiểm soát hiệu quả tính động học của mạng lưới protein trong sinh học.

% \begin{figure}[htp]
%     \centering
%     \includegraphics[width=500pt]{images/relation-of-PPI-types.png}
%     \caption{Mối quan hệ giữa các loại tương tác protein-protein, ái lực liên kết, và vị trí của protomer \cite{nooren2003diversity}}
%     \label{fig:relation-of-PPI-types}
% \end{figure}

% \pagebreak

\subsubsection{Các phương pháp thực nghiệm xác định tương tác protein-protein}
\par Trong vài thập kỷ qua, các nhà khoa học đã tạo ra một số lượng lớn các công cụ thực nghiệm khác nhau để xác định tương tác protein protein và nghiên cứu các đặc điểm của chúng. Các kĩ thuật này có thể dựa trên nền tảng vật lý, hóa sinh, di truyền, có thể phát hiện các thông lượng tương tác khác nhau và xác định được các đặc điểm về cấu trúc, di truyền và năng lượng của tương tác (bảng \ref{table:ppi-detection-methods}). 

\begin{table}[htp]
\caption{\textbf{Các kĩ thuật thực nghiệm thực nghiệm xác định tương tác protein-protein} \cite{keskin2016predicting} }
\label{table:ppi-detection-methods}
\begin{tabularx}{\textwidth}{p{0.4\textwidth}p{0.1\textwidth}p{0.1\textwidth}X}
    \hline
    Tên phương pháp & Thông lượng cao & Loại thí nghiệm & Loại tương tác\\
    \hline
    Lai hai nấm men (Y2H) \cite{fields1989novel} & + & in vivo & Tương tác nhị phân\\
    \hline
    Sắc kí ái lực liên tiếp (TAP) \cite{puig2001tandem} & + & in vitro & Tương tác phức\\
    \hline
    Vi chíp protein \cite{hall2007protein} & + & in vitro & Tương tác phức\\
    \hline
    Tinh thể học tia X / cộng hưởng từ hạt nhân \cite{brunger1998crystallography} & - & in vitro & Tương tác phức, thông tin cấu trúc\\
    \hline
    Truyền năng lượng cộng hưởng từ huỳnh quang (FRET) \cite{yan2003analysis} & - & in vivo & Tương tác nhị phân, thông tin ái lực\\
    \hline
    Tổ hợp gen gây chết \cite{kaelin2005concept} & + & in vivo & Tương tác phức, thông tin di truyền\\
    \hline
    Đồng biểu hiện \cite{jansen2002relating} & + & in vitro & Tương tác di truyền\\
    \hline
\end{tabularx}
\end{table}

\par Các phương pháp thông lượng thấp có thể phát hiện một hoặc một vài tương tác protein-protein và có thể tìm hiểu về các đặc điểm về cấu trúc, năng lượng của các phức hệ. Một trong những phương pháp lâu đời nhất để phát hiện tương tác với protein protein là phương pháp hóa thẩm tách xa, cũng giống với hóa thẩm thông thường ở bước điện di tách protein quan tâm nhưng bước sau không sử dụng kháng thể mà sử dụng một protein đầu dò mà ta muốn kiểm tra xen tương tác với protein quan tâm không \cite{wu2007detecting}. Protein đầu dò này có gắn huỳnh quang hoặc có thể được phát hiện bằng kháng thể, khi có tín hiệu của protein thì cũng chỉ ra sự tương tác tồn tại. Hai hương pháp thông lượng thấp phổ biến khác cũng dùng để tìm hiểu tương tác protein-protein là phương pháp tinh thể học tia X và quang phổ NMR \cite{wu2007detecting} với điểm mạnh là cung cấp thông tin về cấu trúc mô hình nguyên tử của bề mặt protein. Tuy nhiên phương pháp tinh thể học tia X chỉ có thể làm được với những protein có thể kết tinh, trong khi phương pháp cộng hưởng từ hạt nhân có thể được áp dụng cho các protein không kết tinh, nhưng mô hình nguyên tử có độ phân giải thấp. Một kỹ thuật khác để nghiên cứu tương tác với protein protein là truyền năng lượng cộng hưởng huỳnh quang (FRET) không chỉ có thể đo lường tương tác protein-protein trong thời gian thực mà còn cung cấp thông tin về độ lớn của lực liên kết \cite{yan2003analysis}.

\par Mặt khác, các phương pháp thông lượng cao có khả năng xác định một lượng lớn các tương tác protein-protein nhưng có một số hạn chế. Một đánh giá so sánh gần đây cho thấy kết quả của các phương pháp thông lượng cao chỉ giao nhau một lượng nhỏ các tương tác \cite{ito2001comprehensive}, nghĩa là có rất nhiều tương tác với độ tin cậy không cao ở phần không giao bởi các phương pháp và cần xác minh lại \cite{von2002comparative}. Phần này tập trung vào hai phương pháp thực nghiệm thông lượng cao phổ biến nhất, được sử dụng nhiều để xây dựng các cơ sở dữ liệu tương tác hiện nay là lai hai nấm men (Y2H) và tinh sạch ái lực liên tiếp (TAP).


% \textbf{Phương pháp lai hai nấm men}: Sự phát triển của kỹ thuật lai hai nấm men hay Y2H đã tăng tốc đáng kể việc sàng lọc các PPI in vivo. Y2H phát triển dựa trên cơ sở chất hoạt hóa phiên mã ở sinh vật nhân thực có ít nhất hai miền riêng biệt, một miền liên kết với trình tự promoter của gen (miền bám BD (\textit{binding domain})) và một miền khác kích hoạt phiên mã của gen (miền hoạt hóa AD (\textit{activating domain})) (Hình \ref{fig:main-exp-methods}A). Người ta đã chứng minh rằng sự phân tách của hai miền BD và AD của chất hoạt hoá sẽ làm bất hoạt quá trình phiên mã, nhưng quá trình phiên mã có thể được phục hồi nếu đưa hai miền đó gần với nhau, chúng có thể liên kết và khôi phục chất hoạt hóa, do đó phiên mã gen báo cáo \cite{fields1989novel}. Hệ thống lai hai nấm men kinh điển gồm hai protein lai gồm domain của chất hoạt hóa GAL4 ở nấm men được tổ chức trong hai plasmid chuyển vào trong nấm men, plasmid chứa trình tự mã hóa của miền GAL4 bám với ADN lai với một protein X gọi là mồi (\textit{bait}), plasmid chứa trình tự mã hóa của miền GAL4 hoạt hóa phiên mã lai với một protein Y gọi là vật bắt mồi (\textit{prey}). Nếu X và Y có thể hình thành một phức hệ protein, hai miền của GAL4 được đưa đến gần nhau và khôi phục chất hoạt hóa GAL4, dẫn đến biểu hiện gen báo cáo là $\beta$-galactosidase, ta có thể quan sát hiện tượng hai protein tương tác thông qua sàng lọc trắng xanh. Nhiều biến thể của Y2H đã được phát triển bao gồm hệ thống với một số gen báo cáo, hệ thống lai một và lai ba để xác định tương tác của protein với DNA và RNA, hệ thống phát hiện tương tác trong tế bào động vật có vú và nhân sơ, và hệ thống sàng lọc tương tác giữa các protein màng. Để sàng lọc toàn bộ hệ gen, phương pháp Y2H đã được nâng cao thành hai cách tiếp cận chính \cite{shoemaker2007deciphering}: dựa trên ma trận (\textit{matrix-based}) và dựa trên thư viện. Trong cách tiếp cận ma trận, một ma trận các dòng vật bắt mồi được tạo ra trong đó mỗi dòng biểu hiện một loại protein vật bắt mồi cụ thể trong một giếng trên đĩa. Sau đó, mỗi dòng mồi được ghép (\textit{mate}) với một loạt các dòng vật bắt mồi. Ở các vị trí biểu hiện gen báo cáo, dòng mồi bắt được dòng vật mồi, ta sẽ biết được hai protein tương ứng nào tương tác với nhau. Trong phương pháp tiếp cận thư viện, mỗi mồi được sàng lọc dựa trên thư viện vật mồi không xác định có chứa các đoạn ADNc ngẫu nhiên hoặc các khung đọc mở (ORF). Các thể lưỡng bội tạo bởi tương tác được chọn dựa trên khả năng phát triển của chúng trên các cơ chất cụ thể; và các protein tương tác được xác định bằng giải trình tự ADN. Sự trùng lặp nhỏ giữa các đợt sàng lọc Y2H khác nhau có thể được giải thích bởi các yếu tố khác nhau, trong số đó: sự khác biệt trong lấy mẫu PPI, sự phát hiện các tương tác không đặc hiệu và các hạn chế từ chính phương pháp Y2H. Ví dụ, các protein đóng vai trò chất hoạt hóa không tham gia vào dưới vai trò của protein mồi hoặc vật mồi; và việc sử dụng các trình tự lai có thể gây khó khăn vì quá trình tổng hợp protein có thể thay đổi cấu trúc của protein mục tiêu. Ngoài ra, quá trình gấp protein và các biến đổi sau chuyển hóa có thể khác nhau giữa nấm men và các sinh vật khác. Điều này gây khó khăn cho việc sàng lọc các protein từ tế bào động vật có vú và nhân sơ bằng cách sử dụng Y2H cũng như các protein nằm tế bào chất và màng do Y2H chỉ phát hiện các protein tương tác trong nhân tế bào. Để xác nhận chất lượng của các tương tác protein Y2H in vivo, các kỹ thuật in vitro khác nhau có thể được sử dụng.

% \textbf{Khối phổ}: Khối phổ hay MS là một phương pháp mạnh mẽ để nghiên cứu các PPI dạng phức protein in vitro. Nguyên tắc của phương pháp MS là tạo ra các ion có thể được phát hiện dựa trên tỷ lệ khối lượng trên điện tích của chúng, do đó cho phép xác định trình tự polypeptit (Hình \ref{fig:main-exp-methods} B). Vấn đề chuyển đổi các phân tử protein / peptit từ pha cô đặc thành các ion trong pha khí được giải quyết bằng cách sử dụng các kĩ thuật ion hóa như MALDI hoặc ESI. Các thuật toán khác nhau đã được phát triển để phân tích các hình ảnh phổ khối của các peptit và xác định ra protein từ các peptit thành phần. Một số người trong số họ tìm thấy mối tương quan giữa phổ lý thuyết và thực nghiệm trong khi những người khác sử dụng thuật toán de novo để suy ra chuỗi peptit từ luận giải lí thuyết của phổ khối. Mặc dù tính hữu ích của MS đối với việc xác định đặc tính của các protein tương tác, việc tinh sạch các phức protein lại là giới hạn của việc xác định chúng. Để giải quyết vấn đề này, tinh sạch ái lực liên tiếp hay TAP đã được phát triển để giúp MS có đầu vào tốt hơn để xác định phức protein.

% \textbf{Tinh sạch ái lực liên tiếp}: Gavin và cộng sự năm 2002 đã lần đầu tiên đã thử phương pháp gắn thẻ TAP theo cách thông lượng cao để phân tích tương tác của nấm men \cite{gavin2002functional}. Phương pháp này dựa trên việc gắn thẻ kép của protein quan tâm trên vị trí nhiễm sắc thể của nó, sau đó là quy trình tinh sạch gồm hai bước. Các protein vẫn còn liên kết với protein mục tiêu sau đó có thể được kiểm tra và xác định thông qua SDS-PAGE, tiếp theo là phân tích khối phổ \cite{rohila2004improved}, nhờ đó mà xác định các đối tác tương tác của protein quan tâm. Thẻ TAP bao gồm hai miền liên kết IgG của protein A của Staphylococcus và một peptit liên kết calmodulin được phân tách bởi vị trí phân cắt protease của virus etch thuốc lá. Khung đọc mở protein mục tiêu (ORF) được hợp nhất với trình tự DNA mã hóa thẻ TAP và được biểu hiện trong nấm men, nơi nó có thể tạo thành phức hệ bản địa (\textit{native complex}) với các protein khác. Ở bước đầu tiên của quá trình tinh sạch TAP, protein A liên kết chặt chẽ với chất nền IgG; và sau khi rửa sạch các chất không tương tác, protease phân cắt liên kết giữa protein A và chất nền IgG. Dịch rửa giải của bước đầu tiên này sau đó được ủ với các hạt phủ calmodulin với sự có mặt của canxi. Sau khi rửa, phức hợp protein mục tiêu được giải phóng. Các thành phần của mỗi phức hệ được sàng lọc bằng điện di trên gel polyacrylamide, phân cắt bằng protease, và các đoạn peptit được xác định bằng MS. So sánh Y2H và TAP – MS, cần lưu ý rằng cả hai phương pháp đều tạo ra rất nhiều kết quả dương tính giả và bỏ sót rất nhiều tương tác đã biết. Y2H có lợi thế là một kỹ thuật in vivo và phát hiện các tương tác tạm thời. Ngược lại, TAP – MS có thể báo cáo về các tương tác bậc cao ngoài loại nhị phân và do đó, cung cấp thông tin trực tiếp về phức hệ protein. Một ưu thế quan trọng của việc gắn thẻ TAP là khả năng xác định nhiều loại phức hệ protein và kiểm tra tính hoạt động của các phức hệ protein tồn tại trong sinh vật. 

% \textbf{Đồng biểu hiện gen}: Số lượng các tiểu phần có mặt với lượng cân bằng trong một phức hệ protein để đảm bảo phức hệ ổn định, do đó mức độ biểu hiện gen của các phần trong một phức hệ phải có liên quan với nhau. Ví dụ, hồ sơ biểu hiện gen có thể được cung cấp từ các thí nghiệm chu kỳ tế bào và mức độ biểu hiện của gen trong các điều kiện khác nhau. Sự tương đồng về hồ sơ biểu hiện có thể được tính toán như một hệ số tương quan giữa các mức độ biểu hiện tương đối của hai gen / protein hoặc sự khác biệt chuẩn hóa giữa các mức độ biểu hiện tuyệt đối của chúng hoặc được tính bằng các phương pháp khác (Hình \ref{fig:main-exp-methods}D). Sự phân bố của những số lượng này của các protein đích sau đó có thể được so sánh với sự phân bố cho các cặp protein không tương tác ngẫu nhiên. Nó được chỉ ra rằng sự đồng biểu hiện rõ ràng nhất đến từ các phức hệ vĩnh viễn như ribosome và proteasome \cite{jansen2002relating}. Một số nghiên cứu đã giải quyết vấn đề đồng biểu hiện gen và chứng minh rằng các protein tương tác trong nấm men có nhiều khả năng các gen của chúng cùng biểu hiện hơn so với các protein không tương tác \cite{jansen2002relating}. Một nghiên cứu quan trọng đã chỉ ra mức độ biểu hiện của các protein tương tác với nhau đồng tiến hóa (\textit{coevolve}), và có lẽ sự đồng tiến hóa của biểu hiện gen là một chỉ thị dự báo tốt hơn về sự tương tác với protein hơn là đồng tiến hóa của các trình tự axit amin \cite{fraser2004coevolution}. Để suy ra sự tương tác giữa các gen, phương pháp vi chíp ADN có thể được sử dụng thành công cùng với phương pháp tổ hợp gen gây chết.

% \textbf{Phương pháp tổ hợp gen gây chết}: Để tìm hiểu về ảnh hưởng của biến dị di truyền đến kiểu hình và cách các gen tương tác với nhau tạo ra các kiểu hình khác nhau trong các dòng khác nhau của cùng một loài, ta sử dụng các phương pháp tương tác di truyền khác nhau, trong đó phổ biến nhất là phương pháp tổ hợp gen gây chết (Hình \ref{fig:main-exp-methods}F). Phương pháp tổ hợp gen gây chết tạo ra đột biến hoặc loại bỏ hai gen riêng biệt có thể tồn tại đơn lẻ nhưng lại gây chết khi kết hợp với nhau trong một tế bào ở những điều kiện nhất định \cite{fraser2004coevolution}. Vì những đột biến này gây chết, chúng không thể được phân lập trực tiếp và cần được tạo ra nhân tạo. Tương tác tổng hợp (\textit{synthetic interaction}) có thể chỉ ra sự tương tác vật lý có thể có giữa hai sản phẩm gen, sự tham gia của chúng vào một con đường duy nhất hoặc một chức năng tương tự.

% \textbf{Theo dõi các tương tác protein ở độ phân giải cao}: Thông tin chi tiết nhất về các giao diện protein ở cấp độ nguyên tử được giải quyết khi sử dụng các phương pháp vật lý hiện đại như phương pháp tinh thể học tia X, phương pháp phổ cộng hưởng từ hạt nhân NMR, kính hiển vi điện tử nghiệm lạnh. Số lượng phức hệ protein được giải quyết bằng các phương pháp này vẫn còn hạn chế. Đồng thời, đặc tính thời gian thực của các protein tương tác in vivo có thể đạt được bằng các kỹ thuật quang phổ khác nhau yêu cầu gắn nhãn quang phổ vào protein mục tiêu. Một kỹ thuật mạnh mẽ khai thác tốt khía cạnh này là truyền năng lượng cộng hưởng huỳnh quang (FRET), sự phát quang chỉ có thể xảy ra nếu hai fluorophores nằm gần nhau \cite{yan2003analysis}. Một phương pháp hiệu quả khác, cộng hưởng plasmon bề mặt (SPR), không yêu cầu dùng nhãn quang phổ và có thể phát hiện tương tác giữa các chất gắn hòa tan và các thụ thể cố định; trong khi kỹ thuật đo nhiệt lượng chuẩn độ đẳng nhiệt (ITC) cho phép đo trực tiếp entanpi của liên kết \cite{campoy2005itc}. Gần đây, các phương pháp mới đã được phát triển để phân tích các tương tác protein ở cấp độ đơn phân tử. Ví dụ, kính hiển vi lực nguyên tử có thể đo khá chính xác các lực tương tác \cite{yang2003quantitative} trong khi kỹ thuật huỳnh quang có thể mô tả các thay đổi cấu trúc trong protein khi liên kết.


% subsubsusb
\subsubsection*{Hệ thống lai hai nấm men (Y2H)}
\par Hệ thống lai hai nấm men (Y2H) là một phương pháp sàng lọc thông lượng cao các tương tác protein-protein, phương pháp này đã giúp các nhà khoa học xây dựng một số lượng lớn các bản đồ hệ tương tác ở các loài sinh vật khác nhau \cite{ito2001comprehensive} \cite{giot2003protein} \cite{rual2005towards}. Hệ thống hoạt động dựa trên cơ sở các yếu tố phiên mã của sinh vật nhân chuẩn thuờng có hai miền phân biệt bao gồm miền liên kết hay BD (binding domain) sẽ bám vào trình tự vùng khởi động của gen và miền hoạt hóa hay AD (activating domain) sẽ kích hoạt phiên mã của gen tương ứng; nghiên cứu đã chứng minh các yếu tố phiên mã cấu trúc như vậy có thể được tách thành hai đoạn, và vẫn duy trì chức năng sinh học khi cả AD và BD tạo với nhau những liên kết yếu mà không phải liên kết mạnh như cộng hóa trị \cite{fields1989novel}. Quá trình sàng lọc lai hai nấm men của hai loại protein A và B hoạt động bằng cách tạo ra protein dung hợp nhân tạo A-BD gọi là protein mồi nhử (prey) và B-AD gọi là mồi (bait). Cả hai vector mã hóa protein chimera A-BD và B-AD được đồng chuyển vào tế bào nấm men, nếu hai protein chimera tương tác với nhau thì sẽ dẫn đến phiên mã gen báo cáo (Hình \ref{fig:y2h-system}). Sự kết hợp gen yếu tố phiên mã và báo cáo được sử dụng phổ biến nhất là yếu tố phiên mã GAL4 kết hợp với gen LacZ, mã hóa beta-galactosidase. Có một số biến thể của phương pháp Y2H: hệ thống lai một nấm men \cite{young1998yeast} phát hiện tương tác protein với ADN, hệ thống lai ba nấm men phát hiện tương tác protein với ARN \cite{fashena2000continued}. Ngoài ra, các hệ thống lai trên các sinh vật mô hình khác cũng được phát triển cho động vật có vú \cite{lee2004mammalian}, vi khuẩn \cite{toby2001using}, và protein màng \cite{aronheim1997isolation}. 

\par Có hai cách tiếp cận chung để sàng lọc Y2H trên toàn bộ hệ gen: i) dựa trên ma trận, ii) dựa trên thư viện. Trong phương pháp dựa trên ma trận \cite{walhout2000protein}, một dãy các dòng protein mồi được chuẩn bị, sau đó sử dụng một dãy các dòng protein mồi nhử để thả câu ta thu được kết quả dạng ma trận chứa các cặp protein mồi-protein mồi nhử, trong đó vị trí gen báo cáo trong ma trận biểu hiện cho biết tương tác giữa dòng protein mồi và protein mồi nhử. Phương pháp sàng lọc dựa trên thư viện \cite{bartel1996protein} dựa trên cơ sở sử dụng các dòng mồi nhử đã biết để thả câu một thư viện các dòng mồi của các đoạn ADNc hoặc khung đọc mở (ORF) chưa biết trước trình tự. Các thể nấm men chứa protein mồi nhử-protein mồi được sàng lọc dựa trên khả năng sống sót của chúng trong các môi trường cụ thể, và sau đó các protein tương tác được xác định bằng cách giải trình tự ADN các đoạn ADNc hoặc ORF. 

\par Phương pháp Y2H có một số các hạn chế, thứ nhất các protein ở sinh vật khác khi được biểu hiện trong nấm men có thể có cấu trúc cuộn gấp không đúng hoặc thiếu nhóm chức năng nên không xảy ra tương tác, thứ hai hê thống lai hai nấm men chỉ giúp xác định các tương tác protein-protein trong nhân nên với những tương tác protein-protein ngoài nhân thì sẽ không phát hiện được tương tác (âm tính giả). 

\FloatBarrier
\begin{figure}[htp]
    {\centering
    \includegraphics[width=400pt]{images/Y2H.png}
    \caption{\textbf{Hệ thống lai hai nấm men} \cite{lin2017protein}}
      \label{fig:y2h-system}
      }
    {\par (A) Hai protein muốn kiểm tra tương tác được dung hợp với hai miền của nhân tố phiên mã Gal4, với protein mồi được dung hợp với miền BD của Gal4 và protein mồi được hợp nhất với miền AD của Gal4. Ở chủng nấm men AH109, sự hoạt hóa phiên mã của gen báo cáo (ADE2, HIS3, và MEL1) chỉ xảy ra trong một tế bào mà protein mồi nhử tương tác với protein mồi để khôi phục yếu tố phiên mã Gal4 gắn với promoter GAL UAS (B) Đồng biến nạp hai vector mã hóa protein chimera mồi và chimera mồi nhử sử dụng PEG hoặc LiAc. Môi trường SD-WL chỉ môi trường tổng hợp tối thiểu khuyết thiếu tryptophan (Trp) and leucine (Leu). Môi trường SD-WLHA chỉ môi trường tổng hợp tối thiểu dextrose khuyết thiếu Trp, Leu, adenine (Ade), and histidine (His)}
\end{figure}
\FloatBarrier

\subsubsection*{Tinh sạch ái lực liên tiếp (TAP)}
\par Tinh sạch ái lực liên tiếp (TAP) là một phương pháp để tinh sạch phức hệ protein gồm một protein quan tâm với tất cả các protein đối tác từ dịch chiết tế bào \cite{puig2001tandem}. Trong bước đầu tiên của phương pháp, một protein dung hợp được tạo ra bao gồm protein quan tâm và thẻ TAP. Thẻ tinh sạch ái lực liên tiếp hay thẻ TAP bao gồm hai miền, miền liên kết IgG của Staphylococcus và một miền liên kết calmodulin được phân tách bởi vị trí cắt protease từ virus ăn mòn thuốc lá hay TEV (Tobacco etch virus) \cite{puig2001tandem} (Hình \ref{fig:tap}). Trong bước đầu tiên của TAP, thẻ TAP được thiết kế đưa vào hệ gen của sinh vật chủ để tạo protein dung hợp, tế bào có protein dung hợp được ly giải thu dịch chiết tế bào và cho qua hai cột ái lực. Ở cột thứ nhất, protein dung hợp được giữ lại trên cột gắn hạt phủ IgG. Sau đó, protein dung hợp được loại bỏ khỏi hạt phủ IgG thông qua việc cắt thẻ TAP tại vị trí cắt TEV protease, và phức hệ protein sau đó được rửa giải khỏi cột. Trong cột thứ hai, phần còn lại của thẻ TAP liên kết với các hạt calmodulin, và sau đó được rửa giải khỏi cột bằng cách đưa canxi vào và thu được phức hệ protein quan tâm và các protein đối tác. Trong các bước cuối cùng, các protein của phức hệ được phân tách thông qua điện di trên gel, được cắt ra và xác định thành phần thông qua khối phổ. Nhiều nghiên cứu quy mô lớn kết hợp TAP để xác định phức hệ và Y2H để xác định PPI trực tiếp \cite{krogan2006global}.

\begin{figure}[htp]
    {\centering
    \includegraphics[width=330pt]{images/TAP.png}
    \caption{\textbf{Phương pháp tinh sạch ái lực liên tiếp} \cite{lin2017protein}}
      \label{fig:tap}
      }
    {\par Thẻ tinh sạch ái lực liên tiếp hay thẻ TAP bao gồm ba thành phần: peptit liên kết với calmodulin, vị trí phân cắt protease của virus ăn mòn thuốc lá hay TEV (Tobacco etch virus) và Protein A là vùng liên kết với kháng thể IgG. Protein gắn thẻ TAP được tạo ra nhờ các kĩ thuật di truyền từ tế bào sinh vật mô hình. Dịch chiết tế bào sau đó được chuẩn bị cho quá trình tinh sạch ái lực liên tiếp. Cột đầu tiên bao gồm các hạt phủ kháng thể IgG giữ lại phức hệ protein quan tâm và loại bỏ các protein tạp chất (lần đầu tinh sạch) nhờ protein A trên thẻ TAP liên kết IgG, sau đó xử lý với TEV protease để chuyển sang cột tiếp theo. Cột thứ hai bao gồm các hạt calmodulin sẽ liên kết với phức hệ protein quan tâm và loại bỏ đi các tạp chất hơn nữa (lần thứ hai tinh sạch), sau cùng rửa giải nguyên thể để thu được dạng cấu trúc nguyên thể phức hệ protein.}

\end{figure}

% \textbf{Mạng tương tác protein xây dựng từ thực nghiệm}: Sự phát triển nhanh chóng của các kỹ thuật thực nghiệm đối với các tương tác protein đã cho phép xây dựng và phân tích hệ thống các mạng tương tác. Bản đồ tương tác thu được cho một loài có thể được sử dụng để dự đoán mạng lưới tương tác ở các loài khác, để xác định chức năng của các protein chưa biết và để có cái nhìn sâu sắc về sự phát triển của các kiểu tương tác protein. Các phân tích và so sánh bản đồ tương tác dựa trên quan sát rằng nhiều tương tác bảo thủ giữa các loài (liên kết bảo thủ \textit{interolog}). Các tìm kiếm dựa trên trình tự cho liên kết bảo thủ có thể xác định từ 16\% –31\% các liên kết bảo thủ thật (được kiểm tra bằng hệ thống Y2H) ngay cả giữa các loài có liên quan từ xa như nấm men và sâu \cite{matthews2001identification}. Một mạng lưới nhiều loài đã được xây dựng bằng cách xác định các cặp gen có sự biểu hiện tương quan ở các loài sinh vật khác nhau. Mạng lưới nhiều loài đã cho thấy hoạt động tốt hơn mạng đơn loài trong việc liên kết các gen liên quan về chức năng với nhau.

\subsubsection*{\textbf{Xác minh tương tác protein-protein}}
Sau tất cả quá trình khám phá, xác định tương tác và xây dựng mạng lưới, ta vẫn cần xác minh các tương tác đó có thực sự là tương tác hay không. Một số phương pháp đã được đề xuất để xác minh dữ liệu tương tác với protein tuy nhiên chúng vẫn chưa toàn diện, dưới đây tôi sẽ trình bày về hai phương pháp chính để xác minh tương tác protein-protein.
\begin{itemize}
    \item \textbf{Phương pháp chỉ số độ tin cậy của hồ sơ biểu hiện} hay chỉ số EPR (Expression profile reliability index) \cite{deane2002protein} để đánh giá chất lượng của các tập dữ liệu dựa trên hồ sơ biểu hiện của ARN thông tin. Ban đầu, hai phân bố của khoảng cách của tập dữ liệu tương tác chuẩn và tập dữ liệu không tương tác được tính toán. Sự phân bố của khoảng cách biểu hiện cho một tập dữ liệu các tương tác protein-protein  đang cần đánh giá được giả định là tổ hợp tuyến tính của hai phân bố khoảng cách biểu hiện của tập tương tác và không tương tác được tính toán ban đầu, với hệ số tuyến tính tương ứng với phân bố khoảng cách cho tập tương tác là con số đặc tả cho độ chính xác của một tập dữ liệu đang cần đánh giá. Con số đó được gọi là chỉ số EPR, cho biết mức độ chính xác của một tập dữ liệu tương tác, ví dụ chỉ số EPR = 70\% cho biết là tập dữ liệu tương tác có 70\% dữ liệu là dương tính thật, còn lại 30\% là dương tính giả.
    
    \item \textbf{Phương pháp xác minh đồng đẳng} hay PVM (Paralogous verification method) \cite{deane2002protein} dùng để kiểm tra xem các cặp tương tác protein-protein có thực sự tương tác hay không dựa trên quan sát rằng nếu hai protein tương tác với nhau, thì rất có thể các đồng đẳng (paralog) của chúng của chúng cũng sẽ phải tương tác với nhau. Trong PVM, ta lấy ra các cặp protein quan tâm từ tập dữ liệu hoặc cả tập dữ liệu, tìm kiếm các đồng đẳng với protein trong cặp và lập thành họ các protein tương ứng với protein trong cặp, đếm xem có bao nhiêu tương tác giữa các thành phần trong hai họ, nếu số đếm đó vượt một ngưỡng quy định thì gán là tương tác. Phương pháp PVM giúp gia tăng độ tin cậy đối với các tập dữ liệu tương tác, phương pháp này đã xác định \~40\% dương tính thật với tỷ lệ lỗi 1\%.
    % \item \textbf{Phương pháp đồng địa hóa protein} hay PLM (Protein localization method) \cite{sprinzak2003reliable} định nghĩa tương tác dương tính thật xảy ra khi các protein tương tác đồng địa hóa trong cùng một không gian tế bào hoặc các protein tương tác được chú giải là có chung chức năng trong tế bào. PLM cho thấy độ chính xác của dữ liệu thực nghiệm phụ thuộc phần nhiều vào phương pháp xác định thực nghiệm, với phương pháp Y2H có thể đạt 50\% dương tính thật và phương pháp kết tủa miễn dịch có thể đạt 100\% dương tính thật \cite{masters2004co}.
\end{itemize}


% \pagebreak


\subsubsection{Các cơ sở dữ liệu tương tác protein-protein}
\par Việc tích lũy một lượng lớn dữ liệu tương tác protein-protein thực nghiệm dẫn đến nhu cầu xây dựng các cơ sở dữ liệu hay CSDL để tổ chức, quản lý và xử lý thông tin về tương tác protein-protein một cách hợp lý và hiệu quả. Dữ liệu PPI trong các CSDL có thể được chia thành hai loại chính theo phương pháp thu thập các dữ liệu trong CSDL là dữ liệu PPI tuyển chọn bởi chuyên gia hay LC (literature curate) và dữ liệu PPI thông lượng cao hay HT (high-throughput) \cite{sambourg2010new}. Trong đó, lớp dữ liệu đầu tiên lưu trữ các PPI được mô tả trong tài liệu nghiên cứu là kết quả của các phương pháp thực nghiệm xác định PPI thông lượng thấp, còn lớp thứ hai lưu trữ các PPI thu được trực tiếp kết quả từ các phương pháp thực nghiệm xác định PPI thông lượng cao. Hai loại dữ liệu trên có bản chất xác định PPI từ thực nghiệm, đôi khi người ta gộp thành một loại dữ liệu, còn loại thứ hai là dữ liệu PPI dựa trên các chương trình tính toán, mô phỏng, dự đoán. Các nhà khoa học đã xây dựng các CSDL dựa hoàn toàn vào thực nghiệm, hoặc các CSDL dựa vào cả thực nghiệm và tính toán.

\par Có nhiều cơ sở dữ liệu công khai khác nhau lưu trữ PPI và các thông tin liên quan hay được sử đụng đã được phát triển (Bảng \ref{table:ppi-db}). Các CSDL tương tác được xây dựng dựa trên các tiêu chí về thông tin sinh học và mục đích sử dụng dữ liệu. Điểm chung là chúng thường có giao diện đồ họa web đơn giản để người dùng dễ dàng truy vấn tìm kiếm tương tác, sau đó các CSDL cho phép trực quan hóa các hình ảnh kết quả dạng bảng và đồ thị và cuối cùng người dùng có thể tải dữ liệu xuống dưới một số định dạng nhất định. Các CSDL thường khác nhau về mã số truy cập CSDL, loài sinh vật trọng tâm, khía cạnh thông tin PPI đang quan tâm, ngôn ngữ truy vấn trong CSDL, định dạng tệp và cách trực quan hóa kết quả; do đó có thể gây bối rối người sử dụng. Về dữ liệu, các CSDL tương tác này thường chứa thông tin tương tác dưới dạng hai mã định danh của hai protein tương tác, các mã định danh này khác nhau giữa các CSDL, để liên kết các mã định danh này ta thường dùng một cơ sở dữ liệu trình tự Uniprot \cite{uniprot2017uniprot} để quy đổi các mã định danh từ các CSDL tương tác khác nhau về mã định danh của CSDL trình tự tiêu chuẩn. Khi chuyển đổi, ta có thể gặp tình huống một số mã không tồn tại khi quy đổi sang CSDL trình tự. Khi tổng hợp thông tin từ các CSDL tương tác, chỉ có một phần rất nhỏ các tương tác trùng nhau so với số lượng tương tác trong hệ tương tác ước tính \cite{chaurasia2007unihi}.

\par Các nhà khoa học đã đi đến một số giải pháp trong việc thống nhất  các nguồn dữ liệu rời rạc, trong đó có Nhóm Sáng kiến Tiêu chuẩn Proteomics của Tổ chức Hệ protein Người hay HUPO-PSI (Human Proteome Organization Proteomics Standard Initiative) \cite{orchard2011data} và Hiệp hội Trao đổi Phân tử Quốc tế hay Imex (International Molecular Exchange Consortium) \cite{orchard2012protein}. Nhóm HUPO-PSI xác định một định dạng dữ liệu chung để trao đổi thông tin PPI tên là HUPO-PS-MI XML hiện được nhiều CSDL tương tác sử dụng để chia sẻ dữ liệu tương tác. Hiệp hội IMEx giải quyết tình trạng dư thừa thông tin PPI trong các CSDL khác nhau và sự khác biệt do tuyển chọn từ cùng một tài liệu nghiên cứu PPI. Các cơ sở dữ liệu chính Cơ sở Dữ liệu về Tương tác Protein hay DIP  (Database of Interacting Proteins) \cite{salwinski2004database}, IntAct \cite{orchard2014mintact}, và Cơ sở Dữ liệu Tương tác Phân tử hay MINT (Molecular Interaction Database) \cite{licata2012mint} là một trong những đối tác sáng lập cốt lõi của IMEx. IMEx cung cấp một hướng dẫn tuyển chọn chung để loại bỏ sự trùng lặp các nỗ lực tuyển chọn dữ liệu trước đây và loại bỏ sự sai khác của các tuyển chọn độc lập do khác nhau về phương pháp tuyển chọn. Hướng dẫn này cung cấp một tập hợp các tương tác protein không dư thừa (nonredundant) thông qua một giao diện chung giữa các CSDL.

\FloatBarrier
\begin{table}[htp]
\caption{\textbf{Các cơ sở dữ liệu tương tác thường được sử dụng gần đây} \cite{hu2021survey}}
\label{table:ppi-db}
\begin{tabularx}{\textwidth}{|p{0.1\textwidth}|p{0.72\textwidth}|X|}
    \specialrule{1.5pt}{1pt}{1pt}
    \textbf{CSDL} & \textbf{Mô tả} & \textbf{Lần cuối cập nhật}\\
    \specialrule{1.5pt}{1pt}{1pt}
    DIP \cite{salwinski2004database} & CSDL thực nghiệm tuyển chọn PPI hay được sử dụng nhất gồm hơn 81000 PPI tạo từ hơn 28000 protein của hơn 800 loài sinh vật \newline \url{https://dip.doe-mbi.ucla.edu/dip/Main.cgi} & 2021\\
    \hline
    MINT \cite{licata2012mint} & CSDL thực nghiệm tuyển chọn PPI bao gồm hơn 240000 PPI từ hơn 35000 protein 607 loài\newline \url{https://mint.bio.uniroma2.it/}  & 2012\\
    \hline
    Biogrid \cite{chatr2017biogrid} & CSDL bao gồm các tương tác protein, tương tác di truyền và các tương tác hóa học, hiện tại có hơn 1 triệu PPI từ hơn 60000 protein của hơn 40 loài sinh vật \newline\url{https://thebiogrid.org/} & 2022\\
    \hline
    HPRD \cite{keshava2009human} & CSDL PPI người lớn nhất bao gồm các thông tin về chú giải protein, PPI, biến đổi hậu dịch mã, vị trí protein biểu hiện và các thông tin khác bao gồm 30000 protein tạo nên hơn 41000 PPI \newline\url{https://www.hprd.org/} & 2010\\
    \hline
    IntAct \cite{kerrien2012intact} & CSDL bao gồm 275000 PPI nhị phân từ hơn 44000 protein của khoảng 400 loài sinh vật \newline \url{https://www.ebi.ac.uk/intact/} & 2014\\
    \hline
    STRING \cite{szklarczyk2021string} & CSDL lớn nhất cung cấp thông tin về liên hệ chức năng của hơn 1.3 tỷ PPI của hơn 9.6 triệu protein từ hơn 2030 loài sinh vật, dữ liệu tương tác thu từ cả thực nghiệm và tính toán, chú giải tự động \newline \url{https://string-db.org/} & 2022\\
    \specialrule{1.5pt}{1pt}{1pt}
\end{tabularx}
\end{table}
\FloatBarrier

% \begin{table}[htp]
% \caption{Các cơ sở dữ liệu tương tác thường được sử dụng gần đây \cite{hu2021survey}}
% \label{table:ppi-db}
% \begin{tabularx}{|X|X|X|X|X|}
%     \textbf{CSDL}  & \textbf{Số lượng tương tác} & \textbf{Số lượng protein} & \textbf{Số lượng loài} & \textbf{Loại CSDL} \\
%     \hline
%     DIP \cite{salwinski2004database} & 81923 & 28850 & 834 & Thực nghiệm\\
%     \hline
%     MINT \cite{licata2012mint} & 81923 & 28850 & 834 & Thực nghiệm\\
%     \hline
    
% \end{tabularx}
% \end{table}



\subsection{Tổng quan về học sâu}
\subsubsection{Giới thiệu về học sâu}
\par Những nghiên cứu về trí tuệ nhân tạo và phát triển một hệ thống máy móc có trí tuệ có lịch sử phát triển lâu dài, với bài báo kinh điển đầu tiên của cha đẻ ngành khoa học máy tính Alan Turing vào năm 1950 \cite{turing1950computing}. Các phương pháp tiếp cận ban đầu phát triển một hệ thống như vậy cố gắng lập trình tường minh những tri thức chuyên gia, tri thức miền cần thiết cho máy tính trong việc giải quyết một tác vụ cụ thể. Tuy nhiên, đó là một nhiệm vụ bất khả thi cho các nhà khoa học vì có quá nhiều tri thức cần thiết để lập trình dưới dạng các dòng lệnh để điều khiển máy tính thực hiện tốt một tác vụ, trong thực tế có quá nhiều các viễn cảnh khi thực hiện tác vụ đó ngay cả các nhà khoa học cũng không thể biết trước được để lập trình lại cho máy tính \cite{goodfellow2016deep}. 

\par Trong trí tuệ nhân tạo, có một lĩnh vực là học máy, đây là phương tiện đơn giản nhất để giúp máy tính thực hiện tốt tác vụ. Học máy cung cấp các giải pháp khả thi hơn với khả năng cải thiện chất lượng thực thi tác vụ thông qua gia tăng kinh nghiệm hay gia tăng dữ liệu. Về mặt toán học, học máy là phương pháp đi ước lượng một hàm số để ánh xạ từ dữ liệu đầu vào dưới dạng các vector đặc trưng đến đầu ra là mục tiêu ta đang muốn tìm kiếm, thường là các giá trị liên tục với bài toán hồi quy hoặc các giá trị rời rạc với bài toán phân lớp. Chất lượng của các thuật toán học máy thông thường chủ yếu dựa vào chất lượng của các biểu diễn dữ liệu hay còn được gọi là vector đặc trưng \cite{goodfellow2016deep}. Vector đặc trưng thường được thiết kế thủ công bởi các những chuyên gia có kiến thức miền tốt nên chất lượng của một thuật toán học máy phần nhiều phụ thuộc vào chuyên gia và cách thức thiết kế đặc trưng từ dữ liệu.

\par Một nhánh hẹp của học máy là học biểu diễn đã khắc phục được hạn chế về thiết kế đặc trưng thủ công của học máy. Học biểu diễn là việc học ra các biểu diễn hay các vector đặc trưng từ dữ liệu thô, sau đó có thể ánh xạ từ vector đặc trưng học sang đầu ra mong muốn. Để cải thiện khả năng của học biểu diễn, học sâu học các biểu diễn trung gian và phân tầng, trừu tượng hơn nhờ độ sâu của việc học. Học sâu có thể  học được các đặc trưng phức tạp trong dữ liệu bằng cách kết hợp các đặc trưng đơn giản ở các tầng phía trước trong kiến trúc mạng. Tóm tắt về mối quan hệ trí tuệ nhân tạo, học máy, học biểu diễn và học sâu được mô tả trong hình \ref{fig:relation-ai-ml-dl}.

\begin{figure}[htp]
    \centering
    \includegraphics[width=330pt]{images/relation-ai-ml-dl.jpeg}
    \caption{\textbf{Mối quan hệ của trí tuệ nhân tạo, học máy, học biểu diễn và học sâu \cite{goodfellow2016deep}}}
    \label{fig:relation-ai-ml-dl}
\end{figure}


Trong học sâu, ta thường quan tâm về các mạng nơ-ron nhân tạo sâu với nhiều tầng phi tuyến khác nhau, các biểu diễn mang tính phân cấp và trừu tượng của dữ liệu có thể được học khi chiều sâu của mạng tăng lên nhờ vào việc kết hợp phi tuyến các biểu diễn cấp thấp và đơn giản hơn. Học sâu mới chỉ thực sự nổi lên từ những năm đầu 2010 vì đến thời điểm đó mới thỏa mãn những điều kiện mà thiếu đi nó, học sâu không thể phát huy được năng lực. Chỉ đến thời điểm đó, dữ liệu lớn bùng nổ với thông tin điện tử và kĩ thuật số trở nên dễ dàng hơn bao giờ hết; sức mạnh tính toán song song của các card đồ họa GPU được tận dụng song hành với các siêu máy tính, các dịch vụ điện toán đám mây thông lượng cao; và các kiến trúc mạng nơ-ron nhân tạo đủ tinh vi để trích xuất các thông tin về không gian như mạng nơ-ron tích chập hoặc thời gian như mạng nơ-ron hồi cấp. Từ thời điểm đó, học sâu đứng đằng sau những tiến bộ lớn trong các lĩnh vực đa dạng mà cộng đồng các nhà khoa học máy tính nghiên cứu về trí tuệ nhân tạo (AI) đã phải vật lộn trong nhiều năm \cite{lecun2015deep}. Cho đến nay, các nhà khoa học đã đạt được nhiều tiến bộ trong nhiều lĩnh vực của trí tuệ nhân tạo về thị giác máy tính, xử lý hình ảnh, xử lý ngôn ngữ tự nhiên, dịch máy \cite{devlin2018bert} \cite{vaswani2017attention} \cite{brown2020language}. 

\par Số lượng công bố của học sâu không chỉ gia tăng theo hàm số mũ trong lĩnh vực nội tại mà còn trong một lĩnh vực cũng được hưởng lợi rất nhiều là tin sinh học do bản chất dữ liệu rất lớn trong các cơ sở dữ liệu sinh học (Hình \ref{fig:dl-growth}). Các thành tựu đáng kể đạt được trong tin sinh học phần nhiều cũng đến từ học sâu: các bất thường ung thư có thể được chỉ ra trong hình ảnh X-quang phổi \cite{jiang2018multiple}, hay các biến thể ADN có thể được gọi từ dữ liệu giải trình tự NGS \cite{poplin2018universal}. Và gần đây, vào năm 2020, nhóm nghiên cứu Google DeepMind đã xây dựng chương trình dự đoán cấu trúc protein từ trình tự AlphaFold với độ chính xác dự đoán rất cao lên đến hơn 90\%, tương đương với độ chính xác xác định từ phương pháp thực nghiệm \cite{jumper2021highly}. Thành công của AlphaFold đã giải quyết được một giả thuyết kinh điển đã tồn tại trong sinh học cấu trúc hơn 50 năm được đặt ra bởi Anfinsen năm 1973 \cite{anfinsen1973principles} đó là vì trình tự quy định cấu trúc cho nên ta có thể biết được cấu trúc khi biết được trình tự.





\begin{figure}[htp]
    \centering
    \includegraphics[width=330pt]{images/dl-growth.jpeg}
    \caption{\textbf{Số lượng các bài báo về học sâu được xuất bản theo năm \cite{min2017deep}}}
    \label{fig:dl-growth}
\end{figure}


 



\subsubsection{Các thành phần chính của học sâu}
Thành công của học sâu được tạo nên nhờ những nghiên cứu và phát triển các chi tiết quan trọng trong thuật toán và thường có thể được hiểu theo hai phần: xây dựng kiến trúc và huấn luyện mô hình học sâu. Kiến trúc học sâu về cơ bản là mạng nơ-ron nhân tạo gồm nhiều tầng phi tuyến tính được thiết kế phù hợp với đặc điểm dữ liệu đầu vào và các cơ chế kiểm soát và biến đổi dữ liệu truyền qua mạng. Ta có thể phân kiến trúc học sâu thành bốn nhóm bao gồm mạng nơ-ron sâu hay DNN (deep neural network)  \cite{hinton2006fast} \cite{hinton2006reducing} \cite{svozil1997introduction}, mạng nơ-ron tích chập hay CNN (convolutional neural network) \cite{lawrence1997face} \cite{lecun1989handwritten} \cite{krizhevsky2012imagenet}, mạng nơ-ron hồi cấp hay RNN (recurrent neural network) \cite{williams1989learning} \cite{bengio1994learning} \cite{hochreiter1997long} \cite{chung2014empirical} và các kiến trúc mạng mới nổi khác \cite{lena2012deep} \cite{graves2008offline} \cite{hadsell2009learning}. 


\par Mạng nơ-ron tích chập hay CNN là kiến trúc đã thành công đặc biệt trong việc nhận dạng hình ảnh và bao gồm các tầng tích chập, các tầng biến đổi phi tuyến tính và các tầng pooling. Mạng nơ-ron hồi cấp hay RNN được thiết kế để sử dụng thông tin tuần tự của dữ liệu đầu vào với các kết nối tuần hoàn giữa các khối đơn vị như perceptron, đơn vị bộ nhớ ngắn hạn dài hay LSTM (long short term memory) \cite{hochreiter1997long} hoặc đơn vị hồi tiếp có cổng hay GRU (gated recurrent unit) \cite{chung2014empirical}. Ngoài ra, nhiều kiến trúc học sâu nổi bật khác đã được đề xuất, chẳng hạn như mạng nơ-ron không-thời gian sâu hay DST-NN (deep spatio-temporal neural network) \cite{lena2012deep}, mạng nơ-ron hồi cấp đa chiều (MD-RNN) \cite{graves2008offline} và bộ mã hóa tự động tích chập hay CAE (convolutional autoencoder) \cite{hadsell2009learning}.

\par Mục tiêu của việc huấn luyện kiến trúc học sâu là học được các trọng số trong mỗi tầng, kết hợp các đặc trưng đơn giản hơn thành các đặc trưng phức tạp hơn theo độ sâu của mạng để có thể học được các biểu diễn phân cấp phù hợp từ dữ liệu. Học có giám sát (supervised learning) là hình thức học phổ biến hơn cả và các mô hình học sâu chủ yếu phát triển để giải quyết các vấn đề liên quan đến học có giám sát. Trong học có giám sát, dữ liệu cho thuật toán học bao gồm các mẫu dữ liệu (sample) và nhãn (label) tương ứng. Cách học của thuật toán học có giám sát khi làm việc với hình thức học có giám sát khá tương tự với cách chúng ta dạy một đứa trẻ cách nhận diện đồ vật, ta sẽ cho đứa trẻ nhìn những quả táo và bảo với chúng đây là quả táo, sau đó chúng ta đưa ra những quả táo khác và hỏi chúng đây là gì, ban đầu chúng có thể đoán sai hoặc đoán đúng, nhưng qua thời gian, não bộ của chúng học được cách nhận ra thế nào là một quả táo khi tiếp xúc đủ với những gì gọi là táo. Mô hình học sâu hay mạng nơ-ron nhân tạo cũng hoạt động tương tự như não bộ của đứa trẻ, khi ta cho mô hình đủ dữ liệu với nhãn tương ứng, khi đưa dữ liệu mới, mô hình sẽ biết dữ liệu này có nhãn là gì.

\par Một quy trình học các trọng số trên tập dữ liệu huấn luyện thường bao gồm bốn bước (Hình \ref{fig:nn-learning}). 
Ban đầu mạng nơ-ron sẽ khởi tạo giá trị các trọng số ngẫu nhiên theo một phân bố xác suất nào đó. 

\begin{itemize}
    \item Bước đầu tiên trong quá trình học là lan truyền xuôi (forward propagation), dữ liệu trong tập huấn luyện sẽ được truyền theo các lô (batch) qua các tầng của kiến trúc mạng, tính toán qua các đơn vị biến đổi tổ hợp tuyến tính và phi tuyến ở mỗi tầng, tín hiệu đầu ra ở mỗi tầng được sử dụng làm đầu vào ở tầng tiếp theo và cuối cùng đưa ra nhãn dự đoán (predicted label) ở tầng cuối cùng trong kiến trúc.
    \item Bước thứ hai, ta sẽ tính toán hàm mục tiêu (objective function) hay hàm mất mát (loss function) ở tầng cuối cùng trong kiến trúc mạng để đo mức độ lỗi giữa nhãn dự đoán và nhãn thực tế (true label) tương ứng của dữ liệu truyền vào.
    \item Bước thứ ba của quá trình học là lan truyền ngược (back propagation). Trong bước này, ta sử dụng quy tắc chuỗi để tính đạo hàm hay gradient của hàm mất mát đối với tất cả trọng số theo từng tầng $-$ từ tầng cuối tới tầng đầu của mạng.
    \item  Bước cuối cùng, ta sẽ cập nhật lại các trọng số ở mỗi tầng dựa vào gradient của hàm mất mát đối với các trọng số bằng các hàm tối ưu (optimizer).
\end{itemize}

\FloatBarrier
\begin{figure}[htp]
    \centering
    \includegraphics[width=350pt]{images/forward-backward.png}
    \caption{\textbf{Quá trình học một mạng nơ-ron nhân tạo} \cite{pumperla2019deep}}
    \label{fig:nn-learning}
\end{figure}
\FloatBarrier
%  Để khiến việc học của kiến trúc học sâu trở nên nhanh, ổn định với dữ liệu huấn luyện và có tính mở rộng với dữ liệu kiểm tra mới, các nhà nghiên cứu sử dụng các kĩ thuật điều chuẩn (regularization) khác nhau.

\par Trong những nghiên cứu về học sâu, các nhà khoa học thường cố gắng tối ưu từng thành phần trong mạng nơ-ron từ phát triển các hàm kích hoạt biến đổi phi tuyến cho các đơn vị nơ-ron trong mạng khác nhau như ReLU \cite{nair2010rectified} giúp tăng tốc độ huấn luyện so với các hàm kích hoạt trước đó như sigmoid hay tanh cho mạng tich chập, LeakyReLU \cite{xu2015empirical} giải quyết vấn đề nơ-ron chết bởi tiền nhiệm ReLU; các hàm tối ưu khác nhau ví dụ họ hàm tối ưu thich ứng tốc độ học dựa vào moment của gradient như Adagrad \cite{duchi2011adaptive}, Adam \cite{kingma2014adam} cho đến cách huấn luyện một mạng nơ-ron với các kĩ thuật điều chuẩn (regularization) như dropout \cite{srivastava2014dropout} rất hiệu quả trong giảm tình trạng quá khớp dữ liệu huấn luyện, hay chuẩn hóa lô dữ liệu huấn luyện (batch normalization) \cite{ioffe2015batch} giúp việc học hội tụ nhanh hơn. Việc phát triển một kiến trúc hoàn toàn mới và hiệu quả là một việc hết sức khó khăn và đỏi hỏi tốn nhiều thời gian, công sức và cả những ý tưởng đột phá, nhưng để giải quyết vấn đề nút thắt cho một số tác vụ và hướng tới trí tuệ nhân tạo tổng quát, đó là một việc cần thiết. Kiến trúc Transformer với cơ chế tự tập trung (self-attention) và tập trung (attention) được phát triển vào năm 2017 \cite{vaswani2017attention} của Vaswani và cộng sự đã thực sự cách mạng hóa hàng loạt tác vụ trong xử lý ngôn ngữ tự nhiên và sau đó mở rộng ra cho cả xử lý hình ảnh, và cho đến thời điểm hiện tại Transformer vẫn được sử dụng rất nhiều cho việc phát triển tiếp những mô hình kiến trúc mới. 




% Đầucung cấp một tập dữ liệu huấn luyện, chuyển tiếp chuyển tiếp sẽ tính toán đầu ra trong mỗi lớp và truyền các tín hiệu hàm về phía trước thông qua mạng. Trong lớp đầu ra cuối cùng, một hàm mất mục tiêu đo lường lỗi giữa các đầu ra được xâm nhập và các nhãn đã cho. Để giảm thiểu lỗi huấn luyện, chuyển ngược sử dụng quy tắc chuỗi để sao chép các tín hiệu lỗi và tính toán độ dốc đối với tất cả các trọng số trong toàn bộ mạng nơ-ron [46]. Cuối cùng, các tham số trọng số được cập nhật bằng cách sử dụng các thuật toán tối ưu hóa dựa trên đường xuống dốc ngẫu nhiên (SGD) [47]. Trong khi phần gốc chuyển màu theo lô thực hiện cập nhật tham số cho từng tập dữ liệu hoàn chỉnh, SGD cung cấp các phép xấp xỉ ngẫu nhiên bằng cách thực hiện cập nhật cho từng tập hợp nhỏ các ví dụ dữ liệu. Một số thuật toán tối ưu hóa bắt nguồn từ SGD. Ví dụ: Adagrad [48] và Adam [49] thực hiện SGD trong khi sửa đổi một cách thích ứng tỷ lệ học tập dựa trên tần suất cập nhật và thời điểm của chuyển màu cho từng tham số tương ứng. Một yếu tố cốt lõi khác trong việc đào tạo kiến trúc học sâu là chính quy hóa, đề cập đến các chiến lược nhằm tránh trang bị quá mức và do đó đạt được hiệu suất tổng quát hóa tốt. Ví dụ, phân rã theo trọng lượng [50], một cách tiếp cận thông thường nổi tiếng, thêm một thuật ngữ phạt vào hàm mất mục tiêu để các tham số trọng lượng hội tụ về các giá trị tuyệt đối nhỏ hơn. Hiện nay, cách tiếp cận chính quy được sử dụng rộng rãi nhất là bỏ học [51]. Việc bỏ học sẽ loại bỏ ngẫu nhiên các đơn vị ẩn khỏi mạng nơ-ron trong quá trình đào tạo và có thể được coi là một tập hợp các mạng con có thể có [52]. Để tăng cường khả năng bỏ học, một chức năng kích hoạt mới, maxout [53], và một biến thể bỏ học cho RNN được gọi là rnnDrop [54], đã được đề xuất. Hơn nữa, chuẩn hóa hàng loạt được đề xuất gần đây [55] cung cấp một phương pháp chuẩn hóa mới thông qua việc chuẩn hóa các tính năng vô hướng cho mỗi lần kích hoạt trong một đợt nhỏ và học từng giá trị trung bình và phương sai dưới dạng tham số.


\subsubsection{Mạng perceptron đa tầng}

\par Cấu trúc cơ bản của mạng perceptron hay MLP (multi-layer perceptron) bao gồm một tầng đầu vào (input layer), nhiều tầng ẩn (hidden layer) và một tầng đầu ra (output layer) (Hình \ref{fig:dnn-structure}). Mỗi tầng sẽ gồm một hoặc nhiều đơn vị nơ-ron (hay gọi ngắn gọn là nơ-ron).

\FloatBarrier
\begin{figure}[htp]
    \centering
    \includegraphics[width=280pt]{images/DNN.jpeg}
    \caption{\textbf{Cấu trúc cơ bản của một mạng perceptron đa tầng} \cite{min2017deep}}
    \label{fig:dnn-structure}
\end{figure}
\FloatBarrier

\par Khi truyền dữ liệu qua MLP, các giá trị đầu ra sẽ được tính toán tuần tự dọc theo độ sâu các tầng kiến trúc mạng (xem Hình~\ref{fig:perceptron}). Tại mỗi tầng, mỗi nơ-ron sẽ nhận đầu vào là các giá trị đầu ra của mỗị nơ-ron từ tầng liền trước, rồi xuất đầu ra là tổng trọng số các giá trị đầu vào. Một hàm kích hoạt thực hiện phép biến đổi phi tuyến cho tổng trọng số sẽ tính toán ra giá trị cuối cùng ở nơ-ron đó và truyền cho tầng tiếp theo. Việc tính toán trong mỗi tầng biến đổi các biểu diễn tầng phía trước thành các biểu diễn trừu tượng và mang tính thứ bậc cao hơn trong tầng phía sau \cite{lecun2015deep}. Ví dụ trong một tác vụ về phân loại hình ảnh chó mèo, biểu diễn ở các tầng thấp học được chỉ đơn thuần là các đường nét cơ bản như nét thẳng đứng, nét ngang thì ở các tầng sau học được các biểu diễn phức tạp hơn cái mũi của con mèo, cái tai của con chó. MLP được huấn luyện theo lối học giám sát, đạt được hiệu quả học càng tốt khi dữ liệu huấn luyện càng nhiều.

\pagebreak
\begin{figure}[htp]
    \centering
    \includegraphics[width=370pt]{images/perceptron.png}
    \caption{\textbf{Cấu trúc cơ bản của nơ-ron nhân tạo}}
    \label{fig:perceptron}
\end{figure}

\par Trong các nghiên cứu phát triên mô hình học sâu gần đây, MLP, hay đôi khi còn gọi là các tầng kết nối đầy đủ hay FCNN (fully-connected neural network), luôn tham gia vào các kiến trúc đa dạng khác nhau với vai trò làm thành phần cuối cùng trong mô hình với chức năng học biểu diễn và thực hiện phân lớp. Các thành phần phía trước thay đổi và đa dạng phụ thuộc vào kiến trúc, dạng dữ liệu đầu vào. Việc để MLP ở phần cuối cùng trong kiến trúc, phía sau các thành phần tích chập hoặc hồi cấp giúp tận dụng biểu diễn tốt liên quan về mặt không gian (tích chập) hoặc thời gian (hồi cấp) đã học bởi các thành phần mạng phù hợp phía trước. Đây là một cách thực hành tốt hay được khuyên dùng trong các bản thiết kế về  kiến trúc mạng nơ-ron nhân tạo.

\subsubsection{Mạng nơ-ron tích chập}
\par Mạng nơ-ron tích chập hay CNN được thiết kế để xử lý dữ liệu không gian, đặc biệt là hình ảnh hai chiều. CNN được truyền cảm hứng trực tiếp từ các nghiên cứu về vỏ não thị giác bên khoa học thần kinh. Trong vỏ não thị giác, có một hệ thống phân cấp của hai loại tế bào cơ bản: tế bào đơn giản (simple cell) và tế bào phức tạp (complex cell) \cite{hubel1968receptive}. Các tế bào đơn giản phản ứng với các mẫu nguyên thủy trong các vùng phụ của kích thích thị giác, và các tế bào phức tạp tổng hợp thông tin từ các tế bào đơn giản để xác định các dạng phức tạp hơn. Vì vỏ não thị giác là một hệ thống xử lý hình ảnh tự nhiên và mạnh mẽ, CNN được áp dụng để sử dụng ba ý tưởng chính: kết nối cục bộ (local connectivity), bất biến với vị trí (invariance to location) và bất biến với chuyển dịch cục bộ (invariance to local transition) \cite{lecun2015deep}. Kết nối cục bộ là việc sử dụng một vùng trên hình ảnh làm đầu vào nhằm khai thác mối tương quan cục bộ giữa các vùng với nhau, học được biểu diễn của các điểm ảnh xung quanh, lân cận với nhau. Trong trường hợp với hình ảnh, có một số vùng cục bộ chứa thông tin quan trọng hơn cả trong việc nhận dạng mẫu để trích xuất đặc trưng quan trọng. Bất biến về vị trí và chuyển dịch cục bộ là việc không để vị trí các vùng điểm ảnh và việc dịch chuyển chúng trong không gian ảnh hưởng đến việc học các khuôn mẫu từ hình ảnh. 

\par Cấu trúc cơ bản của CNN bao gồm các tầng tích chập (convolution layer), hàm kích hoạt và tầng gộp (pooling layer) (Hình \ref{fig:cnn}). Để học trên các vùng con trong bức ảnh có tính tương quan cao, các ánh xạ đặc trưng (feature map) được tạo ra từ mỗi tầng tích chập, phép tích chập diễn ra giữa các mảng cục bộ (local patch) và các vectơ trọng số gọi là bộ lọc (filter) hay hạt nhân (kernel). Vì các khuôn mẫu dữ liệu giống hệt nhau có thể xuất hiện bất kể vị trí, nên các bộ lọc cùng được áp dụng trên toàn bộ hình ảnh, điều này cũng cải thiện hiệu quả huấn luyện bằng cách giảm số lượng tham số cần phải học. Các bộ lọc với các trọng số khác nhau có thể học được các đặc trưng không gian khác nhau trên hình ảnh. Sau đó các hàm kích hoạt thực hiện các phép biến đổi phi tuyến trên các ánh xạ đặc trưng nhằm tăng cường các đặc trưng phi tuyến trong các ánh xạ đặc trưng. Tại mỗi tầng gộp, việc gộp tối đa (max pooling) hoặc gộp trung bình (average pooling) của các vùng trong ánh xạ đặc trưng được thực hiện cho phép CNN giảm chiều dữ liệu, giảm bớt các đặc trưng giống nhau, giữ lại các đặc trưng quan trọng và trừu tượng.


\begin{figure}[htp]
    \centering
    \includegraphics[width=400pt]{images/cnn.jpeg}
    \caption{\textbf{Cấu trúc cơ bản của mạng nơ-ron tích chập}}
    \label{fig:cnn}
\end{figure}


\subsubsection{Đánh giá chất lượng mô hình}
\subsubsection*{Quy trình đánh giá chất lượng học}
\par Kiểm định (validation) là việc đánh giá chất lượng mô hình khi cho học trên tập huấn luyện rồi đánh giá trên tập kiểm tra. Kiểm định có thể diễn ra theo nhiều phương pháp trong đó có ba phương pháp chính là kiểm định hold-out (hold-out validation), kiểm định chéo k-fold (k-fold cross-validation), kiểm định chéo leave-one-out (leave-one-out cross-validation) \cite{hu2021survey}. 

\par Kiểm định hold-out là quá trình đánh giá đơn giản nhất, ta thường chia ngẫu nhiên tập dữ liệu thành tập huấn luyện và tập kiểm tra theo tỷ lệ 80\%:20\% hoặc 70\%:30\% tuy nhiên chiến lược đánh giá này có phương sai cao, chất lượng phụ thuộc nhiều vào các cặp protein trong cả tập huấn luyện và tập kiểm tra được chia ngẫu nhiên. Để vượt qua hạn chế ở kiểm định hold-out do tính ngẫu nhiên trong phân chia tập huấn luyện và tập kiểm tra, kiểm định chéo k-fold chia tập dữ liệu thành k phân hoạch và đánh giá chất lượng k lần trong đó mỗi lần sử dụng k-1 phân hoạch cho tập huấn luyện và 1 phân hoạch cho tập kiểm tra, các lần đánh giá không sử dụng cùng 1 phân hoạch làm tập kiểm tra. Với cách triển khai như vậy sẽ làm giảm phương sai đánh giá và chất lượng đáng tin cậy hơn, tuy nhiên thời gian tăng lên nhiều vì phải tăng số lần đánh giá. Kiểm định chéo leave-one-out là trường hợp mở rộng của kiểm định chéo k-fold, trong đó kich thước của phân hoạch kiểm tra là một phần tử hay trong trường hợp này là một cặp protein, phần còn lại được sử dụng để huấn luyện. Chiến lược làm như vậy sẽ làm phân bố của các đặc trưng trong tập huấn luyện gần với thực tế hơn, do đó chất lượng đánh giá càng đáng tin cậy hơn, tuy nhiên sẽ làm cho thời gian tính toán gia tăng theo hàm số mũ.

\subsubsection*{Độ đo đánh giá chất lượng học}
\par Để đánh giá chất lượng dự đoán PPI của các mô hình tính toán, một số độ đo chất lượng được sử dụng trong so sánh các mô hình học thống kê trong tác vụ phân lớp nhị phân như độ chính xác hay Acc (accuracy), độ tụ hay Pre (precision), độ nhạy hay Rec (recall), độ đặc hiệu hay Spe (specificity),  điểm F1 hay F1 (F1-score) \cite{powers2020evaluation}, hệ số tương quan Matthew hay MCC (Matthew coefficient of correlation) \cite{matthews1975comparison}, diện tích dưới đường cong ROC hay AUROC (area under receiver operating curve) \cite{fawcett2006introduction} và diện tích dưới đườn cong PRC hay AUPRC (area under precision recall curve) \cite{davis2006relationship}. Các độ đo này được định nghĩa trên nền tảng ma trận nhầm lẫn (confusion matrix) với 4 chỉ số cho tác vụ dự đoán nhị phân: Dương tính thật hay TP (true positive) là số lượng mẫu dương tính được dự đoán là dương tính, âm tính thật hay TN (true negative) là số lượng mẫu âm tính được dự đoán là âm tính, dương tính giả hay FP (false positive) là số lượng mẫu âm tính được dự đoán là dương tính, âm tính giả hay FN (false negative): số lượng mẫu dương tính được dự đoán là âm tính. 

\par Độ chính xác là số dự đoán đúng trên tổng số dự đoán. Trong bài toán phân lớp nhị phân, Acc hay được sử dụng khi tập dữ liệu cân bằng về nhãn âm tính và dương tính, không nên sử dụng khi tập dữ liệu mất cân bằng quá lớn về nhãn một lớp.
\[
    \text{Acc} = \frac{TP+TN}{TP+FP+TN+FN}
\]

\par Độ tụ hay Pre là số dự đoán dương tính thật trên tổng số dự đoán dương tính. Độ tụ cho biết về độ chuẩn xác trong dự đoán dương tính, độ tụ càng cao có nghĩa là số FP càng ít so với số TP bất kể số FN, có nghĩa nếu như mô hình chỉ dự đoán đúng 1 mẫu dương tính còn lại dự đoán là âm tính thì độ tụ của mô hình vẫn là 100\% nhưng sẽ có FN cao do các mẫu dương tính khác đều được dự đoán là âm tính. 
\[
    \text{Pre} = \frac{TP}{TP+FP}
\]

\par Độ nhạy hay Rec là số dự đoán dương tính thật trên tổng số mẫu có nhãn dương tính. Rec cho biết về khả năng gọi ra tất cả những mẫu dương tính, độ nhạy càng cao thì khả năng gọi ra các mẫu dương tính càng cao và FN càng thấp so với TP, nếu như mô hình dự đoán tất cả các mẫu đều là dương tính thì chắc chắn mô hình đã tìm được ra hết mẫu dương tính, độ nhạy lúc đó là 100\% nhưng sẽ có FP cao do các mẫu âm tính cũng được dự đoán là dương tính.
\[
    \text{Rec} = \frac{TP}{TP+FN}
\]

\par Độ đặc hiệu hay Spe là số dự đoán âm tính thật trên tổng số mẫu có nhãn âm tính. Độ đặc hiệu cho biết về khả năng gọi ra tất cả những mẫu là âm tính, độ đặc hiệu càng cao thì khả năng gọi các mẫu âm tính càng cao và FP càng thấp so với TN, nếu như mô hình dự đoán tất cả các mẫu là âm tính thì chắc chắn mô hình đã tìm được ra hết các mẫu âm tính, độ đặc hiệu lúc này là 100\% nhưng sẽ có FN cao do các mẫu dương tính cũng được dự đoán là âm tính.
\[
    \text{Spe} = \frac{TN}{TN+FP}
\]

\par Độ nhạy và độ tụ có mối quan hệ nghịch biến, khi độ nhạy tăng thì độ tụ giảm và ngược lại. Trong thực tế ta mong muốn cả độ nhạy và độ tụ đều cao. Điểm F1 là độ đo hài hòa giữa độ tụ và độ nhạy, là trung bình điều hòa của hai độ đo này. Điểm F1 sẽ bị nghiêng hẳn về phía độ đo nào thấp hơn, chứ không phải ở giữa hai độ đo như trung bình cộng hay trung bình nhân. Điểm F1 là độ đo không phụ thuộc vào TP như độ tụ hoặc độ nhạy, là cân bằng phạt của FN và FP, độ đo này càng cao thì lượng FN và FP càng thấp. Khi điểm F1 thấp, ta sẽ không biết rõ chính xác là do độ tụ hay độ nhạy kéo xuống. Điểm F1 là một độ đo tốt trong trường hợp dữ liệu mất cân bằng.

\[
    \text{F1} = \frac{2 \times Rec \times Pre}{Rec + Pre}
\]

\par Hệ số tương quan Matthew hay MCC là hệ số tương quan cho nhãn dự đoán và nhãn thực tế của các mẫu, MCC sử dụng tất cả các chỉ số trong ma trận nhầm lẫn cả TP, TN, FP, FN. Vì là hệ số tương quan nên khoảng giá trị sẽ nằm trong $[-1, 1]$, MCC bằng 1 khi khớp giữa kết quả dự đoán và nhãn thực, MCC bằng 0 khi khớp giữa kết quả dự đoán và nhãn là ngẫu nhiên và MCC bằng -1 khi không có sự khớp giữa kết quả dự đoán và nhãn. MCC có thể sử dụng trong cả trường hợp tập dữ liệu mất cân bằng và cân bằng.
\[
    \text{MCC} = \frac{TP\times TN-FP\times FN}{\sqrt{(TP+FN)(TP+FP)(TN+FP)(TN+FN)}}
\]

\par Diện tích dưới đường cong ROC hay auROC là độ đo thường được sử dụng trong các bài toán phân lớp nhị phân nhưng cho tập dữ liệu cân bằng. ROC là đường cong cho biết sự đánh đổi giữa tỷ lệ dương tính thực (true positive rate) hay độ nhạy và tỷ lệ dương tính giả (false positive rate) hay 1 - độ đặc hiệu ở các ngưỡng khác nhau cho kết quả dự đoán, đường cong có xu hướng đồng biến. AuROC là diện tích dưới đường cong ROC, là 1 con số nằm trong đoạn $[0, 1]$, giá trị càng gần 1 thì khả năng phân lớp nhị phân của mô hình càng tốt với dữ liệu cân bằng.

\par Diện tích dưới đường cong PRC hay auPRC là độ đo thường được sử dụng trong các bài toán phân lớp nhị phân nhưng cho tập dữ liệu mất cân bằng. PRC là đường cong cho biết sự đánh đổi giữa độ tụ và độ nhạy ở các ngưỡng khác nhau cho kết quả dự đoán, đường cong có xu hướng nghịch biến. AuPRC là diện tích dưới đường cong PRC, là 1 con số nằm trong đoạn $[0, 1]$, giá trị càng gần 1 thì khả năng phân lớp nhị phân của mô hình càng tốt với dữ liệu mất cân bằng.


\subsection{Tổng quan về dự đoán tương tác protein-protein nhị phân}
\subsubsection{Giới thiệu về các bài toán về dự đoán tương tác protein-protein tổng quát và nhị phân}
\par Dự đoán tương tác protein-protein là một bài toán lớn và tổng quát bao gồm nhiều bài toán nhỏ khai thác các khía canh khác nhau của tương tác protein-protein như tương tác nhị phân, loại tương tác, vị trí bám, cấu trúc và tính chất giao diện, cấu trúc phức hệ tương tác, ái lực của phức hệ tương tác. Với các bài toán khác nhau sẽ có các chiến lược phát triển mô hình thuật toán khác nhau để giải quyết (Hình \ref{fig:ppi-prediction-models}). Bài toán dự đoán PPI theo cặp hay nhị phân mục đích để xác định hai protein nào đó có tương tác hay không bao gồm các phương pháp tiếp cận dựa trên học máy, khai phá dữ liệu văn bản, tìm kiếm tương tác bảo thủ, dung hợp gen hoặc miền, đồng biểu hiện gen . Bài toán dự đoán vị trí bám để tìm hiểu vùng nào trên bề mặt protein được sử dụng để liên kết bao gồm dự đoán mảng bề mặt bám (binding surface patch) và tìm kiếm mô-típ. Bài toán dự đoán quá trình lắp ráp phức hệ protein để tìm hiểu cách các protein tương tác và tạo thành một phức hệ dựa trên phương pháp dự đoán dựa trên docking và dự đoán trên khuôn mẫu (template-based prediction). Và mỗi phương pháp này đều góp phần xây dựng một hệ tương tác hoàn chỉnh hơn.

\FloatBarrier
\begin{figure}[htp]
    \centering
    \includegraphics[width=440pt]{images/ppi-prediction-models.png}
    \caption{\textbf{Một số phương pháp tính toán dự đoán PPI chính} \cite{keskin2016predicting}}
    \label{fig:ppi-prediction-models}
\end{figure}
\FloatBarrier

\pagebreak
\par Các mô hình dự đoán PPI được phát triển dựa trên các loại thông tin đầu vào khác nhau, có thể chia ra thành hai loại chính \cite{hu2021survey} là dựa trên mạng lưới tương tác và dựa trên sự kết hợp giữa thông tin tương tác protein-protein và thông tin sinh học liên quan protein như thông tin trình tự, thông tin cấu trúc, thông tin genomics, thông tin bản thể học gen hay GO (\textit{gene ontology}) (Hinh \ref{fig:input-ppi-prediction}). 

\begin{figure}[htp]
    \centering
    \includegraphics[width=460pt]{images/input-ppi-prediction.png}
    \caption{\textbf{Tri thức sinh học sử dụng bởi các mô hình tính toán dự đoán PPI} \cite{hu2021survey}}
    \label{fig:input-ppi-prediction}
\end{figure}

\subsubsection*{Dựa trên mạng lưới tương tác}
\par Các mạng lưới tương tác protein-protein được xây dựng bởi dữ liệu của các cặp tương tác protein-protein, chúng cho biết các đặc điểm về các quá trình, con đường chuyển hóa, trao đổi chất, điều hóa quan trọng trong sinh học. Trong mạng tương tác, hai protein có nhiều khả năng tương tác với nhau hơn nếu chúng có nhiều đối tác tương tác chung hơn, điều này có thể được giải thích trực quan bởi số lượng các đỉnh lân cận chung, từ đó cung cấp bằng chứng nhất định để dự đoán khả năng tương tác. Về các phương pháp dự đoán PPI dựa trên thông tin mạng lưới có thể kể đến một số thuật toán sau. Thuật toán L3 \cite{kovacs2019network} khai thác giả sử hai protein tương tác với nhau nếu một trong số chúng giống với các đối tác của protein còn lại, chứ không phải dựa vào sự tương đồng với protein còn lại, tuy nhiên hạn chế trong việc dự đoán tương tác các protein vị trí xa nhau và không có lân cận chung. Thuật toán SFCN \cite{li2018similarity} xác định chính xác tất cả các lân cận chung tương lai dựa trên những lân cận chung hiện tại trong mạng lưới tương tác với trong mạng PPI. Thuật toán SpectralLink \cite{symeonidis2013biological} khai thác mối quan hệ tôpô (topological affinity) bằng phương pháp phân cụm phổ nhiều chiều (multi-way spectral clustering) với ưu điểm là làm việc với cấu trúc mạng lưới toàn cục của mạng lưới PPI và nhược điểm là dễ dàng bỏ qua các tính chất về cấu trúc phức tạp trong mạng lưới. Thuật toán IRAP \cite{chen2005discovering} đánh giá độ tin cậy của các tương tác protein bằng cách xem xét đường đi thay thế của PPI trong mạng PPI cơ bản, làm việc với toàn bộ mạng PPI thay vì các lân cận cục bộ. Thuật toán của Yang và cộng sự năm 2010 \cite{you2010using} sử dụng kỹ thuật nhúng đa tạp dựa trên thông tin cấu tôpô của mạng PPI, có thể làm việc trên một mạng PPI thưa chỉ với thông tin tôpô của mạng, số chiều của nhúng đa tạp ảnh hưởng đến độ chính xác kết quả dự đoán PPI. 


\subsubsection*{Dựa trên kết hợp thông tin tương tác và thông tin sinh học protein}
\par Trình tự protein bao gồm các axit amin đóng một vai trò quan trọng trong việc xác định cấu trúc bậc cao và đặc điểm sinh học của protein đó. Một nghiên cứu quan trọng trong sinh học cấu trúc đã chỉ ra tri thức được trích xuất từ trình tự protein có thể đủ để ước lượng khả năng tương tác giữa các protein theo cặp cũng như cấu trúc không gian của protein \cite{anfinsen1973principles}. Thông tin về trình tự protein hiện có rất nhiều do thành công của các công nghệ giải trình tự protein, dữ liệu trình tự có thể được lấy từ các CSDL như \cite{uniprot2021uniprot}, PIR \cite{barker1999pir}. Các phương pháp dự đoán PPI dựa trên thông tin về trình tự có thể kể đến một số thuật toán kinh điển sau. Thuật toán của Bock và cộng sự \cite{bock2001predicting} kết hợp thông tin trình tự và đặc trưng hóa lý của protein sử dụng thuật toán máy vector hỗ trợ để đưa ra dự đoán PPI, đây là nghiên cứu đầu tiên cung cấp một phân tích lý thuyết và có hệ thống về cách dự đoán PPI bằng học máy dựa trên trình tự của protein, tuy nhiên khả năng mở rộng chưa cao sang các loài sinh vật khác. Phương pháp CoFex \cite{hu2016extracting} dự đoán PPI dựa trên trình tự protein và trích xuất đặc trưng từ cả hai trình tự trong một cặp protein thay vì một protein đơn lẻ. VLASPD \cite{hu2015discovering} tính đến các phân đoạn có độ dài thay đổi của trình tự protein để dự đoán PPI tuy nhiên các khuôn mẫu bất biến trình tự khiến mô hình gặp khó khăn khi đưa ra dự đoán tương tác.

\par Ngoài cấu trúc cơ bản bậc một của protein dưới dạng trình tự, protein còn có ba cấu trúc bậc cao khác bao gồm cấu trúc bậc hai, bậc ba và bậc bốn. Cấu trúc bậc hai của protein tồn tại dưới dạng cục bộ là các chuỗi xoắn $\alpha$ và tấm $\beta$, các thuật toán dự đoán hiện tại phát triển các mô hình tính toán khác nhau để xác định các cấu trúc không gian cụ thể thường xuất hiện trên các vùng mô-típ tương tác protein-protein. Trong khi cấu trúc bậc ba và bậc bốn có dạng không gian ba chiều phức tạp, các thuật toán dự đoán tập trung vào các vùng không gian tương thích tương tác dựa trên các mô phỏng nguyên tử và phân tử. Thông tin về cấu trúc bậc cao của protein hơn có thể được lấy từ các cơ sở dữ liệu cấu trúc protein như PDB \cite{wwpdb2019protein} và SCOP \cite{andreeva2004scop}. Các phương pháp dự đoán PPI dựa trên thông tin về cấu trúc có thể kể đến một số thuật toán kinh điển sau. Thuật toán PredPPI \cite{zhang2012structure} áp dụng thống kê Bayes với thông tin của các tương tác cấu trúc và phi cấu trúc để dự đoán PPI có khả năng xác định các PPI có vai trò quan trọng đáng kể trong sinh học bằng cách sử dụng thông tin cấu trúc ba chiều tuy nhiên gặp phải hạn chế là không có khả năng dự đoán PPI cho các protein chưa có cấu trúc 3D xác định bằng thực nghiệm. Thuật toán InterPred \cite{mirabello2017interpred} kết hợp so sánh cấu trúc lớn và việc ghép nối phân tử với bộ phân lớp rừng ngẫu nhiên. Thuật toán MEGADOCK \cite{ohue2014megadock} là mô hình dựa trên docking, có thể lấy mẫu một số lượng cực lớn các protein tương tác với tốc độ tương đối cao sử dụng độ tương đồng decoy. 


\par Do sự phát triển của công nghệ giải trình tự toàn hệ gen, các mô hình dự đoán PPI dựa trên hệ gen thường xây dựng trên các quan sát về tiến hóa hệ gen, đặc biệt là sự tiến hóa của các gen quy định các protein tương tác với nhau liên quan đến dung hợp gen, tính bảo thủ của các cặp gen và hồ sơ phát sinh chủng loại của gen. Ví dụ, dung hợp gen được sử dụng để dự đoán các protein tương tác bằng cách quan sát rằng một phần của protein đơn miền ở một sinh vật có thể được hợp nhất thành protein đa miền ở một số sinh vật khác; các mô hình sử dụng đặc điểm phát sinh chủng loại được phát triển dựa trên giả thuyết rằng các cây phát sinh chủng loại tương ứng của các protein tương tác giống nhau hơn do quá trình đồng tiến hóa của các gen quy định các protein tương tác. Các phương pháp dựa trên thông tin về genomics có thể kể đến một số thuật toán kinh điển sau. Thuật toán của Enright và cộng sự \cite{enright1999protein} xác định các sự kiện dung hợp gen dựa trên so sánh trình tự để dự đoán PPI nhưng không xác định được các tương tác không là hệ quả của dung hợp gen. Thuật toán của Dandekar và cộng sự \cite{dandekar1998conservation} nhận ra rằng các protein được mã hóa bởi các cặp gen bảo thủ dường như tương tác về mặt vật lý. Thuật toán của Pellegriniet và cộng sự \cite{pellegrini1999assigning} phát triển phương pháp lập hồ sơ phát sinh chủng loại để dự đoán PPI nhưng trở nên kém hiệu quả số lượng mẫu trong các hồ sơ tăng theo hàm số mũ.


\par GO là một hệ thống ngôn ngữ được thiết lập để mô tả chú giải của gen và sản phẩm của chúng bao gồm ba lớp thông tin là thành phần tế bào, chức năng phân tử và quá trình sinh học. Vì các protein có chức năng tương tự có nhiều khả năng tương tác với nhau hơn, sự giống nhau về ngữ nghĩa trong GO giữa các cặp protein có thể là một dấu hiệu cho sự giống nhau về chức năng của các protein, do đó chỉ ra khả năng tương tác giữa chúng. Dữ liệu GO có thể được tải xuống từ cơ sở dữ liệu GO \cite{gene2017expansion} và QuickGO \cite{binns2009quickgo}. Các phương pháp dựa trên thông tin bản thể học gen hay GO có thể kể đến một số thuật toán kinh điển sau. Thuật toán của Bandyopadhyay và cộng sự, 2016 \cite{bandyopadhyay2016new} sử dụng một tập hợp các đặc trưng mới để đại diện cho một cặp protein dựa trên thuật ngữ GO chú giải cho thấy hiệu suất tốt hơn các đặc trưng đếm phổ dựa trên trình tự nhưng bỏ qua cấu trúc đồ thị không chu trình có hướng trong bản thể thể học gen. Thuật toán của Jain và cộng sự, 2010 \cite{jain2010improved} dự đoán PPI dựa trên sự tương đồng của các thuật ngữ GO và nó cũng xem xét độ sâu biểu diễn kiến thức sinh học không đồng đều trong các nhánh khác nhau của đồ thị GO tuy nhiên độ đo tương đồng này đôi khi được ước lượng cao trong một số tình huống.




\subsubsection{Các nghiên cứu dự đoán tương tác protein-protein nhị phân}
\par Bài toán dự đoán PPI nhị phân là bài toán cơ bản nhất trong dự đoán PPI và có một lịch sử phát triển các mô hình thuật toán lâu dài nhất. Dự đoán PPI nhị phân giúp bổ sung các dữ liệu về tương tác theo cặp protein từ đó xây dựng các hệ thống mạng lưới tương tác, phân tích các con đường, quá trình sinh học cơ bản. Trong khóa luận này, tôi tập trung vào bài toán dự đoán tương tác protein-protein nhị phân.

\par  Bài toán dự đoán PPI nhị phân bắt đầu được quan tâm từ những năm 1998 và kéo dài cho tới ngày nay. Những nghiên cứu đầu tiên của Dandekar và cộng sự, 1998; Pellegrini và cộng sự, 1999 dự đoán PPI nhị phân phân dựa trên thông tin hệ gen, chẳng hạn như hồ sơ phát sinh chủng loài, dự đoán tương tác bằng cách liệt kê các khuôn mẫu có mặt hoặc không có mặt trong một gen của một tập hợp các hệ gen \cite{dandekar1998conservation} \cite{pellegrini1999assigning}. Hạn chế chính của các phương pháp này là chúng chỉ có thể được áp dụng cho các hệ gen được giải trình tự hoàn toàn, đây là điều kiện tiên quyết để loại trừ sự vắng mặt của một gen nhất định và không thể sử dụng được với các protein quan trọng phổ biến với các loài sinh vật. Dự đoán tương tác nhị phân dưới dạng mối quan hệ chức năng của hai protein do hai gen gần nhau mã hóa là chiến lược khá phổ biến giai đoạn đầu, phương pháp này áp dụng trực tiếp chỉ với vi khuẩn vì trật tự hệ gen của chúng phản ánh được mối quan hệ này \cite{wojcik2002prediction}. Park và cộng sự, 2001 \cite{park2001mapping} đã cố gắng tìm các đối tác tương tác với protein bằng cách xem các tương tác giữa các miền protein bằng cách phân tích tương tác giữa các họ cấu trúc của các miền liên quan về mặt tiến hóa. Sprinzak và Margalit \cite{sprinzak2001correlated} đưa ra một phương pháp dự đoán tương tác gián tiếp khác, tìm ra đặc điểm chữ ký liên quan đến các tương tác hơn là thông tin tương tác miền từ các trình tự protein thông qua phân loại protein. Tuy nhiên, các phương pháp này không phổ biến, bởi vì độ chính xác và độ tin cậy của các phương pháp này phụ thuộc vào thông tin về tương đồng của protein hoặc dấu hiệu tương tác của các đối tác protein. 

\par Các mô hình dự đoán PPI nhị phân được phát triển thời gian sau dựa trên các thuật toán học máy truyền thống và đạt được hiệu quả độ chính xác cao hơn các mô hình được phát triển trước đó, một số mô hình tiêu biểu như như cây quyết định \cite{browne2007supervised}, Bayes ngây thơ \cite{lin2013heterogeneous}, rừng ngẫu nhiên \cite{you2015predicting} và máy vectơ hỗ trợ (SVM) \cite{dohkan2006improving} \cite{you2015detecting} \cite{guo2010pred_ppi}. Các phương pháp này sử dụng các đặc trưng hóa lý trích xuất và tóm tắt thông tin trình tự protein từ các bộ mô tả đặc trưng trình tự như bộ mô tả đặc trưng tự hiệp phương sai hay AC (autocovariance) \cite{guo2008using}, bộ mô tả bộ ba liên tiếp hay CT (conjoint triad) \cite{you2013prediction}, bộ mô tả liên tục và không liên tục hay MCD (multi-scale continuous and discontinuous) \cite{you2013prediction}. Trong thời gian những năm 2004-2016, ngoài các phương pháp học máy được phát triển kể trên, để biết được chất lượng dự đoán cao hay thấp và so sánh các mô hình dự đoán với nhau, các nhà nghiên cứu xây dựng các tập dữ liệu PPI chuẩn bao gồm các cặp tương tác được lấy từ các cơ sở dữ liệu tương tác thực nghiệm, các cặp không tương tác được tạo ra theo nhiều chiến lựợc khác nhau \cite{ben2006choosing}. Một số tập dữ liệu PPI chuẩn tiêu biểu như tập dữ liệu nấm men Guo (2008) \cite{guo2008using}, tập dữ liệu người Pan (2010) \cite{pan2010large}, tập dữ liệu vi khuẩn \textit{H.pylori} Martin (2005) \cite{martin2005predicting}.

\par Giai đoạn sau bắt đầu từ năm 2017 là thời kì lên ngôi các mô hình học sâu cho dự đoán PPI nhị phân do sự phát triển vượt bậc của học sâu bắt đầu từ năm 2012 với nghiên cứu về mô hình AlexNet chiến thắng trong cuộc thi phân loại ảnh ImageNet \cite{krizhevsky2012imagenet}. Các mô hình học sâu này tỏ ra ưu thế vượt trội hơn so với mô hình học máy truyền thống với hiệu quả học tốt hơn trên dữ liệu càng lớn và khả năng trích xuất đặc trưng và học biểu diễn phân tầng từ dữ liệu thô qua các tầng trong kiến trúc mạng \cite{goodfellow2016deep}. Các mô hình học máy và học sâu này chủ yếu khai phá thông tin và nhận dạng mẫu trên dữ liệu trình tự protein nên các mô hình này còn gọi là mô hình dựa trên trình tự (sequence-based model). Nghiên cứu đầu tiên phát triên mô hình học sâu dựa trên trình tự cho bài toán dự đoán PPI nhị phân là bộ mã hóa tự động xếp chồng hay SAE (stacked autoencoder) của Sun và cộng sự, 2017 \cite{sun2017sequence}, mô hình này đạt hiệu quả hứa hẹn trên tập dữ liệu người Pan (2010) lên đến 97\%. Nghiên cứu cùng năm của Du và cộng sự sau đó phát triển một mô hình mạng nơ-ron sâu DeepPPI để trích xuất các đặc trưng phân biệt bậc cao từ các bộ mô tả protein \cite{du2017deepppi}, mô hình đạt được độ chính xác 92.5\% trên tập dữ liệu nấm men Guo (2008). Hai mô hình này dựa trên mạng nơ-ron sâu cơ bản, chưa trích xuất được các thông tin không gian hoặc thời gian, mang tính cục bộ hoặc toàn cục của trình tự protein, do đó có một nhu cầu phát triển các kiến trúc học toàn diện và hiệu quả hơn. 


\par Hashemifar và cộng sự năm 2018 \cite{hashemifar2018predicting} đã phát triển mô hình DPPI, sử dụng kiến trúc sâu dựa trên mạng tích chập song sinh, tập trung vào việc nắm bắt các đặc điểm cục bộ từ các cặp hồ sơ trình tự protein chạy PSI-BLAST với cơ sở dữ liệu trình tự. Mô hình DPPI đạt độ chính xác 94.5\% trên tập dữ liệu chuẩn nấm men Guo (2008) nhưng yêu cầu rất nhiều thời gian chạy PSI-BLAST. Một năm sau đó, mô hình PIPR của Chen và cộng sự năm 2019 \cite{chen2019multifaceted}, mô hình sử dụng các khối tích chập hồi cấp hay RCNN kết hợp sử dụng mạng song sinh phần dư (residual siamese) với đầu vào là vector nhúng axit amin skip-gram và one-hot đã khai thác tốt hơn các đặc điểm cục bộ cũng như toàn cục của trình tự axit amin, đạt được độ chính xác 97\% trên tập dữ liệu Guo (2008). Mô hình PIPR trên là mô hình tiêu chuẩn, thường được so sánh nhất với các mô hình giai đoạn sau. Có một số thiết kế mô hình nặng nhiều về tổng hợp các đặc trưng trong các bộ mô tả đặc trưng sau đó áp dụng thuật toán học máy (NMBA+Moran+Geary+LD+CT)-LGBM như của Chen và cộng sự năm 2019 \cite{chen2019lightgbm}, hoặc (EGBW+AC+PAAC)-SVM như của Tian và cộng sự năm 2019 \cite{tian2019predicting}. Các ý tưởng tổng hợp này không thực sự tốt, còn tương đối đơn giản và phụ thuộc phần nhiều vào các bộ mô tả. 


\par Các mô hình phát triển sau năm 2020 không có nhiều khởi sắc và đang dần đi đến giai đoạn bão hòa, các ý tưởng về thiết kế mô hình mạng nơ-ron chủ yếu dựa trên mạng tích chập và hồi cấp giống như mô hình PIPR hoặc DPPI. Mô hình D-SCRIPT \cite{sledzieski2021d} của Sledzieski và cộng sự năm 2021 có triển vọng lớn vì sử dụng các vector nhúng axit amin theo ngữ cảnh tạo ra từ mô hình ngôn ngữ protein đã được tiền huấn luyện trên một tập dữ liệu trình tự khổng lồ. Mô hình D-SCRIPT tập trung vào khai thác bản đồ tiếp xúc giữa hai trình tự từ đó mà có khả năng mở rộng dự đoán cho nhiều loài sinh vật khác nhau. Khai thác bản đồ tiếp xúc liên protein hay trong protein đang là một hướng đang nhận được sự quan tâm gần đây với các mô hình dự đoán liên quan đến cấu trúc và tương tác. Mô hình FSNN-LGBM được phát triển vào nửa cuối năm 2021 bởi Mahapatra và cộng sự \cite{mahapatra2021improved} là một mô hình lai giữa một mạng nơ-ron mở rộng liên kết (một cách thiết kế khá cũ) và thuật toán LGBM sử dụng vector đặc trưng từ bộ mô tả CT và PAAC, mô hình tương đối đơn giản nhưng đạt hiệu quả rất cao trên các tập dữ liệu tiêu chuẩn, với độ chính xác 98.5\% trên tập Guo.

% \begin{figure}[htp]
%     \centering
%     \includegraphics[width=450pt]{images/DPPI.png}
%     \caption{\textbf{Kiến trúc mô hình DPPI} \cite{hashemifar2018predicting}}
%     \label{fig:DPPI}
% \end{figure}

% \begin{figure}[htp]
%     \centering
%     \includegraphics[width=400pt]{images/PIPR.png}
%     \caption{\textbf{Kiến trúc mô hình PIPR} \cite{chen2019multifaceted}}
%     \label{fig:PIPR}
% \end{figure}


% \FloatBarrier
% \begin{figure}[htp]
%     \centering
%     \includegraphics[width=380pt]{images/FSNN-LGBM.png}
%     \caption{\textbf{Kiến trúc mô hình FSNN-LGBM} \cite{mahapatra2021improved}}
%     \label{fig:FSNN-LGBM}
% \end{figure}
% \FloatBarrier


% \begin{figure}[htp]
%     \centering
%     \includegraphics[width=490pt]{images/D-SCRIPT.png}
%     \caption{\textbf{Kiến trúc mô hình D-SCRIPT} \cite{sledzieski2021d}}
%     \label{fig:D-SCRIPT}
% \end{figure}


\newpage % tạo section mới là phải sang trang mới
\section{ĐỐI TƯỢNG VÀ PHƯƠNG PHÁP NGHIÊN CỨU}
\subsection{Ý tưởng thiết kế mô hình}
\par Mô hình được phát triển trong khóa luận này được truyền cảm hứng từ các nghiên cứu trước đây về dự đoán tương tác protein-protein nhị phân, phân lớp cặp câu văn, phân lớp văn bản, phân lớp quan hệ. Để tiếp cận đối tượng dạng cặp protein-protein trong dự đoán tương tác, các nghiên cứu trước đây thường sử dụng mạng song sinh (Siamese) trong kiến trúc của mình với mục đích học được quan hệ lẫn nhau trong cặp \cite{hashemifar2018predicting} \cite{chen2019multifaceted} \cite{mahapatra2021improved} \cite{li2018deep}, hiệu quả sử dụng mạng đôi (giống với mạng song sinh nhưng không chia sẻ trọng số) cũng tốt hơn so với sử dụng mạng đơn với đầu vào gộp \cite{du2017deepppi}. Như vậy trong kiến trúc mô hình sẽ nên tổ chức theo lối thiêt kế mạng song sinh.

\par Các mô hình được phát triển cho dự đoán PPI nhị phân thường sử dụng mạng tích chập trong kiến trúc \cite{chen2019multifaceted} \cite{hashemifar2018predicting} \cite{sledzieski2021d} \cite{lei2021deep} để học các thông tin về không gian cục bộ của các bộ của các axit amin với kích thước dao động từ 2-6. Trong lĩnh vực rộng hơn là phân lớp văn bản cũng rất gần với phân lớp cặp văn bản là lĩnh vực sát nhất với phân lớp tương tác protein-protein, nghiên cứu kinh điên và đầu tiên cũng sử dụng mạng tích chập \cite{kim2014convolutional}, nghiên cứu này cũng sử dụng nhiều bộ lọc kích thước khác nhau nhằm trích xuất thông tin của các bộ axit amin khác nhau sau đó sử dụng gộp cực đại toàn cục (global max pooling) để thu được biểu diễn vector, từ đó giảm kích thước dữ liệu tiết kiệm chi phí tính toán nhưng vẫn giữ được đặc trưng của dữ liệu. Điều đó gợi ý về nên sử dụng mang tích chập và nên sử dụng gộp cực đại toàn cục. 

\par Một số hướng nghiên cứu trước đây cho dự đoán tương tác PPI \cite{chen2019multifaceted} \cite{li2018deep} và các nghiên cứu liên quan về phân lớp văn bản \cite{zhou2015c} \cite{zhou2018nlp} \cite{wang2018attention} có sử dụng mạng hồi cấp do khả năng xử lý rất tốt với dữ liệu dạng chuỗi tuy nhiên mạng hồi cấp thường thích hợp hơn với các câu văn, chuỗi kí tự có độ dài trung bình hoặc ngắn dưới 200, trong khi đó protein là những trình tự dài trung bình từ 200-1000 axit amin. Khi so sánh kiến trúc có CNN, RNN hoặc RCNN trong thử nghiệm cắt bỏ thành phần kiến trúc \cite{chen2019multifaceted}, tác giả nhận thấy độ chính xác trên tác vụ dự đoán PPI nhị phân của RCNN và CNN không chênh lệch nhau quá nhiều và hơn RNN đáng kể, chứng tỏ CNN chứ không phải RNN là thành phần cần thiết cho bài toán này.

\par Việc kết hợp thuật toán học máy và học sâu hiện tại vẫn là một điều chưa thu hút sự quan tâm nghiên cứu nhiều, mới chỉ có một số ít các nghiên cứu sử dụng chiến lược này \cite{devan2020efficient} \cite{thongsuwan2021convxgb} \cite{mekruksavanich2022lstm}, ý tưởng  sử dụng học sâu tạo ra dạng biểu diễn tốt và để thuật toán học máy phân lớp dựa trên biểu diễn tốt rất thú vị và đã được thấy ở một trong những mô hình tốt nhất hiện nay trong dự đoán PPI là FSNN-LGBM \cite{mahapatra2021improved}. Điều này gợi ý về việc xây dựng một mô hình lai giữa học máy và học sâu.

\par Vẫn còn một số đề xuất thiết kế mô hình học sâu khác cho tác vụ dự đoán PPI nhị phân, chúng có thể xoay quanh việc sử dụng embedding, tổng thể kiến trúc mô hình và thành phần trong kiến trúc. Điểm khó nhất của học sâu chính là tìm kiếm trong không gian cao chiều các siêu tham số khiến cho mô hình tốt hơn, điều này thường được thực hiện bằng tham khảo lại các mẫu kiến trúc, tham số từ các nghiên cứu trước đây hoặc các nghiên cứu tương tự hoặc gần ngành và thử nghiệm trên dữ liệu của mình, để xem kiến trúc nào sẽ mang lại hiệu quả. Sẽ không chỉ tồn tại một cấu hình kiến trúc rất tốt mà còn nhiều cấu hình đạt được hiệu quả tương đương, chúng khác nhau kể cả những chi tiêt rất nhỏ trong kiến trúc mà ta khó có thể biết được nếu không thử nghiệm. Khóa luận này đề xuất kiến trúc mô hình MCAPSL, kiến trúc đạt được hiệu quả tốt hơn so với các mô hình được so sánh nhưng chưa hẳn là tốt nhất so với các mô hình trên thế giới hiện tại, chi tiết về kiên trúc sẽ được đề cập ở phần kết quả.


\subsection{Quy trình đánh giá chất lượng mô hình}

\par Trong các nghiên cứu về học máy, để đánh giá chất lượng của các mô hình học, ta thường đánh giá về khả năng học trên tập dữ liệu huấn luyện tiêu chuẩn và khả năng tổng quát-dự đoán trên các tập kiểm tra ngoại. Cũng giống như các nghiên cứu khác về học máy, trong khóa luận này, tôi so sánh và đánh giá các mô hình dự đoán PPI nhị phân trên tác vụ học nội tại trên tập dữ liệu huấn luyện và kiểm định, sau đó là dự đoán các dữ liệu mới trên các tập dữ liệu kiểm tra ngoại để quan sát về tính tổng quát hóa của các mô hình. Một quy trình đánh giá chất lượng mô hình học luôn có bốn thành phần quan tâm, đó là cách thức đánh giá (đánh giá học nội tại hay tổng quát hóa), tập dữ liệu sử dụng (tập huấn luyện, tập kiểm định, và tập kiểm tra), các mô hình sử dụng, các độ đo chất lượng (tùy bài toán phân lớp hay hồi quy, dữ liệu cân bằng hay mất cân bằng).

\subsubsection{Tác vụ học trên tập dữ liệu nội tại}

\par Học trên tập dữ liệu nội tại hay học nội tại là tác vụ đánh giá việc học trên một tập dữ liệu. Tác vụ này thường được thực hiện bằng cách sử dụng kiểm định chéo k-fold trên tập dữ liệu, ta sẽ thu được các cặp (tập huấn luyện, tập kiểm định) khi phân hoạch tập dữ liệu đó k lần không gối nhau. Tác vụ này nhằm đánh giá khả năng học trên tập dữ liệu huấn luyện và mở rộng ra tập kiểm định có phân bố dữ liệu tương đương. Tuy nhiên phụ thuộc vào kích thước và chất lượng dữ liệu của tập huấn luyện mà ảnh hưởng nhiều hay ít đến chất lượng đánh giá trên tập kiểm định. Do đó việc khảo sát chất lượng học trên các tập dữ liệu nội tại kích thước khác nhau là điều cần thiết. 

\par Quy trình đánh giá học nội tại (Hình \ref{fig:intra}) bao gồm bốn thành phần:
\begin{itemize}
    \item \textbf{Cách thức đánh giá}: kiểm định chéo 5-fold cho mỗi mô hình trên cả ba tập dữ liệu và lặp lại 5 lần.
    \item \textbf{Các tập dữ liệu sử dụng}: tập dữ liệu Martin \textit{H.pylori} (2005) \cite{martin2005predicting} , tập dữ liệu Guo nấm men (2008) \cite{guo2008using}, tập dữ liệu Pan người (2010) \cite{pan2010large}.
    \item \textbf{Các mô hình so sánh}: D-SCRIPT \cite{sledzieski2021d}, PIPR \cite{chen2019multifaceted},FSNN-LGBM \cite{mahapatra2021improved}, và MCAPSL.
    \item \textbf{Các độ đo sử dụng}: độ chính xác, độ tụ, độ nhạy, độ đặc hiệu, điểm F1, diện tích dưới đường cong ROC, diện tích dưới đường cong PRC, hệ số tương quan Matthew vì đang làm việc trên tập dữ liệu cân bằng nên mọi độ đo trong bài toán phân lớp nhị phân đều có thể sử dụng nhưng quan trọng vẫn là độ chính xác.
\end{itemize}


\FloatBarrier
\begin{figure}[htp]
    \centering
    \includegraphics[width=420pt]{images/intra.png}
    \caption{\textbf{Quy trình đánh giá tác vụ học nội tại}}
    \label{fig:intra}
\end{figure}
\FloatBarrier




\subsubsection{Tác vụ dự đoán trên tập dữ liệu kiểm tra ngoại}

\par Dự đoán trên tập dữ liệu kiểm tra ngoại là tác vụ học trên tập huấn luyện là các tập dữ liệu nội tại và đánh giá trên các tập dữ liệu kiểm tra ngoại. Tác vụ này kiểm tra trên khả năng tổng quát hóa của mô hình trên những dữ liệu chưa nhìn thấy. Thông thường chất lượng trên tập kiểm tra ngoại sẽ kém hơn nhiều so với chất lượng trên tập huấn luyện, một mô hình có tính tổng quát tốt sẽ rút ngắn được khoảng cách này.

\par Quy trình đánh giá khả năng tổng quát hóa dự đoán PPI (Hình \ref{fig:intra}) bao gồm bốn thành phần:
\begin{itemize}
    \item \textbf{Cách thức đánh giá}: huấn luyện các mô hinh PIPR, FSNN-LGBM MCAPSL trên tập dữ liệu cân bằng Pan người (2010) và tập dữ liệu mất cân bằng Sledzieski người (2021) rồi đánh giá trên các tập dữ liệu kiểm tra bao gồm tập dữ liệu Li người (2018) nhằm kiểm tra khả năng mở rộng trên cùng loài, tập dữ liệu chéo loài Sledzieski (2021) nhằm kiểm tra khả năng mở rộng trên các loài sinh vật khác, tập dữ liệu liên loài Yang (2021) nhhằm kiểm tra khả năng mở rộng của protein trên người với các loài khác. Đối với mô hình D-SCRIPT, ta chỉ cần nạp lại bộ trọng số đã được huấn luyện trên tập Sledziski người (2021) và đánh giá trên các tập kiểm tra vừa nhắc tới ở trên, mô hình D-SCRIPT sẽ không huấn luyện trên tập Pan người (2010) nên sẽ không có kết quả với các tập kiểm tra.
    \item \textbf{Các tập dữ liệu sử dụng}:  tập huấn luyện bao gồm tập dữ liệu Pan người (2010) \cite{pan2010large}, tập dữ liệu Sledzieski người (2021) \cite{sledzieski2021d}. Tập kiểm tra là các tập dữ liệu mất cân bằng bao gồm các tập kiểm tra trên người của Li (2018) \cite{li2018deep}; các tập chéo loài Sledzieski (2021) \cite{sledzieski2021d} bao gồm ruồi giấm, giun tròn, \textit{E.coli}, chuột nhà, nấm men; tập dữ liệu liên loài gồm tương tác giữa người và 1 số loài virus Yang (2021) \cite{yang2021transfer} bao gồm virus Dengue, virus Hepatitis, virus Zika, virus SARS-CoV-2, virus HIV, virus Papilloma, virus Herpes.
    \item \textbf{Các mô hình so sánh}: D-SCRIPT \cite{sledzieski2021d}, PIPR \cite{chen2019multifaceted}, FSNN-LGBM \cite{mahapatra2021improved} và MCAPSL
    \item \textbf{Các độ đo sử dụng}: độ tụ, độ nhạy, điểm F1 vì đây là các độ đo tốt trên tập dữ liệu mất cân bằng.
\end{itemize}


\FloatBarrier
\begin{figure}[htp]
    \centering
    \includegraphics[width=420pt]{images/evaluation2.png}
    \caption{\textbf{Quy trình đánh giá tác vụ tổng quát hóa trên tập kiểm tra}}
    \label{fig:external}
\end{figure}
\FloatBarrier

\subsection{Các tập dữ liệu sử dụng}
Các tập dữ liệu có nguồn gốc từ các cơ sở dữ liệu thực nghiệm, đã được các nhà khoa học tuyển chọn và kiểm tra lại. Các tập dữ liệu này đã được xây dựng trong các nghiên cứu trước đây và được sử dụng nhiều trong so sánh các mô hình dự đoán PPI nhị phân về sau. Trong khóa luận này, tôi thu thập lại các tập dữ liệu công khai từ các nghiên cứu trước, xử lý để thu được định dạng chuẩn hai tệp tsv gồm có tệp tương tác chứa các bản ghi gồm mã của protein 1, mã của protein 2 và nhãn của tương tác; tệp từ điển chứa mã của protein và trình tự tương ứng.
\subsubsection{Tập dữ liệu học nội tại}
Thông tin về các tập dữ liệu nội tại được chuẩn bị tóm tắt ở Bảng \ref{table:intra-datasets}

\begin{table}[htp]
\caption{\textbf{Các tập dữ liệu học nội tại} }
\label{table:intra-datasets}
\begin{tabularx}{\textwidth}{Yccc}
    \specialrule{1.5pt}{1pt}{1pt}
    \textbf{Tập dữ liệu} & \textbf{Số cặp dương tính} & \textbf{Số cặp âm tính} & \textbf{Số trình tự} \\
    \specialrule{1.5pt}{1pt}{1pt}
    \textit{H.pylori} Martin (2005) \cite{martin2005predicting} & 1458 & 1365 & 1373\\
    Nấm men Guo (2008) \cite{guo2008using} & 5594 & 5594 & 2497\\
    Người Pan (2010) \cite{pan2010large} & 27593  & 34298 & 8347\\
    \specialrule{1.5pt}{1pt}{1pt}
\end{tabularx}
\end{table}




\subsubsection*{Tập dữ liệu \textit{H.pylori} Martin (2005)}
\par Tập dữ liệu được xây dựng bởi Martin và cộng sự năm 2005 \cite{martin2005predicting} có 2916 cặp bao gồm 1458 cặp dương tính và 1458 cặp âm tính tạo ra từ 1428 trình tự của loài vi khuẩn \textit{H.pylori}. Các cặp tương tác được lấy từ thử nghiệm sàng lọc lai hai nấm men của Rain và cộng sự, 2001 \cite{rain2001protein}, còn các cặp tương tác được lấy mẫu ngẫu nhiên hai trình tự bất kì và loại đi những bắt cặp tương tấc đã biết từ dữ liệu của Rain. Cách làm với dữ liệu âm tính này chưa thực sự được tốt, ở thời điểm đó thì đây là một cách làm tạm chấp nhận được. Về việc chuẩn bị các mẫu dữ liệu âm tính vẫn còn là một vấn đề nan giải cho tới ngày nay, việc chứng minh hai protein không tương tác thì sẽ khó hơn nhiều so với xác định cặp protein tương tác. Các cách làm xác định cặp âm tính ở các tập dữ liệu phía sau sẽ chặt chẽ và đáng tin cậy hơn.

\par Tập dữ liệu Martin được lấy từ kho lưu trữ \url{https://github.com/SatyajitECE/DNN-XGB-for-PPI-Prediction/tree/main/Dataset/Helicobacter\%20pylori}, kích thước tập dữ liệu đúng như đã được báo cáo. Tập dữ liệu ban đầu được tổ chức thành các tệp dương tính và âm tính chỉ mang các cặp trình tự, tập dữ liệu được xử lý loại bỏ các trình tự ngắn để thu được định dạng chuẩn gồm tệp tương tác có 2823 cặp (mất 93 cặp so với gốc) và tệp từ điẻn có 1373 trình tự (mất 55 so với gốc) được lưu trữ ở \url{https://github.com/anhvt00/MCAPS/tree/master/data/Golden-standard-datasets/Martin-2005}.

\subsubsection*{Tập dữ liệu nấm men Guo (2008)}
\par Tập dữ liệu được xây dựng bởi Guo và cộng sự năm 2008 \cite{guo2008using} có 11188 cặp bao gồm 5594 cặp dương tính và 5594 cặp âm tính từ 2497 trình tự protein của nấm men. Dữ liệu PPI được thu thập từ tập con chính \textit{Saccharomyces cerevisiae} của cơ sở dữ liệu DIP phiên bản DIP\_20070219. Độ tin cậy của tập con chính này được kiểm tra bằng hai phương pháp là độ tin cậy hồ sơ biểu hiệu (EPR) và phương pháp xác minh paralog (PVM) \cite{deane2002protein}. Tập dữ liệu con chính lúc đó bao gồm 5966 cặp tương tác, tiếp theo tác giả loại bỏ đi các trình tự protein có độ dài nhỏ hơn 50 do muốn có những trình tự đủ dài. Điều này dẫn tới loại bỏ đi các cặp tương tác chứa trình tự ngắn đã bị loại bỏ và thu được 5943 cặp. Để loại bỏ các cặp protein chứa các protein dư thừa do tương đồng với các trình tự khác, tác giả sử dụng phần mềm cd-hit \cite{li2006cd} để phân cụm các trình tự protein và loại bỏ đi những trình tự có độ tương đồng $\ge$ 40\%, sau cùng chỉ giữ lại các cặp tương tác của các trình tự còn lại, cuối cùng thu được 5594 cặp. Lúc này các cặp protein sẽ có độ tương đồng $<$ 40\%, việc làm này sẽ làm bộ phân lớp giảm thiên vị với những cặp trình tự tương đồng. Với cách xây dựng tập dữ liệu dương tính loại bỏ đi những trình tự protein ngắn (các trình tự ngắn thường là các mảnh đứt gãy của protein) và các cặp tương tác có độ tương đồng không cao, chiến lược của Guo và cộng sự mở đường cho việc xây dựng các tập dữ liệu dương tính chặt chẽ ở các nghiên cứu phía sau.

\par Về dữ liệu âm tính, nghiên cứu của Guo có sử dụng các chiến lược xây dựng khác nhau. Các cặp âm tính có thể được tạo ra bằng ghép ngẫu nhiên các protein từ cặp dương tính và loại đi cặp dương tính, chiến lược này khá giống so với cách làm của Martin và cộng sự. Chiến lược thứ hai dựa trên giả sử các protein ở các bào quan khác nhau thì không tương tác với nhau, các protein của các cặp dương tính sẽ được lấy thông tin về vị trí trong tế bào từ cơ sở dữ liệu Swiss-Prot, và phân thành các khu vực khác nhau (tế bào chất, nhân, ty thể, lưới nội chất, bộ máy golgi, peroxisome, không bào), cặp âm tính được tạo ra bằng cách ghép cặp một protein từ một khu vực với một protein từ một khu vực khác. Chiến lược thứ ba dựa trên giả sử là nếu biến đổi 1 protein trong cặp tương tác bằng cách dịch trình tự đi 1, 2, 3 axit amin thì chúng sẽ không tương tác, ở đây tác giả sử dụng phần mềm k-let \cite{coward1999shufflet} cho việc xáo trộn protein. Các cặp âm tính không được xuất hiện trong tập dương tính và khi tạo ra theo một chiến lược thì phải có số lượng bằng tập dương tính tức là 5594 cặp. Các chiến lược xây dựng cặp âm tính trong tập dữ liệu này phức tạp hơn song chiến lược hai chưa thực sự toàn diện vì một protein có thể có mặt ở nhiều vị trí trong tế bào và chiến lược ba thì cũng chưa chắn hoàn toàn là khi xáo trộn chúng lại không tương tác.

\par Tập dữ liệu Guo được lấy từ kho lưu trữ \url{https://github.com/muhaochen/seq_ppi/tree/master/yeast/preprocessed}, kích thước tập dữ liệu đúng như đã được báo cáo. Tập dữ liệu ban đầu được tổ chức thành đúng định dạng chuẩn nên không cần xử lý gì thêm và lưu trữ ở \url{https://github.com/anhvt00/MCAPS/tree/master/data/Golden-standard-datasets/Guo-2008}

\subsubsection*{Tập dữ liệu người Pan (2010)}
\par Tập dữ liệu được xây dựng bởi Pan và cộng sự năm 2010 \cite{pan2010large} có 73110 cặp bao gồm 36630 cặp dương tính và 36480 cặp âm tính của con người. Tập dữ liệu dương tính được tải từ cơ sở dữ liệu HPRD phiên bản tháng 6 năm 2007. Phiên bản này bao gồm 38788 cặp protein được xác định bằng thực nghiệm của 9630 protein khác nhau ở người. Sau khi loại bỏ các cặp tự tương tác và các tương tác lặp lại, tác giả thu được 36630 cặp dương tính. Tác giả xây dựng tập âm tính từ cơ sở dữ liệu Swiss-Prot dựa vào giả sử là các protein không cùng vị trí trong tế bào thì không tương tác nhưng có một số ràng buộc như 
\begin{itemize}
    \item Chỉ lấy các trình tự protein có ID loài là con người
    \item Loại bỏ các trình tự protein được chú giải vị trí tế bào không chắc chắn với các thuật ngữ như ``potential'', ``probable'', ``maybe'' 
    \item Chỉ giữ lại các protein có vị trí bào quan trong tế bào là duy nhất
    \item Loại bỏ các trình tự ngắn dưới 50 đơn vị thường là các mảnh đứt gãy
\end{itemize}
Các cặp âm tính được tạo ra bằng cách ghép protein từ hai bào quan khác nhau, cách ghép lần này đã chặt chẽ hơn vì các protein chỉ có vị trí duy nhất. Sau đó tác giả tải xuống cơ sở dữ liệu Negatome, cơ sở dữ liệu âm tính đã chứng minh bằng thực nghiệm và lựa chọn những cặp tương tác là người bổ sung vào tập âm tính. Tập âm tính cuối cùng thu được bao gồm 36480 cặp.

\par Tập dữ liệu Pan được lấy từ kho lưu trữ \url{http://www.csbio.sjtu.edu.cn/bioinf/LR_PPI/Data.htm}, kích thước tập dữ liệu đúng như đã được báo cáo. Trong tập dữ liệu này chỉ cung cấp tệp tương tác không cung cấp tệp từ điển mã-trình tự nên buộc phải chuẩn bị tệp mã-trình tự. Tệp tương tác bao gồm các mã từ ba cơ sở dữ liệu khác nhau bao gồm UniProt, ENA và RefSeq; cần quy đổi ba mã này về cùng một mã tiêu chuẩn, ở đây tôi lựa chọn mã của cơ sở dữ liệu UniProt. Các cặp chưa mã không tồn tại khi quy đổi sẽ bị loại bỏ. Sau cùng ta thu được tập dữ liệu Pan có 61891 cặp (mất 11291 so với gốc) gồm 27593 cặp dương tính (mất 9037 so với gốc) và 34298 cặp âm tính (mất 2182 so với gốc) tạo từ 8347 trình tự. Tập dữ liệu sau khi được tiền xử lý và định dạng lại được lưu trữ ở \url{https://github.com/anhvt00/MCAPS/tree/master/data/Golden-standard-datasets/Pan-2010}.


\subsubsection{Tập dữ liệu kiểm tra ngoại}
Để kiểm tra khả năng tổng quát hóa của mô hình dự đoán, một số tập dữ liệu PPI chuẩn khác chứa các dữ liệu chưa nhìn thấy trên tập nội tại được chuẩn bị, có thể trên cùng loài hoặc ở các loài khác.

\subsubsection*{Tập dữ liệu kiểm tra Li người (2018)}
Ở nghiên cứu năm 2018 của Li và cộng sự \cite{li2018deep}, tác giả chuẩn bị các tập kiểm tra ở con người không có chung các cặp với tập nội tại Pan (2010) lấy từ ba cơ sở dữ liệu HPRD, DIP và HIPPIE nhằm kiểm tra khả năng tổng quát hóa, dự đoán với các dữ liệu mới trên cùng loài người. Ở cả ba tập dữ liệu, tác giả đều loại bỏ đi những trình tự dài hơn 1200 với giả sử phần lớn các trình tự axit amin nằm dưới 1200, việc cắt bớt trình tự thế này để thuận lợi cho áp dụng mô hình tuần tự trong nghiên cứu của họ. Các cặp trình tự chia sẻ nhiều hơn 40\% độ tương đồng bị loại bỏ sử dụng phần mềm CD-HIT. Ở đây, tác giả không cung cấp phiên bản dữ liệu tác giả sử dụng nên tôi sẽ tái tạo lại tập dữ liệu dựa vào những ràng buộc tác giả sử dụng.  Vì các dữ liệu trình tự chưa được cung cấp sẵn nên ta sẽ phải lấy dữ liệu trình tự từ cơ sở dữ liệu Uniprot sử dụng các mã của hai tập dữ liệu này quy đổi sang mã Uniprot. Có một số mã của cơ sở dữ liệu DIP/HIPPE/HPRD không ánh xạ được sang mã của cơ sỡ dữ liệu Uniprot nên ta sẽ loại bỏ các cặp chứa mã đó, đồng thời ta cũng loại bỏ đi các mã trùng lặp với tập dữ liệu Pan (2010) (ở phía trên ta đã đề cập về việc chuyển đổi mã của tập Pan về mã Uniprot). Các bước tiền xử lý này được áp dụng với cả ba tập dữ liệu. Thông tin tóm tắt về ba tập kiểm tra ở người được sử dụng trong nghiên cứu của Li được trình bày ở Bảng \ref{table:human-datasets}

\begin{table}[htp]
\caption{\textbf{Tập dữ liệu kiểm tra ở người Li (2018) \cite{li2018deep}} }
\label{table:human-datasets}
\begin{tabularx}{\textwidth}{Yccc}
    \specialrule{1.5pt}{1pt}{1pt}
    \textbf{Tập dữ liệu} & \textbf{Số cặp dương tính} & \textbf{Số cặp âm tính} & \textbf{Số trình tự} \\
    \specialrule{1.5pt}{1pt}{1pt}
    HPRD (phiên bản 2010) & 3516 & 0 & 3636\\
    DIP (phiên bản 20160430)  & 1468 & 0 & 1876\\
    HIPPIE HQ (phiên bản 2.0) & 15489  & 0 & 6123\\
    HIPPIE LQ (phiên bản 2.0) & 101684  & 0 & 10488\\
    \specialrule{1.5pt}{1pt}{1pt}
\end{tabularx}
\end{table}


\par HPRD là một cơ sở dữ liệu lưu trữ tập trung cho kiến trúc miền, các biến đổi sau phiên dịch, mạng tương tác và các liên kết về bệnh trong hệ protein người. Tất cả thông tin trong HPRD đều được các chuyên gia sinh học trích xuất thủ công từ tài liệu. Trong nghiên cứu tác giả sử dụng phiên bản 2010 của CSDL. Thực hiện các bước tiền xử lý ta thu được 3516 cặp tương tác tạo ra từ 3636 protein \url{https://github.com/anhvt00/MCAPS/tree/master/data/Independent-testsets/Human-sets/HPRD-2010-new/Non-redundant}.



\par Cơ sở dữ liệu về các protein tương tác (DIP) lưu trữ và đánh giá các tương tác được xác định bằng thực nghiệm giữa các protein. Tất cả các tương tác trong DIP đều được chọn lọc từ các tài liệu đã được đánh giá bình duyệt và được nhập thủ công vào cơ sở dữ liệu bởi những chuyên gia. Tác giả sử dụng phiên bản 20160430 của cơ sở dữ liệu DIP nên tôi tải xuống dữ liệu của phiên bản đó từ tran web của cơ sở dữ liệu. Thực hiện các bước tiền xử lý ta thu được 1468 cặp tương tác tạo ra từ 1876 protein \url{https://github.com/anhvt00/MCAPS/tree/master/data/Independent-testsets/Human-sets/DIP_20160430/Non-redundant}.

\par Cơ sở dữ liệu HIPPIE cung cấp điểm tin cậy và chú giải chức năng cho tương tác protein-protein người, điểm tin cậy $\ge$ 0.73 coi là chất lượng cao hay HQ (high quality) và $<$ 0.73 coi là chất lượng thấp hay LQ (low quality). Dữ liệu HQ và LQ phiên bản 2.0 được tác giả sử dụng. Tập dữ liệu HIPPIE phiên bản 2.0 có thể được tải trực tiếp từ trang web của cơ sở dữ liệu, tập dữ liệu này bao gồm các bản ghi bao gồm mã của hai mã của cơ sở dữ liệu HIPPIE tương ứng với hai protein, và điểm tin cậy của tương tác giữa chúng. Từ đây ta sẽ tách ra thành hai tập HIPPIE HQ và HIPPIE LQ dựa vào điểm tin cậy. Thực hiện các bước tiền xử lý kết quả là thu được 15489 cặp dương tính tạo ra từ 6123 protein cho tập HIPPIE HQ và 101684 cặp dương tính tạo ra từ 10488 protein cho tập HIPPIE LQ \url{https://github.com/anhvt00/MCAPS/tree/master/data/Independent-testsets/Human-sets/HIPPIE/Non-redundant-quality}.




\subsubsection*{Tập dữ liệu kiểm tra chéo loài \cite{sledzieski2021d}}

Nghiên cứu của Sledzieski và cộng sự năm 2021 \cite{sledzieski2021d} xây dựng các tập dữ liệu nhằm kiểm tra khả năng mở rộng của mô hình khi cho học trên người và đánh giá trên các loài khác. Các tập dữ liệu của các loài sinh vaajt khác được xây dựng từ cơ sở dữ liệu STRING \cite{szklarczyk2021string} (phiên bản 11). STRING chứa các cặp protein tương ứng với nhiều nguồn dữ liệu sơ cấp và phương thức tương tác (liên kết so với đồng biểu hiện). Để chọn các tương tác protein vật lý có độ tin cậy cao, tác giả đã lọc các cặp dương tính với điểm số thực nghiệm cao. Từ tập hợp này, tác giả đã loại bỏ các PPI liên quan đến các protein rất ngắn (ngắn hơn 50 axit amin) và loại bỏ các protein dài hơn 800 axit amin do hạn chế về tài nguyên tính toán. Đồng thời, tác giả loại bỏ các PPI tương đồng trình tự cao cho các PPI khác sử dụng phần mềm CD-HIT ở ngưỡng 40\%. PPI (A-B) được coi dư thừa về mặt trình tự nếu chọn một PPI (C-D) khác mà các cặp protein (A, C) và (B, D) có chung một cụm CD-HIT. Việc loại bỏ các PPI dư thừa về trình tự khỏi tập dữ liệu ngăn không cho mô hình ghi nhớ các tương tác chỉ dựa trên sự giống nhau về trình tự.

\par Để tạo ra các cặp âm tính, tác giả ghép nối ngẫu nhiên các protein từ nhóm không dư thừa, chọn tỷ lệ âm-dương 10: 1 để mô phỏng bản chất hệ tương tác trong thực tế của các loài sinh vật rằng các cặp dương tính rất ít so với âm tính. Đối với mỗi sinh vật trong số 5 sinh vật mô hình (Bảng \ref{table:cross-datasets}), tác giả đã chọn 5.000 cặp dương tính và 50.000 cặp âm tính, ngoại trừ \textit{E.coli} (2.000 / 20.000) do số lượng cặp âm tính của \textit{E.coli} giới hạn trong cơ sở dữ liệu STRING. Tập dữ liệu chéo loài được Sledzieski công khai ở địa chỉ \url{https://github.com/samsledje/D-SCRIPT/tree/main/data} bao gồm cả dữ liệu về cặp tương tác và trinh tự đủ số lượng, dữ liệu không bị sai hỏng và đúng định dạng chuẩn nên ở đây tôi chỉ cần thu thập và sử dụng lại tập dữ liệu này mà không cần xử lý gì thêm.

\begin{table}[htp]
\caption{\textbf{Tập dữ liệu chéo loài Sledzieski (2021) \cite{sledzieski2021d}} }
\label{table:cross-datasets}
\begin{tabularx}{\textwidth}{Yccc}
    \specialrule{1.5pt}{1pt}{1pt}
    \textbf{Tập dữ liệu} & \textbf{Số cặp dương tính} & \textbf{Số cặp âm tính} & \textbf{Số trình tự} \\
    \specialrule{1.5pt}{1pt}{1pt}
    Chuột & 5000 & 50000 & 40606\\
    Ruồi giấm & 5000 & 50000 & 19310\\
    Giun tròn & 5000  & 50000 & 25930\\
    Nấm men & 5000  & 50000 & 5664\\
    E.coli & 2000  & 20000 & 17722\\
    \specialrule{1.5pt}{1pt}{1pt}
\end{tabularx}
\end{table}



\subsubsection*{Tập dữ liệu kiểm tra liên loài (2021)}

\par Yang và cộng sự năm 2021 \cite{yang2021transfer} đã thu thập dữ liệu tương tác protein-protein của con người-virus đã được xác minh bằng thực nghiệm để xây dựng tập dữ liệu liên loài với 31.381 tương tác bao gồm ở 9.880 tương tác ở virus HIV, 5.966 ở virus Herpes, 5.099 ở virus Papilloma, 3.044 ở virus Influenza, 1.300 ở virus Hepatitis, 927 ở virus Dengue, 709 ở virus Zika, 586 ở virus Sars-CoV-2  từ năm cơ sở dữ liệu công khai, bao gồm HPIDB \cite{ammari2016hpidb}, VirHostNet \cite{guirimand2015virhostnet}, VirusMentha \cite{calderone2015virusmentha}, PHISTO \cite{durmucs2013phisto} và PDB \cite{rose2016rcsb} và hai tập dữ liệu gần đây của Li và cộng sự năm 2020 \cite{li2020early}, Gordon và cộng sự năm 2020 \cite{gordon2020sars}. Để có được PPI chất lượng cao, tác giả loại bỏ các tương tác khỏi các thử nghiệm MS quy mô lớn chỉ được phát hiện một lần, các tương tác phi vật lý và tương tác giữa các protein không có hồ sơ PSSM. 

\par Về xây dựng dữ liệu âm tính, tác giả sử dụng phương pháp Lấy mẫu âm tính dựa trên mức độ không tương đồng (dissimilarity-based negative sampling) \cite{eid2016denovo} và lấy mẫu âm tính gấp 10 lần dương tính để mô phỏng phân bố thực tế của tương tác. Điểm quan trọng trong cách lấy mẫu âm tính trong phương pháp là nếu trình tự của protein virus A và B tương đồng nhau và A tương tác với protein C của người (tức là A-C là cặp dương tính), thì B-C không được chọn làm cặp âm tính. Tập dữ liệu được công khai ở địa chỉ sau \url{https://github.com/XiaodiYangCAU/TransPPI/tree/main/sample}, dữ liệu đầy đủ, không bị sai hỏng và ở đúng định dạng chuẩn gồm cả tệp tương tác và từ điên nên có thể sử dụng lại luôn. Tóm tắt về tập dữ liệu được cho ở Bảng \ref{table:inter-datasets}.
\FloatBarrier
\begin{table}[htp]
\caption{\textbf{Tập dữ liệu liên loài Yang (2021) \cite{yang2021transfer}} }
\label{table:inter-datasets}
\begin{tabularx}{\textwidth}{Yccc}
    \specialrule{1.5pt}{1pt}{1pt}
    \textbf{Tập dữ liệu} & \textbf{Số cặp dương tính} & \textbf{Số cặp âm tính} & \textbf{Số trình tự}\\
    \specialrule{1.5pt}{1pt}{1pt}
    HIV & 9880 & 98800 & 20464\\
    Herpes & 5966 & 59660 & 19845\\
    Papilloma &  5099 & 50990 & 19087\\
    Influenza & 3044  & 30440 & 16377\\
    Hepatitis & 1300  & 13000 & 10287\\
    Dengue & 927  & 9270 & 8028\\
    Zika & 709  & 7090 & 6480\\
    Sars-CoV-2 & 586  & 5860 & 5360\\
    \specialrule{1.5pt}{1pt}{1pt}
\end{tabularx}
\end{table}
\FloatBarrier
\subsection{Các mô hình so sánh}

\par Trong khóa luận này, tôi lựa chọn ba mô hình để so sánh với mô hình MCAPSL do tôi phát triển, đó là PIPR \cite{chen2019multifaceted}, D-SCRIPT \cite{sledzieski2021d}, và FSNN-LGBM \cite{mahapatra2021improved}.

\par PIPR là mô hình được phát triển bởi Chen và cộng sự tại đại học UCLA (Mỹ) vào năm 2019 \cite{chen2019multifaceted}, cách đây hơn 2 năm nhưng vẫn là mô hình tiêu chuẩn được so sánh với nhiều nghiên cứu phát triển mô hình hiện tại. PIPR vẫn có thể coi là mô hình dự đoán PPI nhị phân dựa trên trình tự tốt nhất hiện nay, với hiệu năng dự đoán ổn định, vượt trội hơn tất cả các mô hình học máy, học sâu cho đến năm 2019. So với các mô hình được phát triển vào 2 năm sau đó, chất lượng dự đoán PIPR không kém hơn đáng kể. Kiến trúc PIPR là một kiến trúc khá hiện đại, kết hợp được cả CNN và RNN dưới dạng các đơn vị, đồng thời sử dụng được liên kết tắt giúp duy trì thông tin tốt hơn, và mạng song sinh giúp trích xuất đặc trưng theo cặp (Hình \ref{fig:PIPR}). Vector nhúng axit amin sử dụng trong mô hình là một dạng kết hợp giữa vector nhúng mô hình skip-gram và đặc trưng về hóa lí dạng nhị phân của axit amin, giúp cho tận dụng cả tri thức về sinh học cũng như thống kê. Điểm hạn chế đáng kể nhất của PIPR có lẽ nằm ở việc sử dụng RNN không hợp lý cho bài toán này, do protein là trình tự có kích thước khá lớn so với kích thước trung bình một câu văn thường sử dụng RNN trong các bài toán về phân lớp văn bản. Mã nguồn của mô hình PIPR được tác giả chia sẻ công khai ở kho lưu trữ \url{https://github.com/muhaochen/seq_ppi}. Tôi tiến hành cài đặt mã nguồn của tác giả, và chạy chương trình nhằm kiểm tra tái lập kết quả từ nghiên cứu của Chen. Kết quả là tái lập lại được các độ đo chất lượng của mô hình trên các tập dữ liệu trong bài báo với chênh lệch dưới 0.4\% con số báo cáo vậy có thể sử dụng được mô hình PIPR để so sánh.

% \begin{figure}[htp]
%     \centering
%     \includegraphics[width=450pt]{images/DPPI.png}
%     \caption{\textbf{Kiến trúc mô hình DPPI} \cite{hashemifar2018predicting}}
%     \label{fig:DPPI}
% \end{figure}

\FloatBarrier
\begin{figure}[htp]
    \centering
    \includegraphics[width=400pt]{images/PIPR.png}
    \caption{\textbf{Kiến trúc mô hình PIPR} \cite{chen2019multifaceted}}
    \label{fig:PIPR}
\end{figure}
\FloatBarrier

\par D-SCRIPT là mô hình được phát triển bởi Sledzieski và cộng sự tại đại học MIT (Mỹ) vào đầu năm 2021 \cite{sledzieski2021d}. D-SCRIPT hiện tại đang là 1 trong những mô hình dự đoán PPI nhị phân dựa trên trình tự tốt nhất hiện nay, có khả năng dự đoán mở rộng chéo loài rất tốt. D-SCRIPT sử dụng mô hình ngôn ngữ protein của Bepler \cite{bepler2019learning}, khai thác được các đặc trưng về cấu trúc không gian protein ẩn trong trình tự chuỗi axit amin. Kiến trúc D-SCRIPT dựa trên CNN và MLP (Hình \ref{fig:D-SCRIPT}), điểm đặc biệt là khai thác các đặc trưng liên quan đến bản đồ tiếp xúc của hai trình tự. Đây là điểm nổi bật gần đây được các nhà khoa học khai thác nhiều hơn trong việc dự đoán cấu trúc, tương tác của các protein. Dựa vào bản đồ tiếp xúc giữa hai protein được D-SCRIPT dự đoán, điều quan trọng hơn không chỉ là có tương tác hay không mà là về khả năng tương tác của các gốc axit amin. Bản đồ tiếp xúc thể hiên tính bảo thủ trong tiến hóa của giao diện giữa các protein đồng đẳng với nhau, được quy định bởi một số axit amin bảo thủ trong suốt bề dày tiến hóa của các loài sinh vật. Hạn chế lớn của D-SCRIPT là mô hình có kích thước rất lớn trong thời gian chạy, tốn kém về tài nguyên bộ nhớ rất nhiều do đó đòi hỏi phải có phần cứng tính toán với cấu hình cao. Mã nguồn của mô hình D-SCRIPT được tác giả chia sẻ công khai ở kho lưu trữ \url{https://github.com/samsledje/D-SCRIPT}. Tôi tiến hành cài đặt lại mã nguồn của tác giả, chạy chương trình nhằm kiểm tra tái lập kết quả từ nghiên cứu. Ở đây, tôi chỉ tái lập lại dựa trên các mẫu dữ liệu với cỡ mẫu từ 1000-2000 (khoảng 5-10\% dữ liệu thực, cùng phân bố) từ tập dữ liệu của tác giả do dữ liệu thật có kích thước rất lớn, đòi hỏi phần cứng quá nhiều đến mức các dịch vụ tính toán hiệu năng cao cũng không cung cấp được nên không kiểm tra lại được toàn bộ các kết quả. Kết quả tái lập lại lại có sự chênh lệch trên dưới 1-5\%, quả thực, cũng có các nỗ lực khác cố gắng tái tạo lại mô hình này nhưng thường chất lượng không đạt được như bài báo mô tả kể cả khi làm với tập dữ liệu đầy đủ, và cũng có sự sai lệch như trên đối với mã nguồn. Vì chất lượng của mô hình D-SCRIPT không cao, thường dao động từ 40-80 với các độ đo nên việc chênh lệch vài \% cũng khá đáng kể. Tuy vậy, đây có lẽ là nỗ lực tốt nhất có thể làm được với mô hình D-SCRIPT.

\FloatBarrier
\begin{figure}[htp]
    \centering
    \includegraphics[width=490pt]{images/D-SCRIPT.png}
    \caption{\textbf{Kiến trúc mô hình D-SCRIPT} \cite{sledzieski2021d}}
    \label{fig:D-SCRIPT}
\end{figure}
\FloatBarrier

\par FSNN-LGBM là mô hình được phát triển bởi Mahapatra và cộng sự tại Viện Công nghệ Birla Mesra (Ấn Độ) \cite{mahapatra2021improved} vào giữa năm 2021. FSNN-LGBM hiện đang là mô hình tốt nhất từng được ghi nhận, vượt trội đáng kể hơn so với PIPR trên nhiều tập dữ liệu khác nhau cũng như các mô hình khác được phát triển cho tới năm 2021. FSNN-LGBM là một mô hình lai giữa mô hình học máy và học sâu, FSNN là mạng nơ-ron mở rộng theo bậc của đầu vào trong khi LGBM là một mô hình học máy phân lớp rất tốt. Mô hình có kiến trúc tương đối đơn giản (Hình \ref{fig:FSNN-LGBM}) và sử dụng đầu vào dưới dạng vector từ bộ mô tả đặc trưng protein chứ không phải ma trận của các vector nhúng axit amin. Với cách thiết kế đơn giản như vậy, mô hình FSNN-LGBM chưa khai thác được các đặc trưng liên quan không gian và thời gian của chuỗi axit amin. Thông tin được trích rút từ bộ mô tả đặc trưng còn tương đối cơ bản và rời rạc. Mã nguồn của mô hình FSNN-LGBM không được tác giả chia sẻ công khai, chỉ là một phiên bản mô hình tương tự như vậy được chia sẻ công khai ở kho lưu trữ \url{https://github.com/SatyajitECE/DNN-XGB-for-PPI-Prediction}. Dựa vào mã nguồn của một mô hình tương tự và cấu hình mô hình được nêu rõ trong bài báo, tôi tiến hành cài đặt lại mô hình. Kết quả tái lập lại trên các tập dữ liệu chênh lệch dưới 0.6\% nên có thể sử dụng mô hình FSNN-LGBM để so sánh.

\FloatBarrier
\begin{figure}[htp]
    \centering
    \includegraphics[width=380pt]{images/FSNN-LGBM.png}
    \caption{\textbf{Kiến trúc mô hình FSNN-LGBM} \cite{mahapatra2021improved}}
    \label{fig:FSNN-LGBM}
\end{figure}
\FloatBarrier


\subsection{Các công nghệ được sử dụng}

\par Python là một ngôn ngữ lập trình bậc cao, kịch bản (scripting programming language), kiểu dữ liệu động (dynamic typed), đa mục đích. Ngôn ngữ lập trình này được phát triển từ những năm 1980 bởi Guido van Rossum, sau đó được phát hành lần đầu vào năm 1991. Python là một ngôn ngữ linh hoạt, sử dụng kiểu dữ liệu động, hỗ trợ rất nhiều phong cách lập trình: lập trình hướng đối tượng, lập trình hàm, lập trình thủ tục\ldots Đến nay, Python là một ngôn ngữ lập trình đa nền tảng (được hỗ trợ trên rất nhiều hệ điều hành) và thường xuyên nằm trong top các ngôn ngữ lập trình phổ biến nhất. Python được thiết kế có cú pháp gọn gàng, dễ đọc, và thường được so sánh với mã giả (pseudo code). Ngôn ngữ này là một lựa chọn rất tốt cho khoa học dữ liệu cũng như tin sinh học do đã được cung cấp sẵn khả năng làm việc với các con số, thống kê, các hàm tiện ích, cùng rất nhiều thư viện lập trình. Trong khóa luận này, để cài đặt thuật toán tôi phát triển, tôi lập trình chủ yếu bằng ngôn ngữ Python.

\subsubsection{Các thư viện học sâu}

\par Thực tế, khi lập trình để giải quyết một vấn đề nào đó, người ta không bao giờ viết mã từ con số không (from scratch). Thay vào đó, họ dùng tới các thư viện lập trình (hay được viết ngắn gọn là thư viện). Thư viện lập trình là một bộ mã nguồn được viết ra nhằm phục vụ một mục đích nào đó. Khi sử dụng thư viện, người dùng sẽ gọi tới các giao diện (interface), hàm (function), lớp (class) được cung cấp bởi thư viện đó. Sử dụng thư viện giúp cho việc lập trình trở nên hiệu quả - Bởi khi đó, người dùng có thể tập trung giải quyết vấn đề của mình, tiết kiệm đáng kể thời gian thay vì viết lại mã tương tự như thư viện (phát minh lại bánh xe).

\par Trong lĩnh vực học máy cũng như học sâu, có rất nhiều thuật toán, mô hình đã được phát triển. Đã có các thư viện đã cài đặt những thuật toán này. Từ góc nhìn của một người giải quyết vấn đề, sự có mặt của các thư viện đó là điều thuận tiện. Nhờ có thư viện, ta có thể tập trung vào việc phát triển thuật toán, mô hình mới.

\par Khóa luận tốt nghiệp này sử dụng những thư viện học sâu dưới đây:

\begin{itemize}
  \item \textbf{Tensorflow}. Đây là một thư viện mã nguồn mở, cung cấp khả năng tính toán hiệu năng cao và hỗ trợ cho học máy cũng như học sâu. Tensorflow cho phép phát triển trên nhiều nền tảng khác nhau (CPU, GPU, và TPU), máy tính cá nhân, điện thoại di động, các máy phục vụ. Thư viện này được phát triển bởi một đội ngũ của Google.
  \item \textbf{Keras}. Thư viện mã nguồn mở này có bản chất là Tensorflow. Tuy nhiên, Keras cung cấp các API bậc cao để sử dụng Tensorflow, vốn dễ hiểu và dễ dùng hơn so với Tensorflow. API của Keras thân thiện hơn so với Tensorflow.
  \item \textbf{PyTorch}. Đây là một thư viện tensor mã nguồn mở dành cho học sâu, hỗ trợ GPU và CPU. Thư viện này được phát triển bởi Meta (tên gọi cũ là Facebook). PyTorch thường được so sánh với Tensorflow.
  \item \textbf{Scikit-learn}. Đây là một thư viện học máy mã nguồn mở. Thư viện này cung cấp rất nhiều thuật toán học máy phổ biến, đồng thời được thiết kế để tương tác thuận tiện với nhiều thư viện phổ biến khác như SciPy và Numpy.
\end{itemize}

\subsubsection{Điện toán đám mây}

\par Để phát triển, cũng như kiểm thử một thuật toán/mô hình học máy hay học sâu, cần có một máy tính thật mạnh. Một máy tính như vậy cần có bộ nhớ lớn, ổ cứng có dung lượng lưu trữ lớn, và đặc biệt là có GPU (thành phần xử lý đồ họa). Học sâu cần có GPU, thậm chí là rất nhiều GPU để có thể tính toán hiệu quả, tiết kiệm thời gian bởi thành phần này có thể thực hiện rất nhiều tính toán đồng thời, nhanh hơn rất nhiều so với CPU tốt nhất.

\par Điều không may là không phải ai cũng có điều kiện để tiếp cận một máy tính với cấu hình cao như trên. Riêng giá thành của một GPU cũng đã cao hơn rất nhiều so với một máy tính cá nhân thông thường. Giá của một máy tính với bộ nhớ và kích thước ổ cứng lớn cũng vậy. Thay vì bỏ tiền mua, lắp đặt một máy tính mạnh như vậy, người ta có thể áp dụng một giải pháp kinh tế hơn, đó là điện toán đám mây.

\par Điện toán đám mây (Cloud Computing) là một mô hình điện toán sử dụng công nghệ ảo hóa và được phân phối bằng Internet. Trong thuật ngữ  điện toán đám mây, từ điện toán dùng để chỉ máy ảo (thành phần cốt lõi của điện toán đám mây), còn từ đám mây dùng để chỉ Internet. Điện toán đám mây cung cấp nhiều dịch vụ như máy ảo, mạng, cơ sở dữ liệu, lưu trữ, tính toán\ldots $-$ Những dịch vụ này được điều phối, quản lý, tự động hóa sao cho người dùng có thể truy cập và sử dụng được qua Internet theo nhu cầu. Điện toán đám mây có nhiều ưu điểm:

\begin{itemize}
  \item \textbf{Tiết kiệm chi phí.} Các công đoạn như mua và bảo trì phần cứng, lắp đặt, cài đặt hệ điều hành và các phần mềm khác được thực hiện bởi các nhà cung cấp dịch vụ điện toán đám mây. Hơn nữa, khi sử dụng điện toán đám mây, người dùng chỉ cần chi trả cho những dịch vụ mà họ sử dụng (không cần trả tiền cho các phần cứng, phần mềm).
  \item \textbf{Tiết kiệm thời gian.} Khi sử dụng điện toán đám mây, người dùng không phải mất thời gian lắp đặt hệ thống. Bên cạnh đó, việc thiết lập cấu hình mong muốn cho các dịch vụ có thể được thực hiện chỉ trong ít phút, với một đường truyền Internet ổn định.
  \item \textbf{Hiệu năng cao.} Các nhà cung cấp dịch vụ điện toán đám mây có các trung tâm dữ liệu (datacenters) được đặt ở nhiều khu vực trên thế giới, các thiết bị phần cứng ở đó liên tục được cập nhật để có thiết bị làm việc hiệu quả nhất.
  \item \textbf{Tính tin cậy.} Điện toán đám mây có các cơ chế backup dữ liệu, phục hồi sau các sự cố. Người dùng có thể đặt dữ liệu ở nhiều khu vực khác nhau trong mạng của nhà cung cấp.
  \item \textbf{Bảo mật.} Các nhà cung cấp dịch vụ điện toán đám mây cũng mang lại nhiều chính sách, công nghệ nhằm tăng cường, đảm bảo tính bảo mật, giúp bảo vệ dữ liệu, ứng dụng và cơ sở hạ tầng khỏi các mối đe dọa tiềm tàng.
\end{itemize}

\par Trong số rất nhiều loại dịch vụ và điện toán đám mây có thể cung cấp, có dịch vụ dành riêng cho học sâu và nhu cầu sử dụng máy tính hiệu năng cao. Để thực hiện khóa luận tốt nghiệp này, tôi đã sử dụng tới hai dịch vụ như vậy: Google Colab và DataCrunch.

\par \textbf{Google Colab} (hay còn được gọi là Colab) là một dịch vụ của Google, được phát triển bởi Google Research. Colab cho phép mọi người viết và thực thi mã được viết bằng Python ngay trên trình duyệt. Dịch vụ này đặc biệt phù hợp trong giảng dạy, xử lý/phân tích dữ liệu, và học máy, học sâu. Colab có ba gói sử dụng: gói miễn phí, gói Pro, và gói Pro+. Đằng sau, Colab sử dụng một máy ảo Google (Google Compute Engine) sử dụng cơ sở hạ tầng của chính Google Cloud Platform (nền tảng điện toán đám mây của Google). Khóa luận tốt nghiệp này sử dụng Colab cho những tác vụ nhỏ và vừa.

\par \textbf{DataCrunch} là một nhà cung cấp các máy ảo với GPU cao cấp. GPU do DataCrunch cung cấp ổn định và tốt hơn so với Colab (rất ngẫu nhiên và ít khi cung cấp cho người dùng một máy tính mạnh như mong muốn). Khóa luận tốt nghiệp này sử dụng DataCrunch cho những tác vụ lớn, cần đến những GPU tốt như NVIDIA A100.


\newpage % tạo section mới là phải sang trang mới
\section{KẾT QUẢ VÀ THẢO LUẬN}

\subsection{Kết quả xây dựng kiến trúc MCAPSL}
\par Từ những ý tưởng xây dựng mô hình cho dự đoán PPI nhị phân đã trình bày ở phần trước, ở phần này tôi trình bày về kiến trúc mô hình MCAPSL và các thiết lập cho việc huấn luyện mô hình.

\subsubsection{Kiến trúc tổng quát}

\par Mô hình MCAPSL là mô hình lai, được truyền cảm hứng từ mô hình lai FSNN-LGBM \cite{mahapatra2021improved}. Mô hình lai sẽ có một lợi thế là khả năng dự đoán phân lớp tốt hơn với dữ liệu tương tác chưa thấy cùng loài, với những loài khác thì có thể sẽ làm giảm đi một chút ít hiệu năng dự đoán. Mô hình là sự kết hợp giữa mạng nơ-ron sâu song sinh đa kênh sử dụng cơ chế tích lũy gộp theo độ sâu tầng hay MCAPS (multi-channel accumulated pooling siamese neural network), và mô hình học máy LGBM (light gradient boosting machine). Điểm đặc biệt trong mô hình đến từ thiết kế kiến trúc mạng nơ-ron sâu MCAPS với mục tiêu học các biểu diễn vector trích xuất các thông tin quan trọng từ cặp trình tự protein để truyền vào thuật toán học máy LGBM để đưa ra xác suất dự đoán tương tác giữa hai trình tự.

\par Mô hình MCAPSL có kiến trúc tổng quát như hình vẽ dưới đây (Hình \ref{fig:MCAPSL})

\begin{figure}[htp]
    \centering
    \includegraphics[width=480pt]{images/MCAPSL.png}
    \caption{\textbf{Kiến trúc mô hình MCAPSL}}
    \label{fig:MCAPSL}
\end{figure}


\par Mô hình mạng MCAPSL gồm có bốn bước đó là mã hóa (encoding), học trên mỗi trình tự (single sequence learning), học trên cả cặp trình tự (pair learning). 

\subsubsection*{Pha mã hóa trình tự axit amin}
\par Ở bước đầu mã hóa, trình tự axit amin của cặp protein đầu vào sẽ được mã hóa dưới dạng đồng thời cả vector và ma trận, khác với các nghiên cứu trước đây, thường chỉ mã hóa protein dưới dạng vector hoặc ma trận. 

\par Với dạng vector, có rất các nhóm bộ mô tả đặc trưng khác nhau cho trình tự axit amin đã được phát triển. Các nghiên cứu trước đây đã chứng minh sử dụng kết hợp các bộ mô tả trong việc trích xuất thông tin trình tự có hiệu quả tốt hơn sử dụng đơn lẻ từng bộ. Trong khóa luận này, tôi sử dụng ba bộ mô tả đặc trưng protein thường được sử dụng là CT \cite{shen2007predicting}, LD \cite{yang2010prediction} và PseAAC \cite{chou2001prediction} để tạo ra một vector mô tả và tóm tắt thông tin cho mỗi protein.
\begin{itemize}
    \item \textbf{Bộ mô tả đặc trưng CT}: bộ mô tả bộ ba liên tiếp hay CT (conjoint triad) \cite{shen2007predicting} chia các axit amin theo tính lưỡng cực và thể tích chuỗi bên thành 7 nhóm riêng biệt $\{(A, G, V); (I, L, F, P); (Y, M, T, S); (H, N, Q, W); (R, K); (D, E); (C)\}$. Mỗi axit amin trong trình tự sẽ được thay thế bởi chỉ số nhóm chứa axit amin đó. Mỗi trình tự axit amin lúc này sẽ được biểu diễn thành một chuỗi các con số. Trong bộ mô tả CT, tác giả quy định cứ ba axit amin liên tiếp lập thành một bộ ba CT và có tổng cộng $7^3=343$ bộ ba CT. Vector đặc trưng tạo bởi bộ mô tả CT cho trình tự axit amin là một vector 343 chiều, trong đó mỗi chiều hay mỗi đặc trưng là tần số xuất hiện $f_{i}$ của bộ ba CT thứ $i$ với $1\le i \le 343$ (Hình \ref{fig:CT}). Sau đó vector này được chuẩn hóa cho mỗi đặc trưng để không phụ thuộc vào độ dài, vector chuẩn hóa có đặc trưng mỗi chiều $d_{i}$ được xác định ở công thức bên dưới.
    
    \[
        d_{i} = \frac{f_{i} - \min\{f_{1},\ldots, f_{343}\}}{\max\{f_{1},\ldots, f_{343}\}}.
    \]
    
    \FloatBarrier
    \begin{figure}[htp]
        \centering
        \includegraphics[width=420pt]{images/CT.png}
        \caption{\textbf{Bộ mô tả bộ ba liên tiếp (CT)} \cite{wang2017protein}}
        \label{fig:CT}
    \end{figure}
    \FloatBarrier
    
    Bộ mô tả này được dùng trong các nghiên cứu về dự đoán PPI từ trước \cite{pan2010large} \cite{sun2017sequence} \cite{li2020protein} \cite{czibula2021autoppi}.
    
    \item \textbf{Bộ mô tả đặc trưng LD}: bộ mô tả cục bộ hay LD (local descriptor) thuộc nhóm bộ mô tả chia trình tự thanh các phân nhỏ hơn và chạy các tính toán đặc trưng axit amin trên các phần nhỏ hơn đó rồi ghép lại. LD chia trình tự axit amin của protein thành bốn phần bằng nhau, 10 đoạn sẽ được tạo ra từ các phần liên tiếp mà không chứa toàn bộ trình tự \cite{yang2010prediction} (Hình \ref{fig:LD}). Bốn đoạn (A, B, C, D) tương ứng bốn phần chia ban đầu với độ dài $\frac{1}{4}$ trình tự. Ba đoạn (E, F, G) có độ dài bằng $\frac{1}{2}$ trình tự. Hai đoạn (H, I) có độ dài bằng $\frac{3}{4}$ trình tự. Đoạn thứ 10 hay J là một đoạn ở giữa với độ dài bằng 75\% trình tự. Với mỗi đoạn, ta tính bộ đặc trưng đếm axit amin (amino acid count feature) mà nổi bật là đặc trưng thành phần-chuyển dịch-phân bố hay CTD (composition-transition-distribution) sử dụng bộ ba liên tiếp cho mỗi đoạn và thu được vector đặc trưng 63 chiều cho mỗi mảnh tính toán, tổng cộng thu được $63\times10=630$ đặc trưng cho vector đặc trưng sau cùng. Bộ mô tả này đã được sử dụng trong các nghiên cứu \cite{zhou2011prediction} \cite{chen2019lightgbm} \cite{zhang2019protein} \cite{li2020protein}
    \item \textbf{Bộ mô tả đặc trưng PseAAC}: bộ mô tả thành phần giả axit amin hay PseAAC (pseudo amino acid composition) \cite{chou2001prediction} kết hợp thông tin về thành phần và trình tự axit amin của chuỗi protein để tạo ra vector đặc trưng ($Z$) $(20 + \lambda)$-chiều với $\lambda$ là hệ số tương quan axit amin còn 20 là số axit amin tự nhiên. 
    
    \FloatBarrier
    \begin{figure}[htp]
        \centering
        \includegraphics[width=420pt]{images/LD.png}
        \caption{\textbf{Bộ mô tả đặc trưng cục bộ (LD)} \cite{wang2017protein}}
        \label{fig:LD}
    \end{figure}
    \FloatBarrier
    % \{some space}
    % \;
    % \quad
    % \qquad
    % \phantom{space of which length is equal to this text}
    \[ Z = \{z_{1}, z_{2},\ldots, z_{20}, \ldots, z_{20+\lambda}\} \quad  (\lambda < L) \]
     
    
    
    \[
        z_{\eta} =
        \begin{cases}
            \frac{\displaystyle f_{\eta}}{\displaystyle\sum_{\eta=1}^{20}f_{\eta}+\omega \displaystyle\sum_{\eta=1}^{20}\tau_{\eta}}, & 1\le\eta\le20, \\
            \frac{\displaystyle \omega\tau_{\eta-20}}{\displaystyle\sum_{\eta=1}^{20}f_{\eta}+\omega \displaystyle\sum_{\eta=1}^{20}\tau_{\eta}}, & 21\le\eta\le20+\lambda.
        \end{cases}
    \]
    Trong đó $L$ là độ dài của trình tự protein, $\omega$ là trọng số, $f_{\eta}$ là tần số xuất hiện của $\eta$ axit amin trong trình tự protein $Z$, $\tau_{k}$ là hệ số tương quan axit amin bậc $k$ và được tính theo công thức sau
    \[
        \tau_{k} = \frac{1}{L-k} \sum_{1}^{L-k} F_{i,i+k} \quad (k<L)
    \]
    % btw, khi các biểu thức lồng nhau,
    % chỉ có VN mới lần lượt dùng (), [], {} từ trong ra ngoài
    % thực tế chỉ dùng đến (), với kích thước tăng dần
    \[
        F_{i, i+k} = \dfrac{
            {\left(M(Re_{i}) - M(Re_{i+k})\right)}^{2}
            + {\left(H_{A}(Re_{i}) - H_{A}(Re_{i+k})\right)}^{2}
            + {\left(H_{B}(Re_{i}) - H_{B}(Re_{i+k})\right)}^{2}}{3}
    \]
    \par trong đó $M(Re_{i}), H_{A}(Re_{i})$ và $H_{B}(Re_{i})$ là khối lượng chuỗi bên, giá trị kị nước và giá trị ưa nước tương ứng của gốc axit amin thứ $i$
    
    Bộ mô tả này được sử dụng trong các nghiên cứu \cite{pan2010large} \cite{zhao2012predicting} \cite{chen2019lightgbm} \cite{tian2019predicting} \cite{li2020protein} 

\end{itemize}

Như vậy, việc sử dụng ba bộ mô tả trên có thể trích xuất ra được thông tin toàn cục về tính lưỡng cực và thể tích chuỗi bên của trình tự (bộ mô tả CT), thông tin về các đặc trưng đếm axit amin của các mảnh trình tự con (bộ mô tả LD), thông tin về trộn lẫn thành phần và trinh tự axit amin (bộ mô tả PseAAC). 

\par Với dạng mã hóa ma trận, tôi sử dụng vector nhúng skip-gram và one-hot cho axit amin từ nghiên cứu của Chen và cộng sự \cite{chen2019multifaceted}, đây là một dạng vector nhúng tốt nhất được tìm ra trong nghiên cứu của họ. Skip-gram là một mô hình mạng nơ-ron nhân tạo giúp sinh vector nhúng cho các từ, kí tự xuất hiện xung quanh một từ, kí tự cho trước \cite{mikolov2013efficient}. Trong trường hợp này, mô hình skip-gram được tiền huấn luyện trên các tập dữ liệu trình tự axit amin để học được các biểu diễn vector tính toán khả năng các axit amin hay xuất hiện xung quanh một axit amin cho trước. Ở nghiên cứu của Chen năm 2019, tác giả tạo vector nhúng skip-gram kích thước 5 cho mỗi axit amin và lưu nó ở một dạng bảng. Ngoài ra Chen còn ghép nối vector nhúng này với một vector one-hot phân nhóm các axit amin theo tiêu chuẩn bộ ba liên tiếp (CT) với kích thước 7 \cite{shen2007predicting}. Khi tạo dạng biểu diễn ma trận, ở đây tôi áp dụng chuẩn hóa các trình tự cùng một độ dài là 2000 do phần lớn các trình tự protein có độ dài trong khoảng từ 200-1200, cắt bớt vỡi những trình tự dài hơn từ bên phải, và đệm thêm vào bên phải với những trình tự ngắn hơn. 

\subsubsection*{Pha học đơn trình tự}

\par Học đơn trình tự là pha thứ hai trong kiến trúc MCAPS với mục đích học các biểu diễn ở mỗi trình tự trong cặp. Ở pha này, tôi sử dụng kiến trúc song sinh với mạng tích chập sâu để trích xuất đặc trưng cục bộ từ biểu diễn ma trận. Trong mạng tích chập, có 3 khối tích chập xếp liên tiếp nhau tạo thành mạng tích chập sâu với số bộ lọc ở đơn vị tích chập sau gấp đôi so với số bộ lọc đơn vị trước (64-128-256) giống với kiến trúc DPPI \cite{hashemifar2018predicting}, sau lớp tích chập là đến với hàm kích hoạt LeakyReLU. Đầu ra qua hàm kích hoạt sẽ được đi vào hai phần, phần thứ nhất là lớp gộp cực đại toàn cục 1D và chuyển ra ngoài luồng truyền của mạng tích chập để tích lũy trong một mô-đun lưu trữ, phần thứ hai là lớp gộp cực đại 1D (Max-pooling 1D) để tiếp tục truyền đi qua các khối tích chập tiếp theo. Thông tin của mỗi trình tự trong cặp trình tự sẽ được truyền qua các khối tích chập chia sẻ trọng số (kiến trúc song sinh) và trích xuất ra các thông tin gộp toàn cục ở mỗi đơn vị lưu trữ tương ứng với mỗi trình tự. Các thông tin gộp toàn cục này biểu diễn cho các thông tin chính về đặc điểm cục bộ của trình tự protein, các khối tích chập phía sau sẽ trích xuất ra được các đặc trưng cục bộ trừu tượng hơn về mỗi trình tự protein.

\par Mô-đun lưu trữ ghép các gộp toàn cục theo độ sâu của mỗi trình tự thành một vector đại diện cho mỗi trình tự. Việc ghép các gộp toàn cục theo độ sâu là một cách làm tốt để lưu trữ các thông tin từ các tầng phía trước, tránh việc mất mát nhiều thông tin khi truyền qua các tầng sâu của mạng. Vector ghép gộp toàn cục này sau đó sẽ được ghép với vector trích xuất từ ba bộ mô tả để tạo ra dạng vector cuối cùng đại diện cho mỗi trình tự. Vector đặc trưng sau cung tổng hợp các đặc trưng hóa lí từ các bộ mô tả đặc trưng và các đặc trưng cục bộ của các axit amin gần nhau đã được trích xuất qua các tầng của mạng nơ-ron tích chập chia sẻ trọng số. Hai vector này tiếp tục được truyền qua kiến trúc song sinh của một mạng nơ-ron sâu để tinh chỉnh lại các đặc trưng quan trọng hơn. Việc sử dụng kiến trúc mạng song sinh với hai luồng truyền thông tin giúp mạng nơ-ron sẽ trích xuất cả các đặc trưng về mối quan hệ qua lại giữa hai trình tự trong cặp ngoài các đặc trưng hóa lí và đặc trưng cục bộ nhóm axit amin, để rồi phần nào đó học ra được các đặc trưng theo cặp quy định hai trình tự tương tác hay không tương tác.

\subsubsection*{Pha học cặp trình tự và trích xuất vector học biểu diễn}
\par Pha thứ ba là học cặp trình tự, ở đây hai vector bao gồm các đặc trưng trích xuất từ hai trình tự protein trong cặp từ pha trước sẽ được ghép vào thành một vector duy nhất đại diện cho cặp trình tự. Vector cặp trình tự này sau đó được truyền qua một mạng perceptron đa tầng để đưa ra kết quả dự đoán về tương tác protein-protein. Khi huấn luyện mạng nơ-ron MCAPS trước, ta có thể thu được dạng vector học biểu diễn cho cặp trình tự bao gồm các đặc trưng giúp thuật toán học máy LGBM phía sau có thể phân lớp cặp trình tự này vào lớp tương tác hay không tương tác dễ hơn.

\subsubsection*{Pha dự đoán tương tác protein-protein bởi LGBM}

\par Pha thứ tư là pha dự đoán tương tác protein-protein được thực hiện bởi LGBM, trong đó trước hết ta sẽ phải truyền vector học biểu diễn đã được học từ MCAPS vào để huấn luyện mô hình LGBM. Sau khi huấn luyện xong, LGBM sẽ đưa ra dự đoán xác suất tương tác là một con số nằm giữa 0 và 1. Đối với các dữ liệu mới cần đưa ra dự đoán, ta lần lượt truyền các dữ liệu đó qua mạng nơ-ron MCAPS và qua mô hình LGBM đã được huấn luyện để đưa ra xác suất dự đoán. 


\par LGBM là một hệ thống tăng cường độ dốc (gradient boosting) dựa trên thuật toán cây quyết định được phát triển bởi Microsoft vào năm 2016 có khả năng huấn luyện và đưa ra dự đoán nhanh chóng, hiệu năng cao và phân tán \cite{ke2017lightgbm}. LGBM sử dụng thuật toán dựa trên biểu đồ tần suất, biến đổi các giá trị đặc trưng liên tục thành các giá trị rời rạc để đẩy nhanh quá trình huấn luyện và giảm thiểu bộ nhớ tiêu thụ. Trái ngược với các thuật toán tăng cường độ dốc khác, thay vì cách tiếp cận tách theo chiều sâu (level-wise splitting), LGBM sử dụng cách tiếp cận tách theo lá (leaf-wise splitting). Thuật toán tách theo lá giảm nhiều mất mát hơn so với thuật toán tách theo chiều sâu, dẫn đến độ chính xác tốt hơn. Sự phát triển khéo léo của lá dẫn đến sự phát triển của cây quyết định không cân đối và có thể dẫn đến quá khớp. Để tránh hiện tượng quá khớp, LGBM hạn chế độ sâu tối đa trong quá trình phát triển cây. LGBM đã được sử dụng trong một số nghiên cứu trước đây về dự đoán PPI \cite{chen2019lightgbm} \cite{mahapatra2021improved}. 




\subsubsection{Thiết lập tham số cho mô hình và huấn luyện}

\par Đối với các mô hình FSNN-LGBM, PIPR và D-SCRIPT, tôi sử dụng các tham số xây dựng và huấn luyện mô hình giống như từ bái báo gốc của mô hình. Đối với mô hình mạng nơ-ron MCAPS, tôi sử dụng các siêu tham số đã được tối ưu như ở bảng \ref{table:hyper-mcaps}, còn đối với mô hình LGBM, tôi sử dụng các siêu tham số mặc định ban đầu của thư viện LightGBM \cite{ke2017lightgbm}. Phần làm nên khác biệt và hiệu quả của mô hình chính là đến từ mạng MCAPS phía trước của LGBM.


\begin{table}[htp]
\caption{\textbf{Các siêu tham số xây dựng và huấn luyện mô hình MCAPSL} }
\label{table:hyper-mcaps}
\begin{tabularx}{\textwidth}{p{0.4\textwidth}X}
    \specialrule{1.5pt}{1pt}{1pt}
    \textbf{Siêu tham số} & \textbf{Giá trị} \\
    \specialrule{1.5pt}{1pt}{1pt}
    Số đơn vị tích chập & 3\\
    Số bộ lọc tích chập qua các đơn vị & 64-128-256\\
    Kích thước các bộ lọc & (2, 3, 4, 5)\\
    Padding & same \\
    Số đơn vị ẩn MLP trước khi ghép & 256-128 \\
    Số đơn vị ẩn MLP sau khi ghép & 100-64\\
    Dropout trong MLP & 0.2\\
    Hàm kích hoạt & LeakyReLU($\alpha=0.02$) \\
    Hàm tối ưu & Adam(lr=1e-3, epsilon=1e-6, amsgrad=True)\\
    Hàm mất mát & binary crossentropy \\
    Epoch & 100 \\
    Kích thước batch & 64 \\
    \specialrule{1.5pt}{1pt}{1pt}
\end{tabularx}
\end{table}

\par Trong nghiên cứu, tôi có thử các siêu tham số khác nhau và thu được các chất lượng huấn luyện mô hình MCAPS khác nhau nhưng bộ siêu tham số tôi sử dụng ở đây đã là tối ưu hài hòa về cả thời gian huấn luyện và chất lượng mô hình trong đó ưu tiên phần nhiều về chất lượng mô hình. Một số siêu tham số được sử dụng giống với một vài nghiên cứu trước đây, ví dụ như hàm tối ưu Adam với thiết lập như trên từ nghiên cứu của Chen và cộng sự năm 2019 \cite{chen2019multifaceted}, MLP và dropout giống như trong nghiên cứu của Mahapatra và cộng sự năm 2021 \cite{mahapatra2021improved}. Tuy có sự truyền cảm hứng từ các nghiên cứu trước song để có một mô hình hiệu quả hài hòa với tổng thể kiến trúc và tập dữ liệu, cần thử nghiệm và hiệu chỉnh lại các siêu tham số, cuối cùng thu được bộ các siêu tham số giống như trên. Việc có chung một bộ siêu tham số sử dụng cho nhiều tập dữ liệu là một điều có thể chấp nhận được vì theo định lý ``Không có bữa trưa miễn phí'' \cite{wolpert1997no} thì không có một mô hình tối ưu hay thống kê nào có thể làm tốt trên mọi tập dữ liệu, mọi tác vụ, chỉ có thể ở mức ``tốt trong khoảng chấp nhận được''.


\subsection{Kết quả trên tập dữ liệu học nội tại}
Để kiểm tra khả năng học của các mô hình, tôi thực hiện kiểm định chéo 5-fold cho các mô hình trên các tập dữ liệu học nội tại bao gồm tập dữ liệu Martin \textit{H. pylori} (2005), tập dữ liệu Guo nấm men (2008) và tập dữ liệu Pan người (2010), quá trình đó lặp lại năm lần rồi tính kết quả trung bình với cả 8 độ đo (Acc, Pre, Rec, Spe, F1, MCC, AUROC, AUPRC). 

% \begin{table}[htp]
%     \centering
%     \begin{tabular}{cc}
%         \specialrule{1.5pt}{1pt}{1pt}
%         \textbf{Kí hiệu} & \textbf{Ý nghĩa} \\
%         \specialrule{1pt}{1pt}{1pt}
%         Acc & Accuracy \\
%         Pre & Precision \\
%         Rec & Recall \\
%         Spe & Specificity \\
%         F1 & F1-score \\
%         MCC & Hệ số tương quan Matthew  \\
%         AUROC & Diện tích dưới đường cong ROC \\
%         AUPRC & Diện tích dưới đường cong PRC\\
%         \specialrule{1.5pt}{1pt}{1pt}
%     \end{tabular}
%     \caption{\textbf{Các độ đo và viết tắt}.}
%     \label{table:measurements}
% \end{table}

\subsubsection*{Tập dữ liệu Martin \textit{H.pylori} (2005)}

\FloatBarrier
\begin{table}[htp]
    \centering
    \begin{tabularx}{\textwidth}{Xllllllll}
        \specialrule{1.5pt}{1pt}{1pt}
        \textbf{Mô hình} & \textbf{Acc} & \textbf{Pre} & \textbf{Rec} & \textbf{Spe} & \textbf{F1} & \textbf{MCC} & \textbf{AUROC} & \textbf{AUPRC} \\
        \specialrule{1pt}{1pt}{1pt}
        PIPR & 80.84 & 81.44 & 81.55 & 80.32 & 81.43 & 61.69 & 87.11 & 83.90 \\
        FSNN-LGBM & 96.49 & 96.03 & 97.23 & 95.69 & 96.62 & 92.98 & 98.63 & 98.40 \\
        D-SCRIPT & 72.18 & 85.25 & 55.40 & 65.29 & 67.16 & 48.88 & 83.19 & 81.47 \\
        MCAPSL & \textbf{97.13} & \textbf{96.92} & \textbf{97.57} & \textbf{96.67} &\textbf{97.24} & \textbf{94.27} & \textbf{98.86} & \textbf{98.63} \\
        \specialrule{1.5pt}{1pt}{1pt}
    \end{tabularx}
    \caption{\textbf{Kết quả học trên tập dữ liệu Martin \textit{H. pylori} (2005)}}
    \label{table:h-pylori-dataset}
\end{table}
\FloatBarrier

\subsubsection*{Tập dữ liệu Guo nấm men (2008)}

\FloatBarrier
\begin{table}[htp]
    \centering
    \begin{tabularx}{\textwidth}{Xllllllll}
        \specialrule{1.5pt}{1pt}{1pt}
        \textbf{Mô hình} & \textbf{Acc} & \textbf{Pre} & \textbf{Rec} & \textbf{Spe} & \textbf{F1} & \textbf{MCC} & \textbf{AUROC} & \textbf{AUPRC} \\
        \specialrule{1pt}{1pt}{1pt}
        PIPR & 96.47&96.31&96.67&96.65&96.48&92.95&98.69&98.06\\
        FSNN-LGBM & 98.46&98.73&98.18&98.74&98.45&96.92&99.77&99.76   \\
        D-SCRIPT & 49.82&53.81&4.95&50.18&9.72&0.67&51.00&51.85 \\
        MCAPSL & \textbf{99.38} & \textbf{99.29} & \textbf{99.48} & \textbf{99.28} &\textbf{99.38}&\textbf{98.77}&\textbf{99.85}&\textbf{99.80}\\
        \specialrule{1.5pt}{1pt}{1pt}
    \end{tabularx}
    \caption{\textbf{Kết quả học trên tập dữ liệu Guo nấm men (2008)}}
    \label{table:guo-dataset}
\end{table}
\FloatBarrier


\subsubsection*{Tập dữ liệu Pan người (2010)}

\FloatBarrier
\begin{table}[htp]
    \centering
    \begin{tabularx}{\textwidth}{Xllllllll}
        \specialrule{1.5pt}{1pt}{1pt}
        \textbf{Mô hình} & \textbf{Acc} & \textbf{Pre} & \textbf{Rec} & \textbf{Spe} & \textbf{F1} & \textbf{MCC} & \textbf{AUROC} & \textbf{AUPRC} \\
        \specialrule{1pt}{1pt}{1pt}
        PIPR & 98.26&98.68&97.40&97.93&98.04&96.49&99.22&98.83\\
        FSNN-LGBM & 99.50&99.48&99.39&99.58&99.43&98.98&99.70&99.57\\
        D-SCRIPT & \multicolumn{8}{c}{N/A} \\
        MCAPSL & \textbf{99.62} & \textbf{99.52} & \textbf{99.63} & \textbf{99.62} &\textbf{99.58}&\textbf{99.24}&\textbf{99.96}&\textbf{99.96}\\
        \specialrule{1.5pt}{1pt}{1pt}
    \end{tabularx}
    \caption{\textbf{Kết quả kiểm định chéo 5-fold trên tập dữ liệu Pan người (2010)}}
    \label{table:pan-dataset}
\end{table}
\FloatBarrier

\par Ba bảng \ref{table:h-pylori-dataset} \ref{table:guo-dataset}, \ref{table:pan-dataset} cho biết về các độ đo chất lượng của các mô hình khi thực hiện kiểm định chéo 5-fold trên ba tập dữ liệu Martin \textit{H. pylori} (2005), Guo nấm men (2008) và Pan người (2010) tương ứng. \textbf{Trên ba tập dữ liệu, mô hình MCAPSL đều vượt trội hơn các mô hình khác về tất cả các độ đo khác nhau}. Trong phần phân tích này, tôi sẽ tập trung về so sánh độ chính xác giữa các mô hình, đây là độ đo được ưu tiên đối với tác vụ phân lớp nhị phân trên tập dữ liệu cân bằng.

\par Trên tập dữ liệu Martin (2005) (2623 cặp), độ chính xác của mô hình là MCAPSL là \textbf{97.13\%, hơn 0.64\% so với mô hình tốt thứ hai là FSNN-LGBM, hơn 16.28\% so với mô hình tốt thứ ba là PIPR} và hơn 24.92\% so với mô hình kém nhất là D-SCRIPT. Trên tập dữ liệu Guo (2008) (11198 cặp), độ chính xác của mô hình là MCAPSL là \textbf{99.38\%, hơn 0.92\% so với mô hình tốt thứ hai là FSNN-LGBM, hơn 2.91\% so với mô hình tốt thứ ba} là PIPR và hơn gần 50\% so với mô hình kém nhất là D-SCRIPT. Trên tập dữ liệu Pan (2010) (61891 cặp), độ chính xác của mô hình là MCAPSL là \textbf{99.62\%, hơn 0.12\% so với mô hình tốt thứ hai là FSNN-LGBM, hơn 1.36\%} so với mô hình tốt thứ ba, trường hợp này D-SCRIPT không thu được số liệu do hạn chế về tài nguyên tính toán.

\par Với kích thước dữ liệu tăng dần thì khoảng cách chênh lệch giữa mô hình tốt nhất MCAPSL với các mô hình khác càng được thu hẹp, điều đó phản ánh về chất lượng của các mô hình học sâu tăng dần với kích thước dữ liệu. Trên tập dữ liệu kích thước nhỏ Martin (2005), các mô hình học sâu hay học máy từng được phát triển thường đạt được độ chính xác dao động từ 70-87\% (ở đây PIPR và D-SCRIPT là mô hình dựa trên trình tự tốt nhất nhưng cũng chỉ đạt được con số 80\% và 72\%), vậy mà mô hình MCAPSL đạt được hơn 97\% và FSNN-LGBM hơn 96\%, điều này là do kiến trúc lai giữa học máy và học sâu được sử dụng trong mô hình. Với tập dữ liệu kích thước lớn hơn như Guo (2008) và Pan (2010) thì độ chính xác của các mô hình thường cao trên 96\% và 98\% tương ứng, điều này là dễ hiểu với các mô hình học sâu tận dụng được sức mạnh của dữ liệu lớn. Mô hình D-SCRIPT có độ chính xác và các độ đo khác thấp trên Guo (2008) kết quả này không khác gì dự đoán một cách ngẫu nhiên, mô hình gần như không học được gì từ dữ liệu.




% \subsection*{Tập dữ liệu mất cân bằng}
% \subsubsection{Tập dữ liệu liên loài Yang (2021)}

% \FloatBarrier
% \begin{table}[htp]
% 	\centering
% 	% tip
% 	% select text
% 	% then press "Ctrl + B" to wrap the text with \textbf{}
% 	%     DENV
% 	% HIV
% 	% Hepatitis
% 	% Herpes
% 	% Influenza
% 	% Papilloma
% 	% SARS2
% 	% ZIKV
% 	\begin{tabular}{lllllll}
% 		\specialrule{1.5pt}{1pt}{1pt}
% 		\textbf{Loài}                     & \textbf{Mô hình} & \textbf{Pre}            & \textbf{Rec}   & \textbf{Spe}   & \textbf{F1}    & \textbf{AUPRC} \\
% 		\specialrule{1pt}{1pt}{1pt}
% 		\multirow{4}{*}{Virus Dengue}     & PIPR             & 53.04                   & 38.26          & 93.99          & 44.32          & 67.65          \\
% 		                                  & D-SCRIPT         & \multicolumn{5}{c}{N/A}                                                                     \\
% 		                                  & FSNN-LGBM        & 89.79                   & 82.41          & 99.06          & 85.91          & 95.21          \\
% 		                                  & MCAPSL           & \textbf{94.45}          & \textbf{85.87} & \textbf{99.49} & \textbf{89.96} & \textbf{96.71} \\
% 		\hline
% 		\multirow{4}{*}{Virus HIV}        & PIPR             & 91.63                   & 89.14          & 98.92          & 90.35          & 97.12          \\
% 		                                  & D-SCRIPT         & \multicolumn{5}{c}{N/A}                                                                     \\
% 		                                  & FSNN-LGBM        & 94.93                   & 95.75          & 99.48          & 95.31          & 96.02          \\
% 		                                  & MCAPSL           & \textbf{98.77}          & \textbf{97.67} & \textbf{99.88} & \textbf{98.23} & \textbf{99.79} \\
% 		\hline
% 		\multirow{4}{*}{Virus Hepatitis}  & PIPR             & 60.17                   & 47.34          & 94.86          & 52.91          & 72.43          \\
% 		                                  & D-SCRIPT         & \multicolumn{5}{c}{N/A}                                                                     \\
% 		                                  & FSNN-LGBM        & 91.17                   & 87.92          & 99.15          & 89.49          & 96.52          \\
% 		                                  & MCAPSL           & \textbf{94.14}          & \textbf{89.46} & \textbf{99.44} & \textbf{91.74} & \textbf{96.74} \\
% 		\hline
% 		\multirow{4}{*}{Virus Herpes}     & PIPR             & 69.87                   & 65.66          & 96.58          & 67.65          & 83.11          \\
% 		                                  & D-SCRIPT         & \multicolumn{5}{c}{N/A}                                                                     \\
% 		                                  & FSNN-LGBM        & 82.53                   & 84.40          & 98.20          & 83.43          & 87.20          \\
% 		                                  & MCAPSL           & \textbf{91.90}          & \textbf{92.41} & \textbf{99.19} & \textbf{92.15} & \textbf{97.53} \\
% 		\hline
% 		\multirow{4}{*}{Virus Influenza}  & PIPR             & 73.04                   & 69.56          & 96.97          & 71.25          & 85.52          \\
% 		                                  & D-SCRIPT         & \multicolumn{5}{c}{N/A}                                                                     \\
% 		                                  & FSNN-LGBM        & 93.05                   & 91.39          & 99.32          & 92.21          & 97.26          \\
% 		                                  & MCAPSL           & \textbf{95.68}          & \textbf{93.00} & \textbf{99.58} & \textbf{94.32} & \textbf{98.55} \\
% 		\hline
% 		\multirow{4}{*}{Virus Papilloma}  & PIPR             & 72.50                   & 67.93          & 96.82          & 70.14          & 85.45          \\
% 		                                  & D-SCRIPT         & \multicolumn{5}{c}{N/A}                                                                     \\
% 		                                  & FSNN-LGBM        & 89.51                   & 88.47          & 98.96          & 88.98          & 94.49          \\
% 		                                  & MCAPSL           & \textbf{95.39}          & \textbf{92.47} & \textbf{99.55} & \textbf{93.91} & \textbf{98.22} \\
% 		\hline
% 		\multirow{4}{*}{Virus SARS-CoV-2} & PIPR             & 30.84                   & 18.63          & 92.17          & 23.14          & 56.03          \\
% 		                                  & D-SCRIPT         & \multicolumn{5}{c}{N/A}                                                                     \\
% 		                                  & FSNN-LGBM        & 90.31                   & 80.10          & 99.12          & 84.80          & 92.21          \\
% 		                                  & MCAPSL           & \textbf{92.73}          & \textbf{82.40} & \textbf{99.35} & \textbf{87.26} & \textbf{93.10} \\
% 		\hline
% 		\multirow{4}{*}{Virus Zika}       & PIPR             & 67.45                   & 60.48          & 96.09          & 63.62          & 78.41          \\
% 		                                  & D-SCRIPT         & \multicolumn{5}{c}{N/A}                                                                     \\
% 		                                  & FSNN-LGBM        & 95.07                   & 89.57          & 99.53          & 92.23          & 96.48          \\
% 		                                  & MCAPSL           & \textbf{98.05}          & \textbf{90.97} & \textbf{99.82} & \textbf{94.38} & \textbf{97.69} \\
% 		\specialrule{1.5pt}{1pt}{1pt}
% 	\end{tabular}
% 	\caption{\textbf{Kết quả kiểm định chéo 5-fold học trên tập dữ liệu liên loài Yang (2021).}}
% \end{table}
% \FloatBarrier

% \begin{table}[htp]
%     \centering
%     \begin{tabularx}{\textwidth}{Xlllll}
%         \hline
%         Species & Model & AUPR & Precision & Recall & AUROC \\
%         \hline
%         \multirow{3}{*}{M. musculus} & PIPR & 0.526 & 0.734 & 0.331 & 0.39 \\
%          & D-SCRIPT & & & & \\
%          & D-HYBRID & & & & \\
%         \hline
%     \end{tabularx}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table}

\subsection{Kết quả trên tập dữ liệu kiểm tra}

% lưu ý
% việc sử dụng \begin{table}[htp]
% nhất là nhiều bảng liên tiếp
% có thể khiến vị trí của bảng không nằm đúng chỗ (đúng section, subsection, subsubsection)
% để khắc phục,
% thêm \FloatBarrier đằng trước \begin{table}[htp]
% và thêm \FloatBarrier vào sau \end{table}
% vậy thôi!

Sau khi đánh giá khả năng học nội tại của mô hình bằng kiểm định chéo 5-fold trên các ba tập dữ liệu tiêu chuẩn ở phần trước, phần này tập trung vào đánh giá khả năng mở rộng, tổng quát hóa của mô hình trên các dữ liệu mới. Ở đây, tôi huấn luyện các mô hình trên hai tập dữ liệu ở người của Pan (2010) và Sledzieski (2021), sau đó đánh giá trên các tập kiểm tra bao gồm tập Li người (2018) để kiểm tra khả năng mở rộng trên cùng loài người với các dữ liệu mới, tập chéo loài Sledzieski (2021) bao gồm năm sinh vật mô hình khác để kiểm tra khả năng mở rộng ở các loài khác người, và tập liên loài virus-người Yang (2021) để kiểm tra khả năng mở rộng ở các loài khác tương tác với người. Vì tập dữ liệu Li người (2018) chỉ gồm các dữ liệu cặp tương tác, hay các cặp dương tính nên độ chính xác bằng độ nhạy, độ tụ trong trường hợp này là 100\% do không có dữ liệu âm tính nên không tồn tại dương tính giả; diện tích dưới đường cong ROC trong trường hợp này không tính được do không có mẫu âm tính. Còn ở tập dữ liệu Sledzieski chéo loài (2021) và tập dữ liệu Yang liên loài (2021) là các tập dữ liệu mất cân bằng nên tôi sử dụng ba độ đo là độ tụ, độ nhạy và điểm F1 là trung bình điều hòa của hai độ đo đó để đánh giá. Ở đây ta quan tâm nhiều về việc gọi ra các cặp dương tính hay các cặp tương tác nên ta không sử dụng độ đặc hiệu.

\subsubsection{Tập dữ liệu người Li (2018)}

% \FloatBarrier
% \begin{table}[htp]
%     \centering
%     \begin{tabularx}{\textwidth}{Xllllllll}
%         \specialrule{1.5pt}{1pt}{1pt}
%         \textbf{Mô hình} & \textbf{Acc} & \textbf{Pre} & \textbf{Rec} & \textbf{Spe} & \textbf{F1} & \textbf{MCC} & \textbf{AUROC} & \textbf{AUPRC} \\
%         \specialrule{1pt}{1pt}{1pt}
%          & 0.983 & 0.987 & 0.974 & 0.979 & 0.980 & 0.965 & 0.992 & 0.988\\
%         FSNN-LGBM & 0.995 & 0.995 & 0.994 & 0.996 & 0.994 & 0.990 & 0.997 & 0.996 \\
%         D-SCRIPT & N/A&N/A&N/A &N/A & N/A & N/A & N/A & N/A \\
%         MCAPSL & \textbf{0.971} & \textbf{0.969} & \textbf{0.976} & \textbf{0.967} &\textbf{0.971}&\textbf{0.943}&\textbf{0.989}&\textbf{0.986}\\
%         \specialrule{1.5pt}{1pt}{1pt}
%     \end{tabularx}
%     \caption{Chất lượng của các mô hình trên tập dữ liệu Pan người (2010)  \cite{pan2010large}}
%     \label{table:pan-dataset}
% \end{table}
% \FloatBarrier
\FloatBarrier
\begin{table}[htp]
	\centering
	\begin{tabular}{lllllll}
		\specialrule{1.5pt}{1pt}{1pt}
		\textbf{Tập kiểm tra}      & \textbf{Mô hình} & \textbf{Rec}   \\
		\specialrule{1pt}{1pt}{1pt}

		\multirow{4}{*}{HPRD}      & PIPR             & 91.95          \\
		                           & D-SCRIPT         & N/A          \\
		                           & FSNN-LGBM        & 94.19          \\
		                           & MCAPSL           & \textbf{94.76} \\
		\hline
		\multirow{4}{*}{DIP}       & PIPR             & 93.46          \\
		                           & D-SCRIPT         & N/A          \\
		                           & FSNN-LGBM        & 93.25          \\
		                           & MCAPSL           & \textbf{95.36} \\
		\hline
		\multirow{4}{*}{HIPPIE HQ} & PIPR             & 91.23          \\
		                           & D-SCRIPT         & N/A          \\
		                           & FSNN-LGBM        & 91.61          \\
		                           & MCAPSL           & \textbf{93.36} \\
		\hline
		\multirow{4}{*}{HIPPIE LQ} & PIPR             & 91.53          \\
		                           & D-SCRIPT         & N/A            \\
		                           & FSNN-LGBM        & 91.91          \\
		                           & MCAPSL           & \textbf{93.37} \\
		\specialrule{1.5pt}{1pt}{1pt}
	\end{tabular}
	\caption{\textbf{Kết quả kiểm tra trên tập dữ liệu Li người (2018) với tập dữ liệu huấn luyện Pan người (2010)}}
	\label{table:li-dataset1}
\end{table}
\FloatBarrier

\FloatBarrier
\begin{table}[htp]
	\centering
	\begin{tabular}{lllllll}
		\specialrule{1.5pt}{1pt}{1pt}
		\textbf{Tập kiểm tra}      & \textbf{Mô hình} & \textbf{Rec}   \\
		\specialrule{1pt}{1pt}{1pt}

		\multirow{4}{*}{HPRD}      & PIPR             & 35.18          \\
		                           & D-SCRIPT         & 12.63          \\
		                           & FSNN-LGBM        & 23.12          \\
		                           & MCAPSL           & \textbf{40.38} \\
		\hline
		\multirow{4}{*}{DIP}       & PIPR             & 40.26          \\
		                           & D-SCRIPT         & 11.44          \\
		                           & FSNN-LGBM        & 26.23          \\
		                           & MCAPSL           & \textbf{47.76} \\
		\hline
		\multirow{4}{*}{HIPPIE HQ} & PIPR             & 32.58          \\
		                           & D-SCRIPT         & 12.54          \\
		                           & FSNN-LGBM        & 26.60          \\
		                           & MCAPSL           & \textbf{44.55} \\
		\hline
		\multirow{4}{*}{HIPPIE LQ} & PIPR             & 19.99          \\
		                           & D-SCRIPT         & 7.24           \\
		                           & FSNN-LGBM        & 26.03          \\
		                           & MCAPSL           & \textbf{35.34} \\
		\specialrule{1.5pt}{1pt}{1pt}
	\end{tabular}
	\caption{\textbf{Kết quả kiểm tra trên tập dữ liệu Li người (2018) với tập dữ liệu huấn luyện Sledzieski người (2021)}}
	\label{table:li-dataset2}
\end{table}
\FloatBarrier


\par Ở bảng \ref{table:li-dataset1}, mô hình MCAPSL \textbf{đứng nhất 4/4 lần trên bốn tập dữ liệu}, đạt độ nhạy cao \textbf{khoảng 93-95\%, vượt trội hơn so với mô hình đứng thứ 2 từ 0.5-2}\%. Mô hình đứng thứ hai có thể là PIPR (trên tập DIP) hoặc FSNN-LGBM (trên các tập còn lại). Chất lượng của mô hình thứ 2 và thứ 3 có sự chênh lệch không đáng kể, khoảng từ 0.5 cho tới dưới 2\%. Còn ở bảng \ref{table:li-dataset2}, mô hình MCAPSL \textbf{đứng nhất 4/4 lần trên bốn tập dữ liệu}, đạt độ nhạy thấp hơn khoảng từ \textbf{35-47\%, nhưng vẫn vượt trội hơn so với mô hình đứng thứ 2 từ 5-12}\% trên bốn tập dữ liệu con HPRD, DIP, HIPPIE HQ, HIPPIE LQ. Mô hình đứng thứ hai có thể là PIPR (trên tập HPRD, DIP, HIPPIE HQ) hoặc FSNN-LGBM (trên tập HIPPIE LQ). Sự chênh lệch lần này của mô hình thứ hai và thứ ba tương đối lớn, khoảng từ 6-14\%, chủ yếu là PIPR hơn FSNN-LGBM. Mô hình D-SCRIPT đứng cuối cùng trong cả bốn mô hình với độ nhạy rất thấp dưới 15\%, dao động trong khoảng 7-12\%. 

\par Chất lượng kiểm tra của các mô hình khi huấn luyện trên tập dữ liệu cân bằng Pan người (2010) tương đối tốt và phương sai thấp, khoảng từ 91-95\%, còn chất lượng khi huấn luyện các mô hình trên tập dữ liệu mất cân bằng Sledzieski người (2021) tương đối thấp và phương sai cao, đạt khoảng từ 20-40\%. Như vậy có thể thấy là sử dụng tập huấn luyện cân bằng có hiệu quả mở rộng cùng loài tốt hơn so với dữ liệu huấn luyện mất cân bằng.


\subsubsection{Tập dữ liệu chéo loài Sledzieski (2021)}
\FloatBarrier
\begin{table}[htp]
	\centering
	\begin{tabular}{lllll}
		\specialrule{1.5pt}{1pt}{1pt}
		\textbf{Loài}                     & \textbf{Mô hình} & \textbf{Pre}            & \textbf{Rec}   & \textbf{F1}    \\
		\specialrule{1pt}{1pt}{1pt}
		\multirow{4}{*}{\textit{E. Coli}} & PIPR             & 7.75                    & 77.70          & 14.10          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 8.61                    & 90.70          & 15.72          \\
		                                  & MCAPSL           & \textbf{8.67}           & \textbf{92.35} & \textbf{15.85} \\
		\hline
		\multirow{4}{*}{Ruồi giấm}        & PIPR             & 8.32                    & 85.62          & 15.16          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & \textbf{8.72}           & 91.98          & \textbf{15.93} \\
		                                  & MCAPSL           & 8.70                    & \textbf{92.24} & 15.90          \\
		\hline
		\multirow{4}{*}{Chuột}            & PIPR             & 8.72                    & 89.94          & 15.91          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 8.76                    & 91.64          & 15.99          \\
		                                  & MCAPSL           & \textbf{8.81}           & \textbf{92.44} & \textbf{16.09} \\
		\hline
		\multirow{4}{*}{Giun tròn}        & PIPR             & 8.39                    & 87.34          & 15.31          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 8.75                    & 92.60          & 15.98          \\
		                                  & MCAPSL           & \textbf{8.82}           & \textbf{94.24} & \textbf{16.12} \\
		\hline
		\multirow{4}{*}{Nấm men}          & PIPR             & 8.68                    & 88.70          & 15.81          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 8.76                    & 91.70          & 16.00          \\
		                                  & MCAPSL           & \textbf{8.80}           & \textbf{92.72} & \textbf{16.07} \\
		\specialrule{1.5pt}{1pt}{1pt}
	\end{tabular}
	\caption{\textbf{Kết quả kiểm tra trên tập dữ liệu chéo loài Sledzieski (2021) với tập dữ liệu huấn luyện Pan người (2010)}}
	\label{table:sledzieski-dataset1}
\end{table}
\FloatBarrier

\FloatBarrier
\begin{table}[htp]
	\centering
	\begin{tabular}{lllll}
		\specialrule{1.5pt}{1pt}{1pt}
		\textbf{Loài}                     & \textbf{Mô hình} & \textbf{Pre}   & \textbf{Rec}   & \textbf{F1}    \\
		\specialrule{1pt}{1pt}{1pt}
		\multirow{4}{*}{\textit{E. Coli}} & PIPR             & 39.98          & 18.45          & 25.25          \\
		                                  & D-SCRIPT         & \textbf{74.98} & \textbf{38.20} & \textbf{50.61} \\
		                                  & FSNN-LGBM        & 22.40          & 36.10          & 27.65          \\
		                                  & MCAPSL           & 14.20          & 22.95          & 17.55          \\
		\hline
		\multirow{4}{*}{Ruồi giấm}        & PIPR             & 44.94          & 18.58          & 26.29          \\
		                                  & D-SCRIPT         & \textbf{81.12} & 37.69          & \textbf{51.46} \\
		                                  & FSNN-LGBM        & 20.66          & 31.08          & 24.82          \\
		                                  & MCAPSL           & 25.29          & \textbf{42.76} & 31.78          \\
		\hline
		\multirow{4}{*}{Chuột}            & PIPR             & 63.43          & 41.42          & \textbf{50.11} \\
		                                  & D-SCRIPT         & \textbf{75.61} & 34.44          & 47.33          \\
		                                  & FSNN-LGBM        & 28.07          & 36.10          & 31.58          \\
		                                  & MCAPSL           & 33.66          & \textbf{59.64} & 43.03          \\
		\hline
		\multirow{4}{*}{Giun tròn}        & PIPR             & 49.21          & 19.94          & 28.38          \\
		                                  & D-SCRIPT         & \textbf{81.35} & 29.29          & \textbf{43.07} \\
		                                  & FSNN-LGBM        & 20.55          & 32.30          & 25.12          \\
		                                  & MCAPSL           & 26.91          & \textbf{41.10} & 32.53          \\
		\hline
		\multirow{4}{*}{Nấm men}          & PIPR             & 37.15          & 20.36          & 26.30          \\
		                                  & D-SCRIPT         & \textbf{70.63} & 22.32          & \textbf{33.92} \\
		                                  & FSNN-LGBM        & 17.70          & 31.76          & 22.73          \\
		                                  & MCAPSL           & 18.85          & \textbf{32.66} & 23.90          \\
		\specialrule{1.5pt}{1pt}{1pt}
	\end{tabular}
	\caption{\textbf{Kết quả kiểm tra trên tập dữ liệu chéo loài Sledzieski (2021) với tập dữ liệu huấn luyện Sledzieski người (2021)}}
	\label{table:sledzieski-dataset2}
\end{table}
\FloatBarrier

\par Ở bảng \ref{table:sledzieski-dataset1}, ta thấy MCAPSL thường vượt trội hơn các mô hình khác trên các tập dữ liệu về cả ba độ đo. Về xếp hạng, MCAPSL đứng \textbf{nhất 4/5 lần ở độ tụ}, MCAPSL đứng \textbf{nhất 5/5 lần về độ nhạy}, MCAPSL đứng \textbf{nhất 4/5 lần về điểm F1}. Về độ tụ, mặc dù hay đứng nhất nhưng MCAPSL có độ tụ khá thấp, trong khoảng từ \textbf{8.67-8.82\%, thường chỉ hơn vị trí số hai không đáng kể từ 0.02-0.07\%}. Về độ nhạy, MCAPSL thường dẫn đầu với kết quả tương đối cao từ \textbf{92.24-94.24\%, hơn mô hình tốt nhì đáng kể từ 0.5-1.8\%}. Về điểm F1, MCAPSL đứng đầu với giá trị khá thấp trong khoảng từ \textbf{15.85-16.12\%, hơn không đáng kể mô hình xếp thứ hai từ 0.03-0.1\%}. 

\par Ở bảng \ref{table:sledzieski-dataset2}, ta thấy MCAPSL thường chỉ vượt trội hơn về độ nhạy. Về xếp hạng, MCAPSL đứng \textbf{nhất 4/5 lần ở độ nhạy}. Về độ tụ, thường D-SCRIPT đứng đầu với kết quả khá cao từ 70.63-81.35\%, hơn vị trí thứ nhì thường của PIPR một khoảng đáng kể từ 21-35\%. Về độ nhạy, MCAPSL thường dẫn đầu với kết quả từ \textbf{32.66-59.64\%, hơn vị trí thứ nhì thường hơn từ 2-18\%}. Và ở điểm F1, D-SCRIPT thường đứng đầu với giá trị tương đối cao trong khoảng \textbf{33.92-51.46\% và hơn vị trí số hai từ 3-23\%}.

\par So sánh kết quả hai bảng \ref{table:sledzieski-dataset1}, \ref{table:sledzieski-dataset2}, ta thấy độ tụ tốt nhất huấn luyện ở tập cân bằng (8.67-8.82\%) thấp hơn nhiều so với tập mất cân bằng (70.63-81.35\%), độ nhạy tốt nhất huấn luyện ở tập cân bằng (92.24-94.24\%) cao hơn đáng kể so với trên tập mất cân bằng (32.66-59.64\%), điểm F1 tốt nhất huấn luyện ở tập cân bằng (15.85-16.12\%) thấp hơn nhiều so với trên tập mất cân bằng (33.92-51.46\%). 

\par  Độ nhạy có lẽ là độ đo nên được ưu tiên nhất trong việc phát hiện tương tác mới ở các loài sinh vật chưa được nghiên cứu nhiều mà ta muốn suy diễn tương tác. MCAPSL là mô hình vượt trội hơn hẳn về độ nhạy kể cả học trên tập cân bằng và mất cân bằng so với các mô hình khác. Ở tác vụ suy diễn tương tác chéo loài, việc học trên tập cân bằng sẽ cho kết quả suy diễn về độ nhạy cao nhất trên 90\% nhưng độ tụ thì lại rất thấp dưới 10\%, và việc học trên tập mất cân bằng sẽ cho độ tụ tương đối cao trong khoảng 70-80\% với mô hình tốt nhất D-SCRIPT, 20-40\% với các mô hình còn lại, độ nhạy ở mức trung bình trong khoảng 20-50\%. Khả năng mở rộng dự đoán chéo loài của D-SCRIPT là tốt nhất như đã công bố trong nghiên cứu \cite{sledzieski2021d}.

% \par Hai bảng \ref{table:sledzieski-dataset1}, \ref{table:sledzieski-dataset2} ghi lại kết quả kiểm tra của các mô hình trên các tập dữ liệu các loài sinh vật mô hình khác nhau bao gồm \textit{E.coli}, ruồi giấm, chuột, giun tròn và nấm men khi huấn luyện với tập dữ liệu Pan người (2010) và tập dữ liệu Sledzieski người (2021). Vì các tập dữ liệu kiểm tra là mất cân bằng nên tôi chỉ báo cáo các độ đo như độ tụ, độ nhạy, điểm F1, độ đặc hiệu và diện tích dưới đường cong PRC. 

% \par Ở bảng \ref{table:sledzieski-dataset1}, khi so sánh về độ tụ, độ nhạy, điểm F1 và diện tích dưới đường cong PRC, mô hình MCAPSL thường đứng nhất, chỉ có một số ít MCAPSL đứng số 2 (ví dụ như độ tụ và diện tích dưới đường cong PRC trên tập ruồi giấm chỉ đứng sau FSNN-LGBM). Mặc dù xếp nhất về độ tụ trên phần lớn các tập dữ liệu, MCAPSL chỉ có độ tụ đạt được khá khiêm tốn khoảng 8.6-8.8\%, hơn các mô hình khác không đáng kể khoảng từ 0.03-0.05\%; còn về độ nhạy, MCAPSL đạt kết quả tương đối tốt khoảng 92.8-94.2\%, hơn mô hình tốt nhì chỉ khoảng từ 0.5-2\%. Điều này chỉ ra mô hình mạnh mẽ trong việc tìm kiếm các cặp dương tính hay cặp tương tác trong tổng số các cặp tương tác thực sự tồn tại (độ nhạy cao) nhưng ta chưa chắc có thể tin được vào các kết quả mô hình gọi là dương tính (độ tụ thấp). Còn về độ đặc hiệu thì MCAPSL gần như bao giờ cũng xếp cuối, thường đạt khoảng dưới 5\%, FSNN-LGBM cũng gặp điều tương tự, nhưng PIPR lại có độ đặc hiệu tương đối cao trên 75\%. Điều này thể hiện rằng mô hình MCAPSL và FSNN-LGBM có khả năng phát hiện các cặp âm tính trong tổng số các cặp âm tính tồn tại rất yếu ớt, tuy vậy đây không phải là một độ đo ưu tiên trong trường hợp nghiên cứu về các tương tác vì cái mà ta đang muốn đi tìm, đi xác định là các tương tác.

% \par Ở bảng \ref{table:sledzieski-dataset2}, MCAPSL chỉ đứng thứ nhất về độ nhạy (trừ tập dữ liệu \textit{E. coli}), còn các các độ đo khác thường chỉ xếp thứ 3 và thứ tư. Mô hình D-SCRIPT thường dành vị trí quán quân tại các độ đo khác, chứng tỏ khả năng mở rộng chéo loài rất tốt như đã khẳng định trong nghiên cứu của Sledzieski và cộng sự năm 2021 \cite{sledzieski2021d}. Mô hình MCAPSL có độ nhạy rơi vào khoảng từ 33-60\% và cũng là con số cao nhất trên các tập dữ liệu này so với mô hình khác. Mô hình D-SCIPT thì đạt được độ tụ dao động từ 75-80\%, F1 từ 33-51\%, độ đặc hiệu thì xung quanh 99\%, và diện tích dưới đường cong đạt khoảng 60-75\%. Tuy vượt trội hơn về các độ đo khác nhưng D-SCRIPT vẫn có độ nhạy chưa được cao, vì thế khó phát hiện và gọi ra đầy đủ tương tác ở các sinh vật khác.
% \par Với tác vụ dự đoán chéo loài, việc học trên tập dữ liệu cân bằng khiến cho các mô hình có độ nhạy tương đối cao, tuy nhiên các độ đo còn lại rất thấp (trừ độ đặc hiệu thì PIPR vẫn duy trì ở mức cao), còn việc học trên tập dữ liệu mất cân bằng khiến cho các mô hình có độ tụ phân chia rõ ràng (D-SCRIPT thì có độ tụ cao còn các mô hình còn lại có độ tụ khá thấp), độ nhạy khá thấp, độ đặc hiệu rất cao. Từ đây ta có thể thấy được, nếu muốn tận dụng tính mở rộng ra các loài sinh vật khác khi cho huấn luyện mô hình trên người, ta nên ưu tiên tập huấn luyện cân bằng nếu như ta muốn mô hình có thể gọi ra càng nhiều tương tác thực càng tốt (độ nhạy cao). Có lẽ độ nhạy cao chính là ưu tiên hàng đầu khi dự đoán tương tác protein-protein với các loài sinh vật chưa có nhiều nghiên cứu nhiều về hệ tương tác. 

\subsubsection{Tập dữ liệu liên loài Yang (2021)}
% \par Hai bảng \ref{table:yang-dataset1}, \ref{table:yang-dataset2} dưới đây ghi lại kết quả kiểm tra của các mô hình trên tập dữ liệu Yang liên loài người-virus (2021) khi huấn luyện trên tập dữ liệu Pan người (2010) và tập dữ liệu Sledzieski người (2021). Vì các tập dữ liệu kiểm tra là mất cân bằng nên tôi chỉ báo cáo các độ đo bao gồm độ tụ, độ nhạy, điểm F1.
\FloatBarrier
\begin{table}[htp]
	\centering
	% tip
	% select text
	% then press "Ctrl + B" to wrap the text with \textbf{}
	%     DENV
	% HIV
	% Hepatitis
	% Herpes
	% Influenza
	% Papilloma
	% SARS2
	% ZIKV
	\begin{tabular}{lllll}
		\specialrule{1.5pt}{1pt}{1pt}
		\textbf{Loài}                     & \textbf{Mô hình} & \textbf{Pre}            & \textbf{Rec}   & \textbf{F1}    \\
		\specialrule{1pt}{1pt}{1pt}
		\multirow{4}{*}{Virus Dengue}     & PIPR             & 9.01                    & 96.12          & 16.47          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 8.80                    & 92.66          & 16.08          \\
		                                  & MCAPSL           & \textbf{9.22}           & \textbf{98.17} & \textbf{16.86} \\
		\hline
		\multirow{4}{*}{Virus HIV}        & PIPR             & 8.70                    & 88.45          & 15.84          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 8.75                    & 89.82          & 15.94          \\
		                                  & MCAPSL           & \textbf{9.19}           & \textbf{97.35} & \textbf{16.80} \\
		\hline
		\multirow{4}{*}{Virus Hepatitis}  & PIPR             & 9.21                    & 97.23          & 16.82          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 9.15                    & 97.15          & 16.72          \\
		                                  & MCAPSL           & \textbf{9.22}           & \textbf{99.85} & \textbf{16.88} \\
		\hline
		\multirow{4}{*}{Virus Herpes}     & PIPR             & 9.05                    & 94.80          & 16.52          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 9.09                    & 96.30          & 16.61          \\
		                                  & MCAPSL           & \textbf{9.17}           & \textbf{96.71} & \textbf{16.76} \\
		\hline
		\multirow{4}{*}{Virus Influenza}  & PIPR             & 8.60                    & 87.84          & 15.66          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & \textbf{8.77}           & 88.24          & \textbf{15.95} \\
		                                  & MCAPSL           & 8.71                    & \textbf{92.18} & 15.91          \\
		\hline
		\multirow{3}{*}{Virus Papilloma}  & PIPR             & \textbf{9.38}           & 96.49          & \textbf{17.11} \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 9.10                    & 96.78          & 16.63          \\
		                                  & MCAPSL           & 9.14                    & \textbf{98.18} & 16.73          \\
		\hline
		\multirow{3}{*}{Virus SARS-CoV-2} & PIPR             & 8.88                    & 94.72          & 16.23          \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 9.09                    & \textbf{97.54} & 16.63          \\
		                                  & MCAPSL           & \textbf{9.24}           & 97.36          & \textbf{16.89} \\
		\hline
		\multirow{3}{*}{Virus Zika}       & PIPR             & \textbf{9.26}           & \textbf{99.15} & \textbf{16.94} \\
		                                  & D-SCRIPT         & \multicolumn{3}{c}{N/A}                                   \\
		                                  & FSNN-LGBM        & 9.00                    & 88.29          & 16.34          \\
		                                  & MCAPSL           & 8.49                    & 84.34          & 15.43          \\
		\specialrule{1.5pt}{1pt}{1pt}
	\end{tabular}
	\caption{\textbf{Kết quả kiểm tra trên tập dữ liệu liên loài Yang (2021) khi huấn luyện trên tập dữ liệu Pan người (2010).}}
	\label{table:yang-dataset1}
\end{table}
\FloatBarrier

\FloatBarrier
\begin{table}[htp]
	\centering
	% tip
	% select text
	% then press "Ctrl + B" to wrap the text with \textbf{}
	%     DENV
	% HIV
	% Hepatitis
	% Herpes
	% Influenza
	% Papilloma
	% SARS2
	% ZIKV
	\begin{tabular}{lllll}
		\specialrule{1.5pt}{1pt}{1pt}
		\textbf{Loài}                     & \textbf{Mô hình} & \textbf{Pre}   & \textbf{Rec}   & \textbf{F1}    \\
		\specialrule{1pt}{1pt}{1pt}
		\multirow{4}{*}{Virus Dengue}     & PIPR             & \textbf{30.46} & 12.19          & 17.41          \\
		                                  & D-SCRIPT         & 17.95          & 1.51           & 2.79           \\
		                                  & FSNN-LGBM        & 16.04          & 27.83          & 20.36          \\
		                                  & MCAPSL           & 21.36          & \textbf{33.66} & \textbf{26.13} \\
		\hline
		\multirow{4}{*}{Virus HIV}        & PIPR             & \textbf{22.82} & 7.03           & 10.75          \\
		                                  & D-SCRIPT         & 15.97          & 3.97           & 6.36           \\
		                                  & FSNN-LGBM        & 14.97          & 20.72          & 17.38          \\
		                                  & MCAPSL           & 19.91          & \textbf{28.61} & \textbf{23.48} \\
		\hline
		\multirow{4}{*}{Virus Hepatitis}  & PIPR             & \textbf{29.64} & 5.77           & 9.66           \\
		                                  & D-SCRIPT         & 20.00          & 0.55           & 1.08           \\
		                                  & FSNN-LGBM        & 11.02          & 11.92          & 11.46          \\
		                                  & MCAPSL           & 16.16          & \textbf{18.54} & \textbf{17.27} \\
		\hline
		\multirow{4}{*}{Virus Herpes}     & PIPR             & 22.44          & 5.21           & 8.46           \\
		                                  & D-SCRIPT         & \textbf{25.00} & 0.92           & 1.77           \\
		                                  & FSNN-LGBM        & 15.58          & 18.89          & 17.07          \\
		                                  & MCAPSL           & 17.26          & \textbf{23.40} & \textbf{19.86} \\
		\hline
		\multirow{4}{*}{Virus Influenza}  & PIPR             & \textbf{20.02} & 5.81           & 9.01           \\
		                                  & D-SCRIPT         & 10.53          & 0.77           & 1.43           \\
		                                  & FSNN-LGBM        & 18.60          & \textbf{30.85} & 23.21          \\
		                                  & MCAPSL           & 19.48          & 30.06          & \textbf{23.64} \\
		\hline
		\multirow{4}{*}{Virus Papilloma}  & PIPR             & 18.58          & 2.86           & 4.96           \\
		                                  & D-SCRIPT         & \textbf{40.00} & 1.10           & 2.14           \\
		                                  & FSNN-LGBM        & 14.10          & 16.83          & 15.34          \\
		                                  & MCAPSL           & 17.76          & \textbf{24.12} & \textbf{20.46} \\
		\hline
		\multirow{4}{*}{Virus SARS-CoV-2} & PIPR             & 13.91          & 2.82           & 4.69           \\
		                                  & D-SCRIPT         & \textbf{21.88} & 1.23           & 2.33           \\
		                                  & FSNN-LGBM        & 14.25          & 17.96          & 15.89          \\
		                                  & MCAPSL           & 16.19          & \textbf{22,89} & \textbf{18.96} \\
		\hline
		\multirow{4}{*}{Virus Zika}       & PIPR             & 11.76          & 1.97           & 3.38           \\
		                                  & D-SCRIPT         & \textbf{42.42} & 7.90           & 13.32          \\
		                                  & FSNN-LGBM        & 13.76          & 20.17          & 16.36          \\
		                                  & MCAPSL           & 16.59          & \textbf{25.39} & \textbf{20.07} \\
		\specialrule{1.5pt}{1pt}{1pt}
	\end{tabular}
	\caption{\textbf{Kết quả kiểm tra trên tập dữ liệu liên loài Yang (2021) khi huấn luyện trên tập dữ liệu Sledzieski người (2021)}}
	\label{table:yang-dataset2}
\end{table}
\FloatBarrier

\par Ở bảng \ref{table:yang-dataset1}, ta thấy MCAPSL thường vượt trội hơn các mô hình khác trên các tập dữ liệu về cả ba độ đo. Về xếp hạng, MCAPSL đứng \textbf{nhất 5/8 lần ở độ tụ}, MCAPSL đứng \textbf{nhất 6/8 lần về độ nhạy}, MCAPSL đứng \textbf{nhất 5/8 lần về điểm F1}. Về độ tụ, mặc dù hay đứng nhất nhưng MCAPSL có độ tụ khá thấp, trong khoảng từ 8.77-9.38\%, thường chỉ hơn vị trí số hai không đáng kể từ 0.06-0.44\%. Về độ nhạy, MCAPSL thường dẫn đầu với kết quả từ 92.18-99.85\%, hơn mô hình tốt nhì đáng kể từ 2-10\%. Về điểm F1, MCAPSL thường dẫn đầu về độ đo này với giá trị trong khoảng từ 16.76-16.89\%, hơn không đáng kể mô hình xếp thứ từ 0.2-0.4\%. 

\par Ở bảng \ref{table:yang-dataset2}, ta thấy MCAPSL thường chỉ vượt trội hơn về độ nhạy và điểm F1. Về xếp hạng, MCAPSL đứng \textbf{nhất 7/8 lần ở độ nhạy}, MCAPSL đứng \textbf{nhất 8/8 lần ở điểm F1}. Độ tụ không phải thế mạnh trong trường hợp này của MCAPSL, thường PIPR hoặc D-SCRIPT đứng đầu với kết quả từ 22.92-42.42\%, hơn vị trí thứ nhì thường của MCAPSL hoặc PIPR ít nhất một khoảng đáng kể ít nhất 3\%, có thể lên đến 25.83\% ở tập virus Zika, 21.42\% ở tập Papilloma. Về độ nhạy, MCAPSL thường dẫn đầu với kết quả từ 22.89-33.66\%, hơn vị trí thứ nhì thường hơn ít nhất 5\%. Và ở điểm F1, MCAPSL toàn thắng với kết quả từ 17.27-26.13\%, hơn vị trí số hai từ 3-6\%.

\par So sánh kết quả hai bảng \ref{table:yang-dataset1}, \ref{table:yang-dataset2}, ta thấy độ tụ tốt nhất huấn luyện ở tập cân bằng (8.77-9.38\%) thấp hơn nhiều so với tập mất cân bằng (22.92-42.42\%), độ nhạy tốt nhất huấn luyện ở tập cân bằng (92.18-99.85\%) cao hơn đáng kể so với trên tập mất cân bằng (22.89-33.66\%), điểm F1 tốt nhất huấn luyện ở tập cân bằng (16.76-16.89\%) thấp hơn một chút so với trên tập mất cân bằng (17.27-26.13\%). 

\par Như đã đề cập ở phần trước, độ nhạy có lẽ là độ đo quan trọng nhất đối với phát hiện tương tác mới. MCAPSL tiếp tục là mô hình vượt trội hơn hẳn về độ nhạy giống với tác vụ đánh giá trước. Ở tác vụ suy diễn tương tác liên loài, việc học trên tập cân bằng sẽ cho kết quả suy diễn về độ nhạy cao nhất trên 90\% nhưng độ tụ thì lại rất thấp dưới 10\%, và việc học trên tập mất cân bằng sẽ cho độ tụ và độ nhạy ở mức trung bình trong khoảng 20-40\%. Khả năng mở rộng dự đoán các loài sinh vật khác của D-SCRIPT trong trường hợp dự đoán tương tác liên loài không thực sự tốt như dự đoán tương tác chéo loài.




\pagebreak

\section*{KẾT LUẬN VÀ KIẾN NGHỊ}\addcontentsline{toc}{section}{KẾT LUẬN VÀ KIẾN NGHỊ}

\subsection*{Kết luận}
\begin{enumerate}
    \item Xây dựng thành công quy trình đánh giá chất lượng học và dự đoán PPI của các mô hình.
    \item Chuẩn bị các tập dữ liệu PPI tiêu chuẩn bao gồm các tập dữ liệu học nội tại để đánh giá chất lượng học và các tập dữ liệu kiểm tra để đánh giá chất lượng mở rộng của các mô hình. Cài đặt thành công ba mô hình tốt nhất hiện nay là PIPR, D-SCRIPT và FSNN-LGBM.
    \item Phát triển và cài đặt thành công mô hình MCAPSL với hai điểm mới trong kiến trúc so với các mô hình dự đoán PPI trước đó là cơ chế tích lũy gộp theo độ sâu và sử dụng hai dạng mã hóa thông tin đầu vào dưới dạng vector và ma trận, hài hòa tổng thể với kiến trúc mạng đôi tích chập sâu sử dụng nhiều bộ lọc kích thước khác nhau.
    \item Khi đánh giá về chất lượng học nội tại, MCAPSL vượt trội hơn so với các mô hình khác về 8 độ đo trên ba tập dữ liệu tiêu chuẩn. Còn khi đánh giá về chất lượng dự đoán mở rộng trên 3 tác vụ, MCAPSL phần lớn vượt trội hơn các mô hình khác về độ nhạy, độ tụ và điểm F1 trên 17 tập dữ liệu. 
\end{enumerate}

\subsection*{Kiến nghị}
\begin{enumerate}
    \item Cần đánh giá chất lượng dự đoán mô hình trên các tập dữ liệu có ràng buộc chặt chẽ hơn sự tương đồng trình tự hay không có trình tự nào đó xuất hiện quá nhiều trong các mẫu dữ liệu, như vậy sẽ khiến quá trình đánh giá thiên vị
    \item Cần tích hợp cơ chế đa nhánh vào mô hình MCAPSL để có thể làm tốt hơn việc duy trì tính toàn vẹn luồng thông tin
    \item Tối ưu dạng mã hóa đầu vào cho mô hình, có thể là tìm các biểu diễn nhúng theo ngữ cảnh từ các mô hình ngôn ngữ protein dẫn xuất từ mô hình BERT
\end{enumerate}

\pagebreak

% \begin{thebibliography}{100}
% \addcontentsline{toc}{section}{TÀI LIỆU THAM KHẢO}
% \newcommand{\enquote}[1]{``#1''}

% \bibitem{uniprot2017uniprot}
%  (2017), \enquote{Uniprot: the universal protein knowledgebase}, \emph{Nucleic
%   acids research}, 45(D1), pp. D158--D169.

% \bibitem{wwpdb2019protein}
%  (2019), \enquote{Protein data bank: the single global archive for 3d
%   macromolecular structure data}, \emph{Nucleic acids research}, 47(D1), pp.
%   D520--D528.

% \bibitem{uniprot2021uniprot}
%  (2021), \enquote{Uniprot: the universal protein knowledgebase in 2021},
%   \emph{Nucleic acids research}, 49(D1), pp. D480--D489.

% \bibitem{ammari2016hpidb}
% M.~G. Ammari, C.~R. Gresham, F.~M. McCarthy and B.~Nanduri (2016),
%   \enquote{Hpidb 2.0: a curated database for host--pathogen interactions},
%   \emph{Database}, 2016.

% \bibitem{andreeva2004scop}
% A.~Andreeva, D.~Howorth, S.~E. Brenner, T.~J. Hubbard, C.~Chothia and A.~G.
%   Murzin (2004), \enquote{Scop database in 2004: refinements integrate
%   structure and sequence family data}, \emph{Nucleic acids research},
%   32(suppl\_1), pp. D226--D229.

% \bibitem{anfinsen1973principles}
% C.~B. Anfinsen (1973), \enquote{Principles that govern the folding of protein
%   chains}, \emph{Science}, 181(4096), pp. 223--230.

% \bibitem{aronheim1997isolation}
% A.~Aronheim, E.~Zandi, H.~Hennemann, S.~J. Elledge and M.~Karin (1997),
%   \enquote{Isolation of an ap-1 repressor by a novel method for detecting
%   protein-protein interactions}, \emph{Molecular and cellular biology}, 17(6),
%   pp. 3094--3102.

% \bibitem{bandyopadhyay2016new}
% S.~Bandyopadhyay and K.~Mallick (2016), \enquote{A new feature vector based on
%   gene ontology terms for protein-protein interaction prediction},
%   \emph{IEEE/ACM transactions on computational biology and bioinformatics},
%   14(4), pp. 762--770.

% \bibitem{barker1999pir}
% W.~C. Barker, J.~S. Garavelli, P.~B. McGarvey, C.~R. Marzec, B.~C. Orcutt,
%   G.~Y. Srinivasarao, L.-S.~L. Yeh, R.~S. Ledley, H.-W. Mewes, F.~Pfeiffer
%   \emph{et~al.} (1999), \enquote{The pir-international protein sequence
%   database}, \emph{Nucleic Acids Research}, 27(1), pp. 39--43.

% \bibitem{bartel1996protein}
% P.~L. Bartel, J.~A. Roecklein, D.~SenGupta and S.~Fields (1996), \enquote{A
%   protein linkage map of escherichia coli bacteriophage t7}, \emph{Nature
%   genetics}, 12(1), pp. 72--77.

% \bibitem{ben2006choosing}
% A.~Ben-Hur and W.~S. Noble (2006), \enquote{Choosing negative examples for the
%   prediction of protein-protein interactions}, \enquote{BMC bioinformatics},
%   Springer, volume~7, pp. 1--6.

% \bibitem{bengio1994learning}
% Y.~Bengio, P.~Simard and P.~Frasconi (1994), \enquote{Learning long-term
%   dependencies with gradient descent is difficult}, \emph{IEEE transactions on
%   neural networks}, 5(2), pp. 157--166.

% \bibitem{bepler2019learning}
% T.~Bepler and B.~Berger (2019), \enquote{Learning protein sequence embeddings
%   using information from structure}, \emph{arXiv preprint arXiv:1902.08661}.

% \bibitem{binns2009quickgo}
% D.~Binns, E.~Dimmer, R.~Huntley, D.~Barrell, C.~O'donovan and R.~Apweiler
%   (2009), \enquote{Quickgo: a web-based tool for gene ontology searching},
%   \emph{Bioinformatics}, 25(22), pp. 3045--3046.

% \bibitem{bock2001predicting}
% J.~R. Bock and D.~A. Gough (2001), \enquote{Predicting protein--protein
%   interactions from primary structure}, \emph{Bioinformatics}, 17(5), pp.
%   455--460.

% \bibitem{bogan1998anatomy}
% A.~A. Bogan and K.~S. Thorn (1998), \enquote{Anatomy of hot spots in protein
%   interfaces}, \emph{Journal of molecular biology}, 280(1), pp. 1--9.

% \bibitem{boisvert19962}
% D.~C. Boisvert, J.~Wang, Z.~Otwinowski, A.~L. Norwich and P.~B. Sigler (1996),
%   \enquote{The 2.4 {\si{\angstrom}} crystal structure of the bacterial
%   chaperonin groel complexed with atp$\gamma$s}, \emph{Nature structural
%   biology}, 3(2), pp. 170--177.

% \bibitem{brown2020language}
% T.~Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~D. Kaplan, P.~Dhariwal,
%   A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell \emph{et~al.} (2020),
%   \enquote{Language models are few-shot learners}, \emph{Advances in neural
%   information processing systems}, 33, pp. 1877--1901.

% \bibitem{browne2007supervised}
% F.~Browne, H.~Wang, H.~Zheng and F.~Azuaje (2007), \enquote{Supervised
%   statistical and machine learning approaches to inferring pairwise and
%   module-based protein interaction networks}, \enquote{2007 IEEE 7th
%   International Symposium on BioInformatics and BioEngineering}, IEEE, pp.
%   1365--1369.

% \bibitem{brunger1998crystallography}
% A.~T. Br{\"u}nger, P.~D. Adams, G.~M. Clore, W.~L. DeLano, P.~Gros, R.~W.
%   Grosse-Kunstleve, J.-S. Jiang, J.~Kuszewski, M.~Nilges, N.~S. Pannu
%   \emph{et~al.} (1998), \enquote{Crystallography \& nmr system: A new software
%   suite for macromolecular structure determination}, \emph{Acta
%   Crystallographica Section D: Biological Crystallography}, 54(5), pp.
%   905--921.

% \bibitem{calderone2015virusmentha}
% A.~Calderone, L.~Licata and G.~Cesareni (2015), \enquote{Virusmentha: a new
%   resource for virus-host protein interactions}, \emph{Nucleic acids research},
%   43(D1), pp. D588--D592.

% \bibitem{chatr2017biogrid}
% A.~Chatr-Aryamontri, R.~Oughtred, L.~Boucher, J.~Rust, C.~Chang, N.~K. Kolas,
%   L.~O'Donnell, S.~Oster, C.~Theesfeld, A.~Sellam \emph{et~al.} (2017),
%   \enquote{The biogrid interaction database: 2017 update}, \emph{Nucleic acids
%   research}, 45(D1), pp. D369--D379.

% \bibitem{chaurasia2007unihi}
% G.~Chaurasia, Y.~Iqbal, C.~H{\"a}nig, H.~Herzel, E.~E. Wanker and M.~E.
%   Futschik (2007), \enquote{Unihi: an entry gate to the human protein
%   interactome}, \emph{Nucleic acids research}, 35(suppl\_1), pp. D590--D594.

% \bibitem{chen2019lightgbm}
% C.~Chen, Q.~Zhang, Q.~Ma and B.~Yu (2019), \enquote{Lightgbm-ppi: Predicting
%   protein-protein interactions through lightgbm with multi-information fusion},
%   \emph{Chemometrics and Intelligent Laboratory Systems}, 191, pp. 54--64.

% \bibitem{chen2005discovering}
% J.~Chen, W.~Hsu, M.~L. Lee and S.-K. Ng (2005), \enquote{Discovering reliable
%   protein interactions from high-throughput experimental data using network
%   topology}, \emph{Artificial Intelligence in medicine}, 35(1-2), pp. 37--47.

% \bibitem{chen2019multifaceted}
% M.~Chen, C.~J.-T. Ju, G.~Zhou, X.~Chen, T.~Zhang, K.-W. Chang, C.~Zaniolo and
%   W.~Wang (2019), \enquote{Multifaceted protein--protein interaction prediction
%   based on siamese residual rcnn}, \emph{Bioinformatics}, 35(14), pp.
%   i305--i314.

% \bibitem{chou2001prediction}
% K.-C. Chou (2001), \enquote{Prediction of protein cellular attributes using
%   pseudo-amino acid composition}, \emph{Proteins: Structure, Function, and
%   Bioinformatics}, 43(3), pp. 246--255.

% \bibitem{chung2014empirical}
% J.~Chung, C.~Gulcehre, K.~Cho and Y.~Bengio (2014), \enquote{Empirical
%   evaluation of gated recurrent neural networks on sequence modeling},
%   \emph{arXiv preprint arXiv:1412.3555}.

% \bibitem{gene2017expansion}
% G.~O. Consortium (2017), \enquote{Expansion of the gene ontology knowledgebase
%   and resources}, \emph{Nucleic acids research}, 45(D1), pp. D331--D338.

% \bibitem{conte1999atomic}
% L.~L. Conte, C.~Chothia and J.~Janin (1999), \enquote{The atomic structure of
%   protein--protein recognition sites}, \emph{Journal of molecular biology},
%   285(5), pp. 2177--2198.

% \bibitem{coward1999shufflet}
% E.~Coward (1999), \enquote{Shufflet: shuffling sequences while conserving the
%   k-let counts}, \emph{Bioinformatics}, 15(12), pp. 1058--1059.

% \bibitem{czibula2021autoppi}
% G.~Czibula, A.-I. Albu, M.~I. Bocicor and C.~Chira (2021), \enquote{Autoppi: An
%   ensemble of deep autoencoders for protein--protein interaction prediction},
%   \emph{Entropy}, 23(6), p. 643.

% \bibitem{dandekar1998conservation}
% T.~Dandekar, B.~Snel, M.~Huynen and P.~Bork (1998), \enquote{Conservation of
%   gene order: a fingerprint of proteins that physically interact}, \emph{Trends
%   in biochemical sciences}, 23(9), pp. 324--328.

% \bibitem{davis2006relationship}
% J.~Davis and M.~Goadrich (2006), \enquote{The relationship between
%   precision-recall and roc curves}, \enquote{Proceedings of the 23rd
%   international conference on Machine learning}, pp. 233--240.

% \bibitem{deane2002protein}
% C.~M. Deane, {\L}.~Salwinski, I.~Xenarios and D.~Eisenberg (2002),
%   \enquote{Protein interactions: two methods for assessment of the reliability
%   of high throughput observations}, \emph{Molecular \& Cellular Proteomics},
%   1(5), pp. 349--356.

% \bibitem{devan2020efficient}
% P.~Devan and N.~Khare (2020), \enquote{An efficient xgboost--dnn-based
%   classification model for network intrusion detection system}, \emph{Neural
%   Computing and Applications}, 32(16), pp. 12499--12514.

% \bibitem{devlin2018bert}
% J.~Devlin, M.-W. Chang, K.~Lee and K.~Toutanova (2018), \enquote{Bert:
%   Pre-training of deep bidirectional transformers for language understanding},
%   \emph{arXiv preprint arXiv:1810.04805}.

% \bibitem{dohkan2006improving}
% S.~Dohkan, A.~Koike and T.~Takagi (2006), \enquote{Improving the performance of
%   an svm-based method for predicting protein-protein interactions}, \emph{In
%   silico biology}, 6(6), pp. 515--529.

% \bibitem{dong2021survey}
% S.~Dong, P.~Wang and K.~Abbas (2021), \enquote{A survey on deep learning and
%   its applications}, \emph{Computer Science Review}, 40, p. 100379.

% \bibitem{du2017deepppi}
% X.~Du, S.~Sun, C.~Hu, Y.~Yao, Y.~Yan and Y.~Zhang (2017), \enquote{Deepppi:
%   boosting prediction of protein--protein interactions with deep neural
%   networks}, \emph{Journal of chemical information and modeling}, 57(6), pp.
%   1499--1510.

% \bibitem{duchi2011adaptive}
% J.~Duchi, E.~Hazan and Y.~Singer (2011), \enquote{Adaptive subgradient methods
%   for online learning and stochastic optimization.}, \emph{Journal of machine
%   learning research}, 12(7).

% \bibitem{durmucs2013phisto}
% S.~Durmu{\c{s}}~Tekir, T.~{\c{C}}ak{\i}r, E.~Ard{\i}{ \c{c}}, A.~S.
%   Say{\i}l{\i}rba{\c{s}}, G.~k. Konuk, M.~Konuk, H.~Sar{\i}yer,
%   A.~U{\u{g}}urlu, {\.I}.~Karadeniz, A.~{\"O}zg{\"u}r \emph{et~al.} (2013),
%   \enquote{Phisto: pathogen--host interaction search tool},
%   \emph{Bioinformatics}, 29(10), pp. 1357--1358.

% \bibitem{eid2016denovo}
% F.-E. Eid, M.~ElHefnawi and L.~S. Heath (2016), \enquote{Denovo: virus-host
%   sequence-based protein--protein interaction prediction},
%   \emph{Bioinformatics}, 32(8), pp. 1144--1150.

% \bibitem{enright1999protein}
% A.~J. Enright, I.~Iliopoulos, N.~C. Kyrpides and C.~A. Ouzounis (1999),
%   \enquote{Protein interaction maps for complete genomes based on gene fusion
%   events}, \emph{Nature}, 402(6757), pp. 86--90.

% \bibitem{fashena2000continued}
% S.~J. Fashena, I.~Serebriiskii and E.~A. Golemis (2000), \enquote{The continued
%   evolution of two-hybrid screening approaches in yeast: how to outwit
%   different preys with different baits}, \emph{Gene}, 250(1-2), pp. 1--14.

% \bibitem{fawcett2006introduction}
% T.~Fawcett (2006), \enquote{An introduction to roc analysis}, \emph{Pattern
%   recognition letters}, 27(8), pp. 861--874.

% \bibitem{fields1989novel}
% S.~Fields and O.-k. Song (1989), \enquote{A novel genetic system to detect
%   protein--protein interactions}, \emph{Nature}, 340(6230), pp. 245--246.

% \bibitem{finzel1985structure}
% B.~Finzel, P.~Weber, K.~Hardman and F.~Salemme (1985), \enquote{Structure of
%   ferricytochrome c from rhodospirillum molischianum at 1.67 {\si{\angstrom}}
%   resolution}, \emph{Journal of molecular biology}, 186(3), pp. 627--643.

% \bibitem{fukushima1975cognitron}
% K.~Fukushima (1975), \enquote{Cognitron: A self-organizing multilayered neural
%   network}, \emph{Biological cybernetics}, 20(3), pp. 121--136.

% \bibitem{giot2003protein}
% L.~Giot, J.~S. Bader, C.~Brouwer, A.~Chaudhuri, B.~Kuang, Y.~Li, Y.~Hao,
%   C.~Ooi, B.~Godwin, E.~Vitols \emph{et~al.} (2003), \enquote{A protein
%   interaction map of drosophila melanogaster}, \emph{science}, 302(5651), pp.
%   1727--1736.

% \bibitem{goodfellow2016deep}
% I.~Goodfellow, Y.~Bengio and A.~Courville (2016), Deep learning, MIT press.

% \bibitem{gordon2020sars}
% D.~E. Gordon, G.~M. Jang, M.~Bouhaddou, J.~Xu, K.~Obernier, K.~M. White, M.~J.
%   O’Meara, V.~V. Rezelj, J.~Z. Guo, D.~L. Swaney \emph{et~al.} (2020),
%   \enquote{A sars-cov-2 protein interaction map reveals targets for drug
%   repurposing}, \emph{Nature}, 583(7816), pp. 459--468.

% \bibitem{graves2008offline}
% A.~Graves and J.~Schmidhuber (2008), \enquote{Offline handwriting recognition
%   with multidimensional recurrent neural networks}, \emph{Advances in neural
%   information processing systems}, 21.

% \bibitem{guirimand2015virhostnet}
% T.~Guirimand, S.~Delmotte and V.~Navratil (2015), \enquote{Virhostnet 2.0:
%   surfing on the web of virus/host molecular interactions data}, \emph{Nucleic
%   acids research}, 43(D1), pp. D583--D587.

% \bibitem{guo2010pred_ppi}
% Y.~Guo, M.~Li, X.~Pu, G.~Li, X.~Guang, W.~Xiong and J.~Li (2010),
%   \enquote{Pred\_ppi: a server for predicting protein-protein interactions
%   based on sequence data with probability assignment}, \emph{BMC research
%   notes}, 3(1), pp. 1--7.

% \bibitem{guo2008using}
% Y.~Guo, L.~Yu, Z.~Wen and M.~Li (2008), \enquote{Using support vector machine
%   combined with auto covariance to predict protein--protein interactions from
%   protein sequences}, \emph{Nucleic acids research}, 36(9), pp. 3025--3030.

% \bibitem{hadsell2009learning}
% R.~Hadsell, P.~Sermanet, J.~Ben, A.~Erkan, M.~Scoffier, K.~Kavukcuoglu,
%   U.~Muller and Y.~LeCun (2009), \enquote{Learning long-range vision for
%   autonomous off-road driving}, \emph{Journal of Field Robotics}, 26(2), pp.
%   120--144.

% \bibitem{hall2007protein}
% D.~A. Hall, J.~Ptacek and M.~Snyder (2007), \enquote{Protein microarray
%   technology}, \emph{Mechanisms of ageing and development}, 128(1), pp.
%   161--167.

% \bibitem{hashemifar2018predicting}
% S.~Hashemifar, B.~Neyshabur, A.~A. Khan and J.~Xu (2018), \enquote{Predicting
%   protein--protein interactions through sequence-based deep learning},
%   \emph{Bioinformatics}, 34(17), pp. i802--i810.

% \bibitem{hinton2006fast}
% G.~E. Hinton, S.~Osindero and Y.-W. Teh (2006), \enquote{A fast learning
%   algorithm for deep belief nets}, \emph{Neural computation}, 18(7), pp.
%   1527--1554.

% \bibitem{hinton2006reducing}
% G.~E. Hinton and R.~R. Salakhutdinov (2006), \enquote{Reducing the
%   dimensionality of data with neural networks}, \emph{science}, 313(5786), pp.
%   504--507.

% \bibitem{hinton1986parallel}
% G.~E. Hinton and T.~J. Sejnowski (1986), \enquote{Parallel distributed
%   processing: Explorations in the microstructure of cognition}, .

% \bibitem{hochreiter1997long}
% S.~Hochreiter and J.~Schmidhuber (1997), \enquote{Long short-term memory},
%   \emph{Neural computation}, 9(8), pp. 1735--1780.

% \bibitem{hu2015discovering}
% L.~Hu and K.~C. Chan (2015), \enquote{Discovering variable-length patterns in
%   protein sequences for protein-protein interaction prediction}, \emph{IEEE
%   transactions on nanobioscience}, 14(4), pp. 409--416.

% \bibitem{hu2016extracting}
% L.~Hu and K.~C. Chan (2016), \enquote{Extracting coevolutionary features from
%   protein sequences for predicting protein-protein interactions},
%   \emph{IEEE/ACM transactions on computational biology and bioinformatics},
%   14(1), pp. 155--166.

% \bibitem{hu2021survey}
% L.~Hu, X.~Wang, Y.-A. Huang, P.~Hu and Z.-H. You (2021), \enquote{A survey on
%   computational models for predicting protein--protein interactions},
%   \emph{Briefings in Bioinformatics}, 22(5), p. bbab036.

% \bibitem{huang2007have}
% H.~Huang, B.~M. Jedynak and J.~S. Bader (2007), \enquote{Where have all the
%   interactions gone? estimating the coverage of two-hybrid protein interaction
%   maps}, \emph{PLoS computational biology}, 3(11), p. e214.

% \bibitem{hubel1968receptive}
% D.~H. Hubel and T.~N. Wiesel (1968), \enquote{Receptive fields and functional
%   architecture of monkey striate cortex}, \emph{The Journal of physiology},
%   195(1), pp. 215--243.

% \bibitem{ioffe2015batch}
% S.~Ioffe and C.~Szegedy (2015), \enquote{Batch normalization: Accelerating deep
%   network training by reducing internal covariate shift},
%   \enquote{International conference on machine learning}, PMLR, pp. 448--456.

% \bibitem{ito2001comprehensive}
% T.~Ito, T.~Chiba, R.~Ozawa, M.~Yoshida, M.~Hattori and Y.~Sakaki (2001),
%   \enquote{A comprehensive two-hybrid analysis to explore the yeast protein
%   interactome}, \emph{Proceedings of the National Academy of Sciences}, 98(8),
%   pp. 4569--4574.

% \bibitem{jain2010improved}
% S.~Jain and G.~D. Bader (2010), \enquote{An improved method for scoring
%   protein-protein interactions using semantic similarity within the gene
%   ontology}, \emph{BMC bioinformatics}, 11(1), pp. 1--14.

% \bibitem{janin2008protein}
% J.~Janin, R.~P. Bahadur and P.~Chakrabarti (2008), \enquote{Protein--protein
%   interaction and quaternary structure}, \emph{Quarterly reviews of
%   biophysics}, 41(2), pp. 133--180.

% \bibitem{jansen2002relating}
% R.~Jansen, D.~Greenbaum and M.~Gerstein (2002), \enquote{Relating whole-genome
%   expression data with protein-protein interactions}, \emph{Genome research},
%   12(1), pp. 37--46.

% \bibitem{jiang2018multiple}
% J.~Jiang, Y.-C. Hu, C.-J. Liu, D.~Halpenny, M.~D. Hellmann, J.~O. Deasy,
%   G.~Mageras and H.~Veeraraghavan (2018), \enquote{Multiple resolution
%   residually connected feature streams for automatic lung tumor segmentation
%   from ct images}, \emph{IEEE transactions on medical imaging}, 38(1), pp.
%   134--144.

% \bibitem{jones1996principles}
% S.~Jones and J.~M. Thornton (1996), \enquote{Principles of protein--protein
%   interactions}, \emph{Proceedings of the National Academy of Sciences}, 93(1),
%   pp. 13--20.

% \bibitem{kaelin2005concept}
% W.~G. Kaelin (2005), \enquote{The concept of synthetic lethality in the context
%   of anticancer therapy}, \emph{Nature reviews cancer}, 5(9), pp. 689--698.

% \bibitem{ke2017lightgbm}
% G.~Ke, Q.~Meng, T.~Finley, T.~Wang, W.~Chen, W.~Ma, Q.~Ye and T.-Y. Liu (2017),
%   \enquote{Lightgbm: A highly efficient gradient boosting decision tree},
%   \emph{Advances in neural information processing systems}, 30.

% \bibitem{kerrien2012intact}
% S.~Kerrien, B.~Aranda, L.~Breuza, A.~Bridge, F.~Broackes-Carter, C.~Chen,
%   M.~Duesbury, M.~Dumousseau, M.~Feuermann, U.~Hinz \emph{et~al.} (2012),
%   \enquote{The intact molecular interaction database in 2012}, \emph{Nucleic
%   acids research}, 40(D1), pp. D841--D846.

% \bibitem{keshava2009human}
% T.~Keshava~Prasad, R.~Goel, K.~Kandasamy, S.~Keerthikumar, S.~Kumar,
%   S.~Mathivanan, D.~Telikicherla, R.~Raju, B.~Shafreen, A.~Venugopal
%   \emph{et~al.} (2009), \enquote{Human protein reference database - 2009
%   update}, \emph{Nucleic acids research}, 37(suppl\_1), pp. D767--D772.

% \bibitem{keskin2016predicting}
% O.~Keskin, N.~Tuncbag and A.~Gursoy (2016), \enquote{Predicting
%   protein--protein interactions from the molecular to the proteome level},
%   \emph{Chemical reviews}, 116(8), pp. 4884--4909.

% \bibitem{kim2014convolutional}
% Y.~Kim (2014), \enquote{Convolutional neural networks for sentence
%   classification proceedings of the 2014 conference on empirical methods in
%   natural language processing, emnlp 2014, october 25-29, 2014, doha, qatar, a
%   meeting of sigdat, a special interest group of the acl}, \emph{Association
%   for Computational Linguistics, Doha, Qatar}.

% \bibitem{kingma2014adam}
% D.~P. Kingma and J.~Ba (2014), \enquote{Adam: A method for stochastic
%   optimization}, \emph{arXiv preprint arXiv:1412.6980}.

% \bibitem{kovacs2019network}
% I.~A. Kov{\'a}cs, K.~Luck, K.~Spirohn, Y.~Wang, C.~Pollis, S.~Schlabach,
%   W.~Bian, D.-K. Kim, N.~Kishore, T.~Hao \emph{et~al.} (2019),
%   \enquote{Network-based prediction of protein interactions}, \emph{Nature
%   communications}, 10(1), pp. 1--8.

% \bibitem{krizhevsky2012imagenet}
% A.~Krizhevsky, I.~Sutskever and G.~E. Hinton (2012), \enquote{Imagenet
%   classification with deep convolutional neural networks}, \emph{Advances in
%   neural information processing systems}, 25.

% \bibitem{krogan2006global}
% N.~J. Krogan, G.~Cagney, H.~Yu, G.~Zhong, X.~Guo, A.~Ignatchenko, J.~Li, S.~Pu,
%   N.~Datta, A.~P. Tikuisis \emph{et~al.} (2006), \enquote{Global landscape of
%   protein complexes in the yeast saccharomyces cerevisiae}, \emph{Nature},
%   440(7084), pp. 637--643.

% \bibitem{larranaga2006machine}
% P.~Larranaga, B.~Calvo, R.~Santana, C.~Bielza, J.~Galdiano, I.~Inza, J.~A.
%   Lozano, R.~Armananzas, G.~Santaf{\'e}, A.~P{\'e}rez \emph{et~al.} (2006),
%   \enquote{Machine learning in bioinformatics}, \emph{Briefings in
%   bioinformatics}, 7(1), pp. 86--112.

% \bibitem{lawrence1997face}
% S.~Lawrence, C.~L. Giles, A.~C. Tsoi and A.~D. Back (1997), \enquote{Face
%   recognition: A convolutional neural-network approach}, \emph{IEEE
%   transactions on neural networks}, 8(1), pp. 98--113.

% \bibitem{lecun2015deep}
% Y.~LeCun, Y.~Bengio and G.~Hinton (2015), \enquote{Deep learning},
%   \emph{nature}, 521(7553), pp. 436--444.

% \bibitem{lecun1989handwritten}
% Y.~LeCun, B.~Boser, J.~Denker, D.~Henderson, R.~Howard, W.~Hubbard and
%   L.~Jackel (1989), \enquote{Handwritten digit recognition with a
%   back-propagation network}, \emph{Advances in neural information processing
%   systems}, 2.

% \bibitem{lee2004mammalian}
% J.~W. Lee and S.-K. Lee (2004), \enquote{Mammalian two-hybrid assay for
%   detecting protein-protein interactions in vivo}, \emph{Protein-protein
%   interactions}, pp. 327--336.

% \bibitem{lei2021deep}
% Y.~Lei, S.~Li, Z.~Liu, F.~Wan, T.~Tian, S.~Li, D.~Zhao and J.~Zeng (2021),
%   \enquote{A deep-learning framework for multi-level peptide--protein
%   interaction prediction}, \emph{Nature communications}, 12(1), pp. 1--10.

% \bibitem{lena2012deep}
% P.~Lena, K.~Nagata and P.~Baldi (2012), \enquote{Deep spatio-temporal
%   architectures and learning for protein structure prediction}, \emph{Advances
%   in neural information processing systems}, 25.

% \bibitem{li2020protein}
% F.~Li, F.~Zhu, X.~Ling and Q.~Liu (2020), \enquote{Protein interaction network
%   reconstruction through ensemble deep learning with attention mechanism},
%   \emph{Frontiers in Bioengineering and Biotechnology}, 8, p. 390.

% \bibitem{li2018deep}
% H.~Li, X.-J. Gong, H.~Yu and C.~Zhou (2018), \enquote{Deep neural network based
%   predictions of protein interactions using primary sequences},
%   \emph{Molecules}, 23(8), p. 1923.

% \bibitem{li2020early}
% Q.~Li, X.~Guan, P.~Wu, X.~Wang, L.~Zhou, Y.~Tong, R.~Ren, K.~S. Leung, E.~H.
%   Lau, J.~Y. Wong \emph{et~al.} (2020), \enquote{Early transmission dynamics in
%   wuhan, china, of novel coronavirus--infected pneumonia}, \emph{New England
%   journal of medicine}.

% \bibitem{li2018similarity}
% S.~Li, J.~Huang, Z.~Zhang, J.~Liu, T.~Huang and H.~Chen (2018),
%   \enquote{Similarity-based future common neighbors model for link prediction
%   in complex networks}, \emph{Scientific reports}, 8(1), pp. 1--11.

% \bibitem{li2006cd}
% W.~Li and A.~Godzik (2006), \enquote{Cd-hit: a fast program for clustering and
%   comparing large sets of protein or nucleotide sequences},
%   \emph{Bioinformatics}, 22(13), pp. 1658--1659.

% \bibitem{licata2012mint}
% L.~Licata, L.~Briganti, D.~Peluso, L.~Perfetto, M.~Iannuccelli, E.~Galeota,
%   F.~Sacco, A.~Palma, A.~P. Nardozza, E.~Santonico \emph{et~al.} (2012),
%   \enquote{Mint, the molecular interaction database: 2012 update},
%   \emph{Nucleic acids research}, 40(D1), pp. D857--D861.

% \bibitem{lin2017protein}
% J.-S. Lin and E.-M. Lai (2017), \enquote{Protein--protein interactions: yeast
%   two-hybrid system}, \enquote{Bacterial Protein Secretion Systems}, Springer,
%   pp. 177--187.

% \bibitem{lin2013heterogeneous}
% X.~Lin and X.-w. Chen (2013), \enquote{Heterogeneous data integration by
%   tree-augmented naive bayes for protein--protein interactions prediction},
%   \emph{Proteomics}, 13(2), pp. 261--268.

% \bibitem{luck2020reference}
% K.~Luck, D.-K. Kim, L.~Lambourne, K.~Spirohn, B.~E. Begg, W.~Bian, R.~Brignall,
%   T.~Cafarelli, F.~J. Campos-Laborie, B.~Charloteaux \emph{et~al.} (2020),
%   \enquote{A reference map of the human binary protein interactome},
%   \emph{Nature}, 580(7803), pp. 402--408.

% \bibitem{mahapatra2021improved}
% S.~Mahapatra and S.~S. Sahu (2021), \enquote{Improved prediction of
%   protein--protein interaction using a hybrid of functional-link siamese neural
%   network and gradient boosting machines}, \emph{Briefings in Bioinformatics},
%   22(6), p. bbab255.

% \bibitem{martin2005predicting}
% S.~Martin, D.~Roe and J.-L. Faulon (2005), \enquote{Predicting protein--protein
%   interactions using signature products}, \emph{Bioinformatics}, 21(2), pp.
%   218--226.

% \bibitem{masters2004co}
% S.~C. Masters (2004), \enquote{Co-immunoprecipitation from transfected cells},
%   \emph{Protein-Protein Interactions}, pp. 337--348.

% \bibitem{matthews1975comparison}
% B.~W. Matthews (1975), \enquote{Comparison of the predicted and observed
%   secondary structure of t4 phage lysozyme}, \emph{Biochimica et Biophysica
%   Acta (BBA)-Protein Structure}, 405(2), pp. 442--451.

% \bibitem{mekruksavanich2022lstm}
% S.~Mekruksavanich, P.~Jantawong and A.~Jitpattanakul (2022), \enquote{Lstm-xgb:
%   A new deep learning model for human activity recognition based on lstm and
%   xgboost}, \enquote{2022 Joint International Conference on Digital Arts, Media
%   and Technology with ECTI Northern Section Conference on Electrical,
%   Electronics, Computer and Telecommunications Engineering (ECTI DAMT \&
%   NCON)}, IEEE, pp. 342--345.

% \bibitem{mikolov2013efficient}
% T.~Mikolov, K.~Chen, G.~Corrado and J.~Dean (2013), \enquote{Efficient
%   estimation of word representations in vector space}, \emph{arXiv preprint
%   arXiv:1301.3781}.

% \bibitem{min2017deep}
% S.~Min, B.~Lee and S.~Yoon (2017), \enquote{Deep learning in bioinformatics},
%   \emph{Briefings in bioinformatics}, 18(5), pp. 851--869.

% \bibitem{minsky1969perceptrons}
% M.~Minsky and S.~Papert (1969), \enquote{Perceptrons.}, .

% \bibitem{mirabello2017interpred}
% C.~Mirabello and B.~Wallner (2017), \enquote{Interpred: a pipeline to identify
%   and model protein--protein interactions}, \emph{Proteins: Structure,
%   Function, and Bioinformatics}, 85(6), pp. 1159--1170.

% \bibitem{nair2010rectified}
% V.~Nair and G.~E. Hinton (2010), \enquote{Rectified linear units improve
%   restricted boltzmann machines}, \enquote{Icml}, .

% \bibitem{nooren2003diversity}
% I.~M. Nooren and J.~M. Thornton (2003), \enquote{Diversity of protein--protein
%   interactions}, \emph{The EMBO journal}, 22(14), pp. 3486--3492.

% \bibitem{nooren2003structural}
% I.~M. Nooren and J.~M. Thornton (2003), \enquote{Structural characterisation
%   and functional significance of transient protein--protein interactions},
%   \emph{Journal of molecular biology}, 325(5), pp. 991--1018.

% \bibitem{ohue2014megadock}
% M.~Ohue, Y.~Matsuzaki, N.~Uchikoga, T.~Ishida and Y.~Akiyama (2014),
%   \enquote{Megadock: an all-to-all protein-protein interaction prediction
%   system using tertiary structure data}, \emph{Protein and peptide letters},
%   21(8), pp. 766--778.

% \bibitem{orchard2014mintact}
% S.~Orchard, M.~Ammari, B.~Aranda, L.~Breuza, L.~Briganti, F.~Broackes-Carter,
%   N.~H. Campbell, G.~Chavali, C.~Chen, N.~Del-Toro \emph{et~al.} (2014),
%   \enquote{The mintact project - intact as a common curation platform for 11
%   molecular interaction databases}, \emph{Nucleic acids research}, 42(D1), pp.
%   D358--D363.

% \bibitem{orchard2011data}
% S.~Orchard and H.~Hermjakob (2011), \enquote{Data standardization by the
%   hupo-psi: how has the community benefitted?}, \enquote{Data Mining in
%   Proteomics}, Springer, pp. 149--160.

% \bibitem{orchard2012protein}
% S.~Orchard, S.~Kerrien, S.~Abbani, B.~Aranda, J.~Bhate, S.~Bidwell, A.~Bridge,
%   L.~Briganti, F.~S. Brinkman, G.~Cesareni \emph{et~al.} (2012),
%   \enquote{Protein interaction data curation: the international molecular
%   exchange (imex) consortium}, \emph{Nature methods}, 9(4), pp. 345--350.

% \bibitem{pan2010large}
% X.-Y. Pan, Y.-N. Zhang and H.-B. Shen (2010), \enquote{Large-scale prediction
%   of human protein- protein interactions from amino acid sequence based on
%   latent topic features}, \emph{Journal of proteome research}, 9(10), pp.
%   4992--5001.

% \bibitem{park2001mapping}
% J.~Park, M.~Lappe and S.~A. Teichmann (2001), \enquote{Mapping protein family
%   interactions: intramolecular and intermolecular protein family interaction
%   repertoires in the pdb and yeast}, \emph{Journal of molecular biology},
%   307(3), pp. 929--938.

% \bibitem{pellegrini1999assigning}
% M.~Pellegrini, E.~M. Marcotte, M.~J. Thompson, D.~Eisenberg and T.~O. Yeates
%   (1999), \enquote{Assigning protein functions by comparative genome analysis:
%   protein phylogenetic profiles}, \emph{Proceedings of the National Academy of
%   Sciences}, 96(8), pp. 4285--4288.

% \bibitem{poplin2018universal}
% R.~Poplin, P.-C. Chang, D.~Alexander, S.~Schwartz, T.~Colthurst, A.~Ku,
%   D.~Newburger, J.~Dijamco, N.~Nguyen, P.~T. Afshar \emph{et~al.} (2018),
%   \enquote{A universal snp and small-indel variant caller using deep neural
%   networks}, \emph{Nature biotechnology}, 36(10), pp. 983--987.

% \bibitem{powers2020evaluation}
% D.~M. Powers (2020), \enquote{Evaluation: from precision, recall and f-measure
%   to roc, informedness , markedness and correlation}, \emph{arXiv preprint
%   arXiv:2010.16061}.

% \bibitem{puig2001tandem}
% O.~Puig, F.~Caspary, G.~Rigaut, B.~Rutz, E.~Bouveret, E.~Bragado-Nilsson,
%   M.~Wilm and B.~S{\'e}raphin (2001), \enquote{The tandem affinity purification
%   (tap) method: a general procedure of protein complex purification},
%   \emph{Methods}, 24(3), pp. 218--229.

% \bibitem{pumperla2019deep}
% M.~Pumperla and K.~Ferguson (2019), Deep learning and the game of Go, volume
%   231, Manning Publications Company.

% \bibitem{rain2001protein}
% J.-C. Rain, L.~Selig, H.~De~Reuse, V.~Battaglia, C.~Reverdy, S.~Simon,
%   G.~Lenzen, F.~Petel, J.~Wojcik, V.~Sch{\"a}~chter \emph{et~al.} (2001),
%   \enquote{The protein--protein interaction map of helicobacter pylori},
%   \emph{Nature}, 409(6817), pp. 211--215.

% \bibitem{rose2016rcsb}
% P.~W. Rose, A.~Prli{\'c}, A.~Altunkaya, C.~Bi, A.~R. Bradley, C.~H. Christie,
%   L.~D. Costanzo, J.~M. Duarte, S.~Dutta, Z.~Feng \emph{et~al.} (2016),
%   \enquote{The rcsb protein data bank: integrative view of protein, gene and 3d
%   structural information}, \emph{Nucleic acids research}, p. gkw1000.

% \bibitem{rual2005towards}
% J.-F. Rual, K.~Venkatesan, T.~Hao, T.~Hirozane-Kishikawa, A.~Dricot, N.~Li,
%   G.~F. Berriz, F.~D. Gibbons, M.~Dreze, N.~Ayivi-Guedehoussou \emph{et~al.}
%   (2005), \enquote{Towards a proteome-scale map of the human protein--protein
%   interaction network}, \emph{Nature}, 437(7062), pp. 1173--1178.

% \bibitem{salwinski2004database}
% L.~Salwinski, C.~S. Miller, A.~J. Smith, F.~K. Pettit, J.~U. Bowie and
%   D.~Eisenberg (2004), \enquote{The database of interacting proteins: 2004
%   update}, \emph{Nucleic acids research}, 32(suppl\_1), pp. D449--D451.

% \bibitem{sambourg2010new}
% L.~Sambourg and N.~Thierry-Mieg (2010), \enquote{New insights into
%   protein-protein interaction data lead to increased estimates of the s.
%   cerevisiae interactome size}, \emph{BMC bioinformatics}, 11(1), pp. 1--11.

% \bibitem{shen2007predicting}
% J.~Shen, J.~Zhang, X.~Luo, W.~Zhu, K.~Yu, K.~Chen, Y.~Li and H.~Jiang (2007),
%   \enquote{Predicting protein--protein interactions based only on sequences
%   information}, \emph{Proceedings of the National Academy of Sciences},
%   104(11), pp. 4337--4341.

% \bibitem{sledzieski2021d}
% S.~Sledzieski, R.~Singh, L.~Cowen and B.~Berger (2021), \enquote{D-script
%   translates genome to phenome with sequence-based, structure-aware,
%   genome-scale predictions of protein--protein interactions}, \emph{Cell
%   Systems}, 12(10), pp. 969--982.

% \bibitem{sowmya2014protein}
% G.~Sowmya and S.~Ranganathan (2014), \enquote{Protein-protein interactions and
%   prediction: a comprehensive overview}, \emph{Protein and peptide letters},
%   21(8), pp. 779--789.

% \bibitem{sprinzak2001correlated}
% E.~Sprinzak and H.~Margalit (2001), \enquote{Correlated sequence-signatures as
%   markers of protein-protein interaction}, \emph{Journal of molecular biology},
%   311(4), pp. 681--692.

% \bibitem{sprinzak2003reliable}
% E.~Sprinzak, S.~Sattath and H.~Margalit (2003), \enquote{How reliable are
%   experimental protein--protein interaction data?}, \emph{Journal of molecular
%   biology}, 327(5), pp. 919--923.

% \bibitem{srivastava2014dropout}
% N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever and R.~Salakhutdinov
%   (2014), \enquote{Dropout: a simple way to prevent neural networks from
%   overfitting}, \emph{The journal of machine learning research}, 15(1), pp.
%   1929--1958.

% \bibitem{sun2017sequence}
% T.~Sun, B.~Zhou, L.~Lai and J.~Pei (2017), \enquote{Sequence-based prediction
%   of protein protein interaction using a deep-learning algorithm}, \emph{BMC
%   bioinformatics}, 18(1), pp. 1--8.

% \bibitem{svozil1997introduction}
% D.~Svozil, V.~Kvasnicka and J.~Pospichal (1997), \enquote{Introduction to
%   multi-layer feed-forward neural networks}, \emph{Chemometrics and intelligent
%   laboratory systems}, 39(1), pp. 43--62.

% \bibitem{symeonidis2013biological}
% P.~Symeonidis, N.~Iakovidou, N.~Mantas and Y.~Manolopoulos (2013),
%   \enquote{From biological to social networks: Link prediction based on
%   multi-way spectral clustering}, \emph{Data \& Knowledge Engineering}, 87, pp.
%   226--242.

% \bibitem{szklarczyk2021string}
% D.~Szklarczyk, A.~L. Gable, K.~C. Nastou, D.~Lyon, R.~Kirsch, S.~Pyysalo, N.~T.
%   Doncheva, M.~Legeay, T.~Fang, P.~Bork \emph{et~al.} (2021), \enquote{The
%   string database in 2021: customizable protein--protein networks, and
%   functional characterization of user-uploaded gene/measurement sets},
%   \emph{Nucleic acids research}, 49(D1), pp. D605--D612.

% \bibitem{thongsuwan2021convxgb}
% S.~Thongsuwan, S.~Jaiyen, A.~Padcharoen and P.~Agarwal (2021),
%   \enquote{Convxgb: A new deep learning model for classification problems based
%   on cnn and xgboost}, \emph{Nuclear Engineering and Technology}, 53(2), pp.
%   522--531.

% \bibitem{tian2019predicting}
% B.~Tian, X.~Wu, C.~Chen, W.~Qiu, Q.~Ma and B.~Yu (2019), \enquote{Predicting
%   protein--protein interactions by fusing various chou's pseudo components and
%   using wavelet denoising approach}, \emph{Journal of Theoretical Biology},
%   462, pp. 329--346.

% \bibitem{toby2001using}
% G.~G. Toby and E.~A. Golemis (2001), \enquote{Using the yeast interaction trap
%   and other two-hybrid-based approaches to study protein-protein interactions},
%   \emph{Methods}, 24(3), pp. 201--217.

% \bibitem{vaswani2017attention}
% A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
%   {\L}.~Kaiser and I.~Polosukhin (2017), \enquote{Attention is all you need},
%   \emph{Advances in neural information processing systems}, 30.

% \bibitem{vincent2008extracting}
% P.~Vincent, H.~Larochelle, Y.~Bengio and P.-A. Manzagol (2008),
%   \enquote{Extracting and composing robust features with denoising
%   autoencoders}, \enquote{Proceedings of the 25th international conference on
%   Machine learning}, pp. 1096--1103.

% \bibitem{von2002comparative}
% C.~Von~Mering, R.~Krause, B.~Snel, M.~Cornell, S.~G. Oliver, S.~Fields and
%   P.~Bork (2002), \enquote{Comparative assessment of large-scale data sets of
%   protein--protein interactions}, \emph{Nature}, 417(6887), pp. 399--403.

% \bibitem{walhout2000protein}
% A.~J. Walhout, R.~Sordella, X.~Lu, J.~L. Hartley, G.~F. Temple, M.~A. Brasch,
%   N.~Thierry-Mieg and M.~Vidal (2000), \enquote{Protein interaction mapping in
%   c. elegans using proteins involved in vulval development}, \emph{Science},
%   287(5450), pp. 116--122.

% \bibitem{wang2017protein}
% J.~Wang, L.~Zhang, L.~Jia, Y.~Ren and G.~Yu (2017), \enquote{Protein-protein
%   interactions prediction using a novel local conjoint triad descriptor of
%   amino acid sequences}, \emph{International Journal of Molecular Sciences},
%   18(11), p. 2373.

% \bibitem{wang2018attention}
% Q.~Wang, C.~Xu, Y.~Zhou, T.~Ruan, D.~Gao and P.~He (2018), \enquote{An
%   attention-based bi-gru-capsnet model for hypernymy detection between compound
%   entities}, \enquote{2018 IEEE International Conference on Bioinformatics and
%   Biomedicine (BIBM)}, IEEE, pp. 1031--1035.

% \bibitem{williams1989learning}
% R.~J. Williams and D.~Zipser (1989), \enquote{A learning algorithm for
%   continually running fully recurrent neural networks}, \emph{Neural
%   computation}, 1(2), pp. 270--280.

% \bibitem{wojcik2002prediction}
% J.~Wojcik, I.~G. Boneca and P.~Legrain (2002), \enquote{Prediction, assessment
%   and validation of protein interaction maps in bacteria}, \emph{Journal of
%   molecular biology}, 323(4), pp. 763--770.

% \bibitem{wolpert1997no}
% D.~H. Wolpert and W.~G. Macready (1997), \enquote{No free lunch theorems for
%   optimization}, \emph{IEEE transactions on evolutionary computation}, 1(1),
%   pp. 67--82.

% \bibitem{wu2007detecting}
% Y.~Wu, Q.~Li and X.-Z. Chen (2007), \enquote{Detecting protein--protein
%   interactions by far western blotting}, \emph{Nature protocols}, 2(12), pp.
%   3278--3284.

% \bibitem{xu2015empirical}
% B.~Xu, N.~Wang, T.~Chen and M.~Li (2015), \enquote{Empirical evaluation of
%   rectified activations in convolutional network}, \emph{arXiv preprint
%   arXiv:1505.00853}.

% \bibitem{yan2003analysis}
% Y.~Yan and G.~Marriott (2003), \enquote{Analysis of protein interactions using
%   fluorescence technologies}, \emph{Current opinion in chemical biology}, 7(5),
%   pp. 635--640.

% \bibitem{yang2010prediction}
% L.~Yang, J.-F. Xia and J.~Gui (2010), \enquote{Prediction of protein-protein
%   interactions from protein sequence using local descriptors}, \emph{Protein
%   and Peptide Letters}, 17(9), pp. 1085--1090.

% \bibitem{yang2021transfer}
% X.~Yang, S.~Yang, X.~Lian, S.~Wuchty and Z.~Zhang (2021), \enquote{Transfer
%   learning via multi-scale convolutional neural layers for human--virus
%   protein--protein interaction prediction}, \emph{Bioinformatics}, 37(24), pp.
%   4771--4778.

% \bibitem{you2015predicting}
% Z.-H. You, K.~C. Chan and P.~Hu (2015), \enquote{Predicting protein-protein
%   interactions from primary protein sequences using a novel multi-scale local
%   feature representation scheme and the random forest}, \emph{PloS one}, 10(5),
%   p. e0125811.

% \bibitem{you2010using}
% Z.-H. You, Y.-K. Lei, J.~Gui, D.-S. Huang and X.~Zhou (2010), \enquote{Using
%   manifold embedding for assessing and predicting protein interactions from
%   high-throughput experimental data}, \emph{Bioinformatics}, 26(21), pp.
%   2744--2751.

% \bibitem{you2013prediction}
% Z.-H. You, Y.-K. Lei, L.~Zhu, J.~Xia and B.~Wang (2013), \enquote{Prediction of
%   protein-protein interactions from amino acid sequences with ensemble extreme
%   learning machines and principal component analysis}, \enquote{BMC
%   bioinformatics}, Springer, volume~14, pp. 1--11.

% \bibitem{you2015detecting}
% Z.-H. You, J.~Li, X.~Gao, Z.~He, L.~Zhu, Y.-K. Lei and Z.~Ji (2015),
%   \enquote{Detecting protein-protein interactions with a novel matrix-based
%   protein sequence representation and support vector machines}, \emph{BioMed
%   research international}, 2015.

% \bibitem{young1998yeast}
% K.~Young (1998), \enquote{Yeast two-hybrid: so many interactions,(in) so little
%   time…}, \emph{Biology of reproduction}, 58(2), pp. 302--311.

% \bibitem{zhang2019protein}
% L.~Zhang, G.~Yu, D.~Xia and J.~Wang (2019), \enquote{Protein--protein
%   interactions prediction based on ensemble deep neural networks},
%   \emph{Neurocomputing}, 324, pp. 10--19.

% \bibitem{zhang2012structure}
% Q.~C. Zhang, D.~Petrey, L.~Deng, L.~Qiang, Y.~Shi, C.~A. Thu, B.~Bisikirska,
%   C.~Lefebvre, D.~Accili, T.~Hunter \emph{et~al.} (2012),
%   \enquote{Structure-based prediction of protein--protein interactions on a
%   genome-wide scale}, \emph{Nature}, 490(7421), pp. 556--560.

% \bibitem{zhao2012predicting}
% X.-W. Zhao, Z.-Q. Ma and M.-H. Yin (2012), \enquote{Predicting protein-protein
%   interactions by combing various sequence-derived features into the general
%   form of chou’s pseudo amino acid composition}, \emph{Protein and Peptide
%   Letters}, 19(5), pp. 492--500.

% \bibitem{zhou2015c}
% C.~Zhou, C.~Sun, Z.~Liu and F.~Lau (2015), \enquote{A c-lstm neural network for
%   text classification}, \emph{arXiv preprint arXiv:1511.08630}.

% \bibitem{zhou2018nlp}
% Q.~Zhou and H.~Wu (2018), \enquote{Nlp at iest 2018: Bilstm-attention and
%   lstm-attention via soft voting in emotion classification},
%   \enquote{Proceedings of the 9th Workshop on Computational Approaches to
%   Subjectivity, Sentiment and Social Media Analysis}, pp. 189--194.

% \bibitem{zhou2011prediction}
% Y.~Z. Zhou, Y.~Gao and Y.~Y. Zheng (2011), \enquote{Prediction of
%   protein-protein interactions using local description of amino acid sequence},
%   \enquote{Advances in computer science and education applications}, Springer,
%   pp. 254--262.

% \bibitem{zhu2006noxclass}
% H.~Zhu, F.~S. Domingues, I.~Sommer and T.~Lengauer (2006), \enquote{Noxclass:
%   prediction of protein-protein interaction types}, \emph{BMC bioinformatics},
%   7(1), pp. 1--15.

% \end{thebibliography}

% \custombib

\bibliographystyle{thesis}
\bibliography{references}
\end{document}
